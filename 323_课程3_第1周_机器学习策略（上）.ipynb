{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 课程3_第1周_机器学习策略（上）\n",
    "\n",
    "**分类:** 吴恩达深度学习课程\n",
    "\n",
    "**🏹 仗怎么打？**\n",
    "\n",
    "---\n",
    "\n",
    "### 🧪 想象这样一个场景\n",
    "你的模型效果不好。\n",
    "手下（工程师）问你：\n",
    "- \"我们要不要收集更多数据？\"\n",
    "- \"要不要调大模型？\"\n",
    "- \"要不要训练久一点？\"\n",
    "\n",
    "你不能瞎猜。你需要像诸葛亮一样，根据**正交化（Orthogonalization）** 原则，准确判断出问题出在哪，然后给出一个锦囊妙计。\n",
    "\n",
    "### 🎯 为什么需要这个技术?\n",
    "\n",
    "**问题:** 优化模型的方向太多，盲目尝试会浪费大量时间。\n",
    "\n",
    "**解决:** 建立统一的评估指标，使用正交化策略，一次只解决一个特定的问题。\n",
    "\n",
    "### 📚 循序渐进学习\n",
    "\n",
    "**第一步: 理解问题** (你现在在这里)\n",
    "- 为什么需要这个技术?\n",
    "- 它解决什么问题?\n",
    "\n",
    "**第二步: 学习原理** (接下来)\n",
    "- 这个技术如何工作?\n",
    "- 核心思想是什么?\n",
    "\n",
    "**第三步: 实际应用** (最后)\n",
    "- 如何应用到实际项目?\n",
    "- 如何解决实际问题?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "",
    "## 🔰 新手必看",
    "",
    "**第一次学？这些提示能帮到你！**",
    "",
    "### 💡 学习建议",
    "",
    "1. **不要急** - 慢慢看，不懂的多看几遍",
    "2. **动手做** - 每个代码都运行一遍",
    "3. **改参数** - 试着改改数字，看看会怎样",
    "4. **记笔记** - 把重点记下来",
    "",
    "### ⚠️ 常见问题",
    "",
    "**Q: 代码报错怎么办？**",
    "- 先看错误提示（红色的那行）",
    "- 检查是否有拼写错误",
    "- 确认缩进是否正确（Python对空格很敏感）",
    "- 复制错误信息搜索一下",
    "",
    "**Q: 看不懂怎么办？**",
    "- 跳过难的部分，先学简单的",
    "- 看看前面的课程有没有遗漏",
    "- 多看几遍，理解需要时间",
    "",
    "**Q: 需要什么基础？**",
    "- 会用电脑就行",
    "- Python基础最好有，没有也能学",
    "- 数学不好也没关系，我们用例子讲",
    "",
    "### 📌 学习技巧",
    "",
    "- 🎯 **目标明确**: 知道这节课要学什么",
    "- 📝 **做笔记**: 重点内容记下来",
    "- 💻 **多练习**: 代码要自己敲一遍",
    "- 🤔 **多思考**: 想想为什么这样做",
    "- 🔄 **多复习**: 学完了回头再看看",
    "",
    "---",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 课程3_第1周_机器学习策略（上）\n",
    "\n",
    "**分类:** 其他\n",
    "\n",
    "**🎯 让我们从实际问题出发**\n",
    "\n",
    "---\n",
    "\n",
    "\n## 💭 开始之前:想想这个问题\n\n学习 **课程3_第1周_机器学习策略（上）** 能帮我们解决什么实际问题?\n\n在日常生活中,你可能已经在不知不觉中使用了这个技术:\n- 📱 手机App\n- 🎮 游戏\n- 🛒 网购\n- 📺 视频推荐\n\n让我们一起探索这个技术背后的原理!\n\n### 🎯 为什么需要这个技术?\n\n**问题:** 传统方法有什么局限?\n- 效率低?\n- 准确率低?\n- 不能处理复杂情况?\n\n**解决:** 这个技术如何改进?\n- 提高效率?\n- 提高准确率?\n- 处理复杂情况?\n\n### 📚 循序渐进学习\n\n**第一步: 理解问题** (你现在在这里)\n- 为什么需要这个技术?\n- 它解决什么问题?\n\n**第二步: 学习原理** (接下来)\n- 这个技术如何工作?\n- 核心思想是什么?\n\n**第三步: 实际应用** (最后)\n- 如何应用到实际项目?\n- 如何解决实际问题?\n",
    "\n",
    "---\n",
    "\n",
    "## 🎯 本节课你将学会\n",
    "\n",
    "- ✅ 理解核心概念和原理\n",
    "- ✅ 掌握实际代码实现\n",
    "- ✅ 知道如何应用到实际项目\n",
    "- ✅ 理解这个技术解决什么问题\n",
    "\n",
    "## 💡 学习建议\n",
    "\n",
    "1. **先理解\"为什么\"** - 这个技术解决什么实际问题?\n",
    "2. **再学习\"是什么\"** - 这个技术的原理是什么?\n",
    "3. **最后掌握\"怎么做\"** - 如何用代码实现?\n",
    "4. **动手实践** - 运行代码,修改参数,观察结果\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 课程3_第1周_机器学习策略（上）\n",
    "\n",
    "**分类:** 其他\n",
    "\n",
    "**🎯 让我们从实际问题出发**\n",
    "\n",
    "---\n",
    "\n",
    "\n## 💭 开始之前,想想这个问题\n\n学习 **课程3_第1周_机器学习策略（上）** 能帮我们解决什么实际问题?\n\n在日常生活中,你可能已经在不知不觉中使用了这个技术:\n- 📱 手机App\n- 🎮 游戏\n- 🛒 网购\n- 📺 视频推荐\n\n让我们一起探索这个技术背后的原理!\n",
    "\n",
    "---\n",
    "\n",
    "## 🎯 本节课你将学会\n",
    "\n",
    "- ✅ 理解核心概念和原理\n",
    "- ✅ 掌握实际代码实现\n",
    "- ✅ 知道如何应用到实际项目\n",
    "- ✅ 理解这个技术解决什么问题\n",
    "\n",
    "## 💡 学习建议\n",
    "\n",
    "1. **先理解\"为什么\"** - 这个技术解决什么实际问题?\n",
    "2. **再学习\"是什么\"** - 这个技术的原理是什么?\n",
    "3. **最后掌握\"怎么做\"** - 如何用代码实现?\n",
    "4. **动手实践** - 运行代码,修改参数,观察结果\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***机器学习策略（上）***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. ML策略"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "① 当我们最初得到一个深度神经网络模型时，我们可能希望从很多方面来对它进行优化，例如：\n",
    "\n",
    " - Collect more data\n",
    "\n",
    " - Collect more diverse training set\n",
    "\n",
    " - Train algorithm longer with gradient descent\n",
    "\n",
    " - Try Adam instead of gradient descent\n",
    "\n",
    " - Try bigger network\n",
    "\n",
    " - Try smaller network\n",
    "\n",
    " - Try dropout\n",
    "\n",
    " - Add L2 regularization\n",
    "\n",
    " - Network architecture: Activation functions, #hidden units…\n",
    " \n",
    "② 可选择的方法很多，也很复杂、繁琐。\n",
    "\n",
    "③ 盲目选择、尝试不仅耗费时间而且可能收效甚微。\n",
    "\n",
    "④ 因此，使用快速、有效的策略来优化机器学习模型是非常必要的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 正交化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "① 机器学习中有许多参数、超参数需要调试。\n",
    "\n",
    "② 通过每次只调试一个参数，保持其它参数不变，而得到的模型某一性能改变是一种最常用的调参策略，我们称之为正交化方法（Orthogonalization）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "① Orthogonalization的核心在于每次调试一个参数只会影响模型的某一个性能。\n",
    "\n",
    "② 例如老式电视机旋钮，每个旋钮就对应一个功能，调整旋钮会调整对应的功能，而不会影响其它功能。\n",
    "\n",
    "③ 也就是说彼此旋钮之间是互不影响的，是正交的，这也是Orthogonalization名称的由来。\n",
    "\n",
    "④ 这种方法能够让我们更快更有效地进行机器学习模型的调试和优化。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "① 对应到机器学习监督式学习模型中，可以大致分成四个独立的“功能”，每个“功能”对应一些可调节的唯一的旋钮。四个“功能”如下：\n",
    "\n",
    " - Fit training set well on cost function\n",
    "\n",
    " - Fit dev set well on cost function\n",
    "\n",
    " - Fit test set well on cost function\n",
    "\n",
    " - Performs well in real world\n",
    " \n",
    "② 其中，第一条优化训练集可以通过使用更复杂NN，使用Adam等优化算法来实现；第二条优化验证集可以通过正则化，采用更多训练样本来实现；第三条优化测试集可以通过使用更多的验证集样本来实现；第四条提升实际应用模型可以通过更换验证集，使用新的cost function来实现。\n",
    "\n",
    "③ 概括来说，每一种“功能”对应不同的调节方法。而这些调节方法（旋钮）只会对应一个“功能”，是正交的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "① 顺便提一下，early stopping在模型功能调试中并不推荐使用。\n",
    "\n",
    "② 因为early stopping在提升验证集性能的同时降低了训练集的性能。也就是说early stopping同时影响两个“功能”，不具有独立性、正交性。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 单值评估指标"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "① 构建、优化机器学习模型时，单值评价指标非常必要。\n",
    "\n",
    "② 有了量化的单值评价指标后，我们就能根据这一指标比较不同超参数对应的模型的优劣，从而选择最优的那个模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "① 举个例子，比如有A和B两个模型，它们的准确率（Precision）和召回率（Recall）分别如下："
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "② 如果只看Precision的话，B模型更好。如果只看Recall的话，A模型更好。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "① 实际应用中，我们通常使用单值评价指标F1 Score来评价模型的好坏。\n",
    "\n",
    "② F1 Score综合了Precision和Recall的大小，计算方法如下："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "③ 然后得到了A和B模型各自的F1 Score："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "④ 从F1 Score来看，A模型比B模型更好一些。\n",
    "\n",
    "⑤ 通过引入单值评价指标F1 Score，很方便对不同模型进行比较。\n",
    "\n",
    "⑥ 除了F1 Score之外，我们还可以使用平均值作为单值评价指标来对模型进行评估。\n",
    "\n",
    "⑦ 如下图所示，A, B, C, D, E, F六个模型对不同国家样本的错误率不同，可以计算其平均性能，然后选择平均错误率最小的那个模型（C模型）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 优化指标和满意指标"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "① 有时候，要把所有的性能指标都综合在一起，构成单值评价指标是比较困难的。\n",
    "\n",
    "② 解决办法是，我们可以把某些性能作为优化指标（Optimizing metic），寻求最优化值；而某些性能作为满意指标（Satisficing metic），只要满足阈值就行了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "① 举个猫类识别的例子，有A，B，C三个模型，各个模型的Accuracy和Running time如下表中所示："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "② Accuracy和Running time这两个性能不太合适综合成单值评价指标。\n",
    "\n",
    "③ 因此，我们可以将Accuracy作为优化指标（Optimizing metic），将Running time作为满意指标（Satisficing metic）。\n",
    "\n",
    "④ 也就是说，给Running time设定一个阈值，在其满足阈值的情况下，选择Accuracy最大的模型。\n",
    "\n",
    "⑤ 如果设定Running time必须在100ms以内，那么很明显，模型C不满足阈值条件，首先剔除；模型B相比较模型A而言，Accuracy更高，性能更好。\n",
    "\n",
    "⑥ 概括来说，性能指标（Optimizing metic）是需要优化的，越优越好；而满意指标（Satisficing metic）只要满足设定的阈值就好了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.训练/验证/测试分布"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "① Train/dev/test sets如何设置对机器学习的模型训练非常重要，合理设置能够大大提高模型训练效率和模型质量。\n",
    "\n",
    "② 原则上应该尽量保证dev sets和test sets来源于同一分布且都反映了实际样本的情况。\n",
    "\n",
    "③ 如果dev sets和test sets不来自同一分布，那么我们从dev sets上选择的“最佳”模型往往不能够在test sets上表现得很好。\n",
    "\n",
    "④ 这就好比我们在dev sets上找到最接近一个靶的靶心的箭，但是我们test sets提供的靶心却远远偏离dev sets上的靶心，结果这支肯定无法射中test sets上的靶心位置。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "① 在之前的课程中我们已经介绍过，当样本数量不多（小于一万）的时候，通常将Train/dev/test sets的比例设为60%/20%/20%，在没有dev sets的情况下，Train/test sets的比例设为70%/30%。\n",
    "\n",
    "② 当样本数量很大（百万级别）的时候，通常将相应的比例设为98%/1%/1%或者99%/1%。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "① 对于dev sets数量的设置，应该遵循的准则是通过dev sets能够检测不同算法或模型的区别，以便选择出更好的模型。\n",
    "\n",
    "② 对于test sets数量的设置，应该遵循的准则是通过test sets能够反映出模型在实际中的表现。\n",
    "\n",
    "③ 实际应用中，可能只有train/dev sets，而没有test sets。这种情况也是允许的，只要算法模型没有对dev sets过拟合。但是，条件允许的话，最好是有test sets，实现无偏估计。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "① 算法模型的评价标准有时候需要根据实际情况进行动态调整，目的是让算法模型在实际应用中有更好的效果。\n",
    "\n",
    "② 举个猫类识别的例子。初始的评价标准是错误率，算法A错误率为3%，算法B错误率为5%。\n",
    "\n",
    "③ 显然，A更好一些。但是，实际使用时发现算法A会通过一些色情图片，但是B没有出现这种情况。\n",
    "\n",
    "④ 从用户的角度来说，他们可能更倾向选择B模型，虽然B的错误率高一些。\n",
    "\n",
    "⑤ 这时候，我们就需要改变之前单纯只是使用错误率作为评价标准，而考虑新的情况进行改变。例如增加色情图片的权重，增加其代价。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "① 原来的cost function："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "② 更改评价标准后的cost function："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "③ 概括来说，机器学习可分为两个过程：\n",
    "\n",
    " - Define a metric to evaluate classifiers\n",
    "\n",
    " - How to do well on this metric\n",
    " \n",
    "④ 也就是说，第一步是找靶心，第二步是通过训练，射中靶心。但是在训练的过程中可能会根据实际情况改变算法模型的评价标准，进行动态调整。\n",
    "\n",
    "⑤ 另外一个需要动态改变评价标准的情况是dev/test sets与实际使用的样本分布不一致。比如猫类识别样本图像分辨率差异。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. 人类水平表现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "① 机器学习模型的表现通常会跟人类水平表现作比较，如下图所示："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "② 图中，横坐标是训练时间，纵坐标是准确性。机器学习模型经过训练会不断接近human-level performance甚至超过它。\n",
    "\n",
    "③ 但是，超过human-level performance之后，准确性会上升得比较缓慢，最终不断接近理想的最优情况，我们称之为bayes optimal error。\n",
    "\n",
    "④ 理论上任何模型都不能超过它，bayes optimal error代表了最佳表现。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "① 实际上，human-level performance在某些方面有不俗的表现。例如图像识别、语音识别等领域，人类是很擅长的。\n",
    "\n",
    "② 所以，让机器学习模型性能不断接近human-level performance非常必要也做出很多努力：\n",
    "\n",
    " - Get labeled data from humans.\n",
    "\n",
    " - Gain insight from manual error analysis: Why did a person get this right?\n",
    "\n",
    " - Better analysis of bias/variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "① 实际应用中，要看human-level error，training error和dev error的相对值。\n",
    "\n",
    "② 例如猫类识别的例子中，如果human-level error为1%，training error为8%，dev error为10%。\n",
    "\n",
    "③ 由于training error与human-level error相差7%，dev error与training error只相差2%，所以目标是尽量在训练过程中减小training error，即减小偏差bias。\n",
    "\n",
    "④ 如果图片很模糊，肉眼也看不太清，human-level error提高到7.5%。\n",
    "\n",
    "⑤ 这时，由于training error与human-level error只相差0.5%，dev error与training error只相差2%，所以目标是尽量在训练过程中减小dev error，即方差variance。这是相对而言的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "① 对于物体识别这类CV问题，human-level error是很低的，很接近理想情况下的bayes optimal error。\n",
    "\n",
    "② 因此，上面例子中的1%和7.5%都可以近似看成是两种情况下对应的bayes optimal error。\n",
    "\n",
    "③ 实际应用中，我们一般会用human-level error代表bayes optimal error。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "① 通常，我们把training error与human-level error之间的差值称为偏差（bias），也称作avoidable bias；把dev error与training error之间的差值称为方差（variance）。\n",
    "\n",
    "② 根据bias和variance值的相对大小，可以知道算法模型是否发生了欠拟合或者过拟合。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "① 我们说过human-level performance能够代表bayes optimal error。但是，human-level performance如何定义呢？举个医学图像识别的例子，不同人群的error有所不同：\n",
    "\n",
    " - Typical human : 3% error\n",
    "\n",
    " - Typical doctor : 1% error\n",
    "\n",
    " - Experienced doctor : 0.7% error\n",
    "\n",
    " - Team of experienced doctors : 0.5% error\n",
    " \n",
    "② 不同人群他们的错误率不同。一般来说，我们将表现最好的那一组，即Team of experienced doctors作为human-level performance。\n",
    "\n",
    "③ 那么，这个例子中，human-level error就为0.5%。\n",
    "\n",
    "④ 但是实际应用中，不同人可能选择的human-level performance基准是不同的，这会带来一些影响。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "① 假如该模型training error为0.7%，dev error为0.8。\n",
    "\n",
    "② 如果选择Team of experienced doctors，即human-level error为0.5%，则bias比variance更加突出。\n",
    "\n",
    "③ 如果选择Experienced doctor，即human-level error为0.7%，则variance更加突出。\n",
    "\n",
    "④ 也就是说，选择什么样的human-level error，有时候会影响bias和variance值的相对变化。\n",
    "\n",
    "⑤ 当然这种情况一般只会在模型表现很好，接近bayes optimal error的时候出现。\n",
    "\n",
    "⑥ 越接近bayes optimal error，模型越难继续优化，因为这时候的human-level performance可能是比较模糊难以准确定义的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "① 对于自然感知类问题，例如视觉、听觉等，机器学习的表现不及人类。但是在很多其它方面，机器学习模型的表现已经超过人类了，包括：\n",
    "\n",
    " - Online advertising\n",
    "\n",
    " - Product recommendations\n",
    "\n",
    " - Logistics(predicting transit time)\n",
    "\n",
    " - Loan approvals\n",
    " \n",
    "② 实际上，机器学习模型超过human-level performance是比较困难的。\n",
    "\n",
    "③ 但是只要提供足够多的样本数据，训练复杂的神经网络，模型预测准确性会大大提高，很有可能接近甚至超过human-level performance。\n",
    "\n",
    "④ 值得一提的是当算法模型的表现超过human-level performance时，很难再通过人的直觉来解决如何继续提高算法模型性能的问题。\n",
    "\n",
    "⑤ 实际上，机器学习模型超过human-level performance是比较困难的。但是只要提供足够多的样本数据，训练复杂的神经网络，模型预测准确性会大大提高，很有可能接近甚至超过human-level performance。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. 提高模型性能"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "① 提高机器学习模型性能主要要解决两个问题：avoidable bias和variance。\n",
    "\n",
    "② 我们之前介绍过，training error与human-level error之间的差值反映的是avoidable bias，dev error与training error之间的差值反映的是variance。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "① 解决avoidable bias的常用方法包括：\n",
    "\n",
    " - Train bigger model\n",
    "\n",
    " - Train longer/better optimization algorithms: momentum, RMSprop, Adam\n",
    "\n",
    " - NN architecture/hyperparameters search\n",
    " \n",
    "② 解决variance的常用方法包括：\n",
    "\n",
    " - More data\n",
    "\n",
    " - Regularization: L2, dropout, data augmentation\n",
    "\n",
    " - NN architecture/hyperparameters search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n### 🌍 实际应用场景\n\n1. **手机拍照优化**\n   - 场景: iPhone、华为等手机的AI拍照\n   - 应用: 自动识别场景(人像/风景/美食),优化参数\n   - 效果: 随手一拍就是大片\n   - 案例: 华为P系列手机的AI摄影获得多项大奖\n\n2. **智能家居**\n   - 场景: 小米、华为的智能家居系统\n   - 应用: 学习你的生活习惯,自动调节空调、灯光\n   - 效果: 回家前自动开空调,睡觉时自动关灯\n   - 案例: 小米IoT平台连接设备超5亿台\n\n3. **在线教育**\n   - 场景: 作业帮、猿辅导的拍照搜题\n   - 应用: 拍下题目,AI自动识别并给出解答\n   - 效果: 秒出答案和详细解析\n   - 案例: 作业帮月活用户超1.7亿\n\n4. **健康监测**\n   - 场景: Apple Watch、小米手环的健康监测\n   - 应用: 分析心率、睡眠、运动数据\n   - 效果: 及时发现健康异常,提醒就医\n   - 案例: Apple Watch曾多次救人性命\n\n5. **智能翻译**\n   - 场景: 有道翻译、Google翻译\n   - 应用: 实时翻译语音和文字\n   - 效果: 出国旅游不再担心语言不通\n   - 案例: 有道翻译支持100+种语言互译\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 📚 本节小结\n",
    "\n",
    "恭喜你完成了本节学习!让我们回顾一下:\n",
    "\n",
    "### ✅ 你学到了什么?\n",
    "- 请在这里写下你的收获...\n",
    "\n",
    "### 🤔 还有疑问?\n",
    "- 请记录下你不理解的地方...\n",
    "\n",
    "### 🚀 下一步\n",
    "- 继续学习相关主题\n",
    "- 尝试做一些练习题\n",
    "- 应用到实际项目中\n",
    "\n",
    "---\n",
    "\n",
    "**记住:** 学习是一个循序渐进的过程,不要着急,慢慢来! 💪\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.3",
   "language": "python",
   "name": "python3.6.3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "357.344px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}