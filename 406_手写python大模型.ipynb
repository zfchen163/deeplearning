{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# æ‰‹å†™pythonå¤§æ¨¡å‹\n",
    "\n",
    "**åˆ†ç±»:** åŸºç¡€å…¥é—¨\n",
    "\n",
    "**ğŸ§  è®­ç»ƒAIå°±åƒæ•™å°å­©,éœ€è¦è€å¿ƒå’Œæ–¹æ³•**\n",
    "\n",
    "---\n",
    "\n",
    "\n## ğŸ“ æ•™å°å­©å­¦ä¹ \n\næ•™å°å­©æ—¶:\n- **ç¬¬ä¸€æ­¥**: å‘Šè¯‰ä»–è¿™æ˜¯ä»€ä¹ˆ(è¾“å…¥)\n- **ç¬¬äºŒæ­¥**: å‘Šè¯‰ä»–åº”è¯¥æ€ä¹ˆåš(ç›®æ ‡)\n- **ç¬¬ä¸‰æ­¥**: ä»–åšé”™äº†,çº æ­£ä»–(æŸå¤±å‡½æ•°)\n- **ç¬¬å››æ­¥**: é‡å¤ç»ƒä¹ ,è¶Šæ¥è¶Šç†Ÿç»ƒ(è®­ç»ƒ)\n\n**è®­ç»ƒAIæ¨¡å‹å°±åƒæ•™å°å­©!**\n\n### ğŸ¯ ä¸ºä»€ä¹ˆéœ€è¦è®­ç»ƒ?\n\n**é—®é¢˜:** AIä¸€å¼€å§‹ä»€ä¹ˆéƒ½ä¸ä¼š\n- å°±åƒåˆšå‡ºç”Ÿçš„å©´å„¿\n- éœ€è¦å­¦ä¹ æ‰èƒ½å˜èªæ˜\n- è®­ç»ƒå°±æ˜¯\"æ•™\"AIå­¦ä¹ \n\n**æ–¹æ³•:** é€šè¿‡å¤§é‡æ•°æ®è®­ç»ƒ\n- ç»™AIçœ‹å¾ˆå¤šä¾‹å­\n- å‘Šè¯‰AIæ­£ç¡®ç­”æ¡ˆ\n- AIæ…¢æ…¢å­¦ä¼šè§„å¾‹\n\n### ğŸ“š å¾ªåºæ¸è¿›å­¦ä¹ \n\n**ç¬¬ä¸€æ­¥: ç†è§£é—®é¢˜** (ä½ ç°åœ¨åœ¨è¿™é‡Œ)\n- ä¸ºä»€ä¹ˆéœ€è¦è®­ç»ƒ?\n- å¦‚ä½•è®­ç»ƒ?\n\n**ç¬¬äºŒæ­¥: å­¦ä¹ è®­ç»ƒæ–¹æ³•** (æ¥ä¸‹æ¥)\n- å¦‚ä½•è®¾è®¡æŸå¤±å‡½æ•°?\n- å¦‚ä½•ä¼˜åŒ–å‚æ•°?\n\n**ç¬¬ä¸‰æ­¥: å®é™…åº”ç”¨** (æœ€å)\n- å¦‚ä½•è®­ç»ƒè‡ªå·±çš„æ¨¡å‹?\n- å¦‚ä½•è¯„ä¼°æ•ˆæœ?\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ æœ¬èŠ‚è¯¾ä½ å°†å­¦ä¼š\n",
    "\n",
    "- âœ… ç†è§£æ ¸å¿ƒæ¦‚å¿µå’ŒåŸç†\n",
    "- âœ… æŒæ¡å®é™…ä»£ç å®ç°\n",
    "- âœ… çŸ¥é“å¦‚ä½•åº”ç”¨åˆ°å®é™…é¡¹ç›®\n",
    "- âœ… ç†è§£è¿™ä¸ªæŠ€æœ¯è§£å†³ä»€ä¹ˆé—®é¢˜\n",
    "\n",
    "## ğŸ’¡ å­¦ä¹ å»ºè®®\n",
    "\n",
    "1. **å…ˆç†è§£\"ä¸ºä»€ä¹ˆ\"** - è¿™ä¸ªæŠ€æœ¯è§£å†³ä»€ä¹ˆå®é™…é—®é¢˜?\n",
    "2. **å†å­¦ä¹ \"æ˜¯ä»€ä¹ˆ\"** - è¿™ä¸ªæŠ€æœ¯çš„åŸç†æ˜¯ä»€ä¹ˆ?\n",
    "3. **æœ€åæŒæ¡\"æ€ä¹ˆåš\"** - å¦‚ä½•ç”¨ä»£ç å®ç°?\n",
    "4. **åŠ¨æ‰‹å®è·µ** - è¿è¡Œä»£ç ,ä¿®æ”¹å‚æ•°,è§‚å¯Ÿç»“æœ\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "",
    "## ğŸ”° æ–°æ‰‹å¿…çœ‹",
    "",
    "**ç¬¬ä¸€æ¬¡å­¦ï¼Ÿè¿™äº›æç¤ºèƒ½å¸®åˆ°ä½ ï¼**",
    "",
    "### ğŸ’¡ å­¦ä¹ å»ºè®®",
    "",
    "1. **ä¸è¦æ€¥** - æ…¢æ…¢çœ‹ï¼Œä¸æ‡‚çš„å¤šçœ‹å‡ é",
    "2. **åŠ¨æ‰‹åš** - æ¯ä¸ªä»£ç éƒ½è¿è¡Œä¸€é",
    "3. **æ”¹å‚æ•°** - è¯•ç€æ”¹æ”¹æ•°å­—ï¼Œçœ‹çœ‹ä¼šæ€æ ·",
    "4. **è®°ç¬”è®°** - æŠŠé‡ç‚¹è®°ä¸‹æ¥",
    "",
    "### âš ï¸ å¸¸è§é—®é¢˜",
    "",
    "**Q: ä»£ç æŠ¥é”™æ€ä¹ˆåŠï¼Ÿ**",
    "- å…ˆçœ‹é”™è¯¯æç¤ºï¼ˆçº¢è‰²çš„é‚£è¡Œï¼‰",
    "- æ£€æŸ¥æ˜¯å¦æœ‰æ‹¼å†™é”™è¯¯",
    "- ç¡®è®¤ç¼©è¿›æ˜¯å¦æ­£ç¡®ï¼ˆPythonå¯¹ç©ºæ ¼å¾ˆæ•æ„Ÿï¼‰",
    "- å¤åˆ¶é”™è¯¯ä¿¡æ¯æœç´¢ä¸€ä¸‹",
    "",
    "**Q: çœ‹ä¸æ‡‚æ€ä¹ˆåŠï¼Ÿ**",
    "- è·³è¿‡éš¾çš„éƒ¨åˆ†ï¼Œå…ˆå­¦ç®€å•çš„",
    "- çœ‹çœ‹å‰é¢çš„è¯¾ç¨‹æœ‰æ²¡æœ‰é—æ¼",
    "- å¤šçœ‹å‡ éï¼Œç†è§£éœ€è¦æ—¶é—´",
    "",
    "**Q: éœ€è¦ä»€ä¹ˆåŸºç¡€ï¼Ÿ**",
    "- ä¼šç”¨ç”µè„‘å°±è¡Œ",
    "- PythonåŸºç¡€æœ€å¥½æœ‰ï¼Œæ²¡æœ‰ä¹Ÿèƒ½å­¦",
    "- æ•°å­¦ä¸å¥½ä¹Ÿæ²¡å…³ç³»ï¼Œæˆ‘ä»¬ç”¨ä¾‹å­è®²",
    "",
    "### ğŸ“Œ å­¦ä¹ æŠ€å·§",
    "",
    "- ğŸ¯ **ç›®æ ‡æ˜ç¡®**: çŸ¥é“è¿™èŠ‚è¯¾è¦å­¦ä»€ä¹ˆ",
    "- ğŸ“ **åšç¬”è®°**: é‡ç‚¹å†…å®¹è®°ä¸‹æ¥",
    "- ğŸ’» **å¤šç»ƒä¹ **: ä»£ç è¦è‡ªå·±æ•²ä¸€é",
    "- ğŸ¤” **å¤šæ€è€ƒ**: æƒ³æƒ³ä¸ºä»€ä¹ˆè¿™æ ·åš",
    "- ğŸ”„ **å¤šå¤ä¹ **: å­¦å®Œäº†å›å¤´å†çœ‹çœ‹",
    "",
    "---",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# æ‰‹å†™pythonå¤§æ¨¡å‹\n",
    "\n",
    "**åˆ†ç±»:** åŸºç¡€å…¥é—¨\n",
    "\n",
    "**ğŸ§  è®­ç»ƒAIå°±åƒæ•™å°å­©,éœ€è¦è€å¿ƒå’Œæ–¹æ³•**\n",
    "\n",
    "---\n",
    "\n",
    "\n## ğŸ“ æ•™å°å­©å­¦ä¹ \n\næ•™å°å­©æ—¶:\n- **ç¬¬ä¸€æ­¥**: å‘Šè¯‰ä»–è¿™æ˜¯ä»€ä¹ˆ(è¾“å…¥)\n- **ç¬¬äºŒæ­¥**: å‘Šè¯‰ä»–åº”è¯¥æ€ä¹ˆåš(ç›®æ ‡)\n- **ç¬¬ä¸‰æ­¥**: ä»–åšé”™äº†,çº æ­£ä»–(æŸå¤±å‡½æ•°)\n- **ç¬¬å››æ­¥**: é‡å¤ç»ƒä¹ ,è¶Šæ¥è¶Šç†Ÿç»ƒ(è®­ç»ƒ)\n\n**è®­ç»ƒAIæ¨¡å‹å°±åƒæ•™å°å­©!**\n\n### ğŸ¯ ä¸ºä»€ä¹ˆéœ€è¦è®­ç»ƒ?\n\n**é—®é¢˜:** AIä¸€å¼€å§‹ä»€ä¹ˆéƒ½ä¸ä¼š\n- å°±åƒåˆšå‡ºç”Ÿçš„å©´å„¿\n- éœ€è¦å­¦ä¹ æ‰èƒ½å˜èªæ˜\n- è®­ç»ƒå°±æ˜¯\"æ•™\"AIå­¦ä¹ \n\n**æ–¹æ³•:** é€šè¿‡å¤§é‡æ•°æ®è®­ç»ƒ\n- ç»™AIçœ‹å¾ˆå¤šä¾‹å­\n- å‘Šè¯‰AIæ­£ç¡®ç­”æ¡ˆ\n- AIæ…¢æ…¢å­¦ä¼šè§„å¾‹\n\n### ğŸ“š å¾ªåºæ¸è¿›å­¦ä¹ \n\n**ç¬¬ä¸€æ­¥: ç†è§£é—®é¢˜** (ä½ ç°åœ¨åœ¨è¿™é‡Œ)\n- ä¸ºä»€ä¹ˆéœ€è¦è®­ç»ƒ?\n- å¦‚ä½•è®­ç»ƒ?\n\n**ç¬¬äºŒæ­¥: å­¦ä¹ è®­ç»ƒæ–¹æ³•** (æ¥ä¸‹æ¥)\n- å¦‚ä½•è®¾è®¡æŸå¤±å‡½æ•°?\n- å¦‚ä½•ä¼˜åŒ–å‚æ•°?\n\n**ç¬¬ä¸‰æ­¥: å®é™…åº”ç”¨** (æœ€å)\n- å¦‚ä½•è®­ç»ƒè‡ªå·±çš„æ¨¡å‹?\n- å¦‚ä½•è¯„ä¼°æ•ˆæœ?\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ æœ¬èŠ‚è¯¾ä½ å°†å­¦ä¼š\n",
    "\n",
    "- âœ… ç†è§£æ ¸å¿ƒæ¦‚å¿µå’ŒåŸç†\n",
    "- âœ… æŒæ¡å®é™…ä»£ç å®ç°\n",
    "- âœ… çŸ¥é“å¦‚ä½•åº”ç”¨åˆ°å®é™…é¡¹ç›®\n",
    "- âœ… ç†è§£è¿™ä¸ªæŠ€æœ¯è§£å†³ä»€ä¹ˆé—®é¢˜\n",
    "\n",
    "## ğŸ’¡ å­¦ä¹ å»ºè®®\n",
    "\n",
    "1. **å…ˆç†è§£\"ä¸ºä»€ä¹ˆ\"** - è¿™ä¸ªæŠ€æœ¯è§£å†³ä»€ä¹ˆå®é™…é—®é¢˜?\n",
    "2. **å†å­¦ä¹ \"æ˜¯ä»€ä¹ˆ\"** - è¿™ä¸ªæŠ€æœ¯çš„åŸç†æ˜¯ä»€ä¹ˆ?\n",
    "3. **æœ€åæŒæ¡\"æ€ä¹ˆåš\"** - å¦‚ä½•ç”¨ä»£ç å®ç°?\n",
    "4. **åŠ¨æ‰‹å®è·µ** - è¿è¡Œä»£ç ,ä¿®æ”¹å‚æ•°,è§‚å¯Ÿç»“æœ\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# æ‰‹å†™pythonå¤§æ¨¡å‹\n",
    "\n",
    "**åˆ†ç±»:** åŸºç¡€å…¥é—¨\n",
    "\n",
    "**ğŸ¯ è®©æˆ‘ä»¬ä»å®é™…é—®é¢˜å‡ºå‘**\n",
    "\n",
    "---\n",
    "\n",
    "\n## ğŸ’­ å¼€å§‹ä¹‹å‰,æƒ³æƒ³è¿™ä¸ªé—®é¢˜\n\nå­¦ä¹  **æ‰‹å†™pythonå¤§æ¨¡å‹** èƒ½å¸®æˆ‘ä»¬è§£å†³ä»€ä¹ˆå®é™…é—®é¢˜?\n\nåœ¨æ—¥å¸¸ç”Ÿæ´»ä¸­,ä½ å¯èƒ½å·²ç»åœ¨ä¸çŸ¥ä¸è§‰ä¸­ä½¿ç”¨äº†è¿™ä¸ªæŠ€æœ¯:\n- ğŸ“± æ‰‹æœºApp\n- ğŸ® æ¸¸æˆ\n- ğŸ›’ ç½‘è´­\n- ğŸ“º è§†é¢‘æ¨è\n\nè®©æˆ‘ä»¬ä¸€èµ·æ¢ç´¢è¿™ä¸ªæŠ€æœ¯èƒŒåçš„åŸç†!\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ æœ¬èŠ‚è¯¾ä½ å°†å­¦ä¼š\n",
    "\n",
    "- âœ… ç†è§£æ ¸å¿ƒæ¦‚å¿µå’ŒåŸç†\n",
    "- âœ… æŒæ¡å®é™…ä»£ç å®ç°\n",
    "- âœ… çŸ¥é“å¦‚ä½•åº”ç”¨åˆ°å®é™…é¡¹ç›®\n",
    "- âœ… ç†è§£è¿™ä¸ªæŠ€æœ¯è§£å†³ä»€ä¹ˆé—®é¢˜\n",
    "\n",
    "## ğŸ’¡ å­¦ä¹ å»ºè®®\n",
    "\n",
    "1. **å…ˆç†è§£\"ä¸ºä»€ä¹ˆ\"** - è¿™ä¸ªæŠ€æœ¯è§£å†³ä»€ä¹ˆå®é™…é—®é¢˜?\n",
    "2. **å†å­¦ä¹ \"æ˜¯ä»€ä¹ˆ\"** - è¿™ä¸ªæŠ€æœ¯çš„åŸç†æ˜¯ä»€ä¹ˆ?\n",
    "3. **æœ€åæŒæ¡\"æ€ä¹ˆåš\"** - å¦‚ä½•ç”¨ä»£ç å®ç°?\n",
    "4. **åŠ¨æ‰‹å®è·µ** - è¿è¡Œä»£ç ,ä¿®æ”¹å‚æ•°,è§‚å¯Ÿç»“æœ\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# æ‰‹å†™pythonå¤§æ¨¡å‹.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "åŠ è½½æ•°æ® 2025-06-30 13:18:55.233099\n",
      "å†…å®¹é•¿åº¦ 2317\n",
      "åˆ†è¯ 2025-06-30 13:18:55.235095\n",
      "è®­ç»ƒ 2025-06-30 13:18:55.268005\n",
      "Epoch: 1/10, Batch: 0, Avg Loss:6.4988\n",
      "Epoch1 finished, Average Loss:4.7539\n",
      "Epoch: 2/10, Batch: 0, Avg Loss:3.0506\n",
      "Epoch2 finished, Average Loss:1.8768\n",
      "Epoch: 3/10, Batch: 0, Avg Loss:0.8697\n",
      "Epoch3 finished, Average Loss:0.5106\n",
      "Epoch: 4/10, Batch: 0, Avg Loss:0.3464\n",
      "Epoch4 finished, Average Loss:0.2590\n",
      "Epoch: 5/10, Batch: 0, Avg Loss:0.1770\n",
      "Epoch5 finished, Average Loss:0.2028\n",
      "Epoch: 6/10, Batch: 0, Avg Loss:0.1753\n",
      "Epoch6 finished, Average Loss:0.1774\n",
      "Epoch: 7/10, Batch: 0, Avg Loss:0.1516\n",
      "Epoch7 finished, Average Loss:0.1606\n",
      "Epoch: 8/10, Batch: 0, Avg Loss:0.1537\n",
      "Epoch8 finished, Average Loss:0.1558\n",
      "Epoch: 9/10, Batch: 0, Avg Loss:0.1285\n",
      "Epoch9 finished, Average Loss:0.1462\n",
      "Epoch: 10/10, Batch: 0, Avg Loss:0.1453\n",
      "Epoch10 finished, Average Loss:0.1400\n",
      "æµ‹è¯• 2025-06-30 13:22:54.040832\n",
      "\n",
      "Generated Text:\n",
      "å­™æ‚Ÿç©ºåœ¨è¥¿æ–¹é›¨å¸ˆå±±ä¸ŠæŒ‘æˆ˜èå­ç²¾ï¼Œå°å°ä½è¥¿æ¸¸ä¸‰å®ï¼Œåªæœ‰è·å¾—èå­ç²¾çš„â€œè§‚éŸ³çµç­¾â€å››ä¸ªè·Ÿç€è¯´:â€œè§‚éŸ³çµç­¾â€å’ŒæŠŠå’Œå°šå»ï¼Œå‚æ‰åˆ°æ­¤å¤©å±±å¦–æ€ªå¤©é€šæ‰åˆ°æ­¤å®µã€‚â€æ‰åˆ°è´µå¤„â€œï¼Œè®©å”åƒ§ä¸Šé›·å…¬åƒ§è¯´:â€œè§‚éŸ³çµé¥®åå»ï¼Œå²‚ä¸å¾—å¦–æ€ªè„‘çš„ç¥\n"
     ]
    }
   ],
   "source": [
    "# å¯¼å…¥å¤„ç†æ—¥æœŸæ—¶é—´çš„æ¨¡å—\n",
    "import datetime\n",
    "# å¯¼å…¥æ“ä½œç³»ç»Ÿæ¥å£æ¨¡å—ï¼Œç”¨äºç¯å¢ƒå˜é‡ã€è·¯å¾„ç­‰æ“ä½œ\n",
    "import os\n",
    "# ä» pathlib åº“ä¸­å¯¼å…¥ Path ç±»ï¼Œç”¨äºè¿›è¡Œè·¨å¹³å°çš„æ–‡ä»¶è·¯å¾„å¤„ç†\n",
    "from pathlib import Path\n",
    "\n",
    "# å¯¼å…¥ PyTorch åº“åŠå…¶å­æ¨¡å—\n",
    "# PyTorch ä¸»æ¨¡å—\n",
    "import torch             \n",
    "# åŒ…å«ç¥ç»ç½‘ç»œæ¨¡å—\n",
    "import torch.nn as nn        \n",
    "# æä¾›ä¼˜åŒ–å™¨åŠŸèƒ½\n",
    "import torch.optim as optim          \n",
    "# å¯¼å…¥ NumPyï¼Œç”¨äºç§‘å­¦è®¡ç®—ï¼ˆå¦‚æ•°å­¦å‡½æ•°ï¼‰\n",
    "import numpy as np                          \n",
    "\n",
    "# å®šä¹‰å­—ç¬¦çº§åˆ«çš„åˆ†è¯å™¨ç±»ï¼ˆTokenizerï¼‰\n",
    "class CharTokenizer:\n",
    "    def __init__(self, text):\n",
    "        # åˆ›å»ºæ’åºåçš„å»é‡å­—ç¬¦åˆ—è¡¨ä½œä¸ºè¯æ±‡è¡¨\n",
    "        self.vocab = sorted(list(set(text)))       \n",
    "        # è®¡ç®—è¯æ±‡è¡¨å¤§å°ï¼ˆå­—ç¬¦æ•°é‡ï¼‰\n",
    "        self.vocab_size = len(self.vocab)                  \n",
    "        # å­—ç¬¦åˆ°ç´¢å¼•çš„æ˜ å°„å­—å…¸\n",
    "        self.char_to_idx = {char: idx for idx, char in enumerate(self.vocab)}  \n",
    "        # ç´¢å¼•åˆ°å­—ç¬¦çš„æ˜ å°„å­—å…¸\n",
    "        self.idx_to_char = {idx: char for idx, char in enumerate(self.vocab)}  \n",
    "\n",
    "    def encode(self, text):\n",
    "        # å°†è¾“å…¥æ–‡æœ¬çš„æ¯ä¸ªå­—ç¬¦è½¬æ¢ä¸ºç´¢å¼•\n",
    "        return [self.char_to_idx[char] for char in text]             \n",
    "\n",
    "    def decode(self, indices):\n",
    "        # å°†ç´¢å¼•åˆ—è¡¨è¿˜åŸä¸ºå­—ç¬¦ä¸²æ–‡æœ¬\n",
    "        return ''.join([self.idx_to_char[idx] for idx in indices])   \n",
    "\n",
    "# å®šä¹‰ä½ç½®ç¼–ç æ¨¡å—ï¼Œç”¨äºä¸ºåºåˆ—ä¸­çš„æ¯ä¸ªä½ç½®æ·»åŠ å”¯ä¸€ä¿¡æ¯\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        # è°ƒç”¨çˆ¶ç±»æ„é€ å‡½æ•°\n",
    "        super().__init__()              \n",
    "        # åˆ›å»ºä¸€ä¸ªå½¢çŠ¶ä¸º (max_len, d_model) çš„å…¨é›¶å¼ é‡\n",
    "        pe = torch.zeros(max_len, d_model)                           \n",
    "        # åˆ›å»ºä½ç½®ç´¢å¼• (max_len, 1)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)  \n",
    "        # è®¡ç®—åˆ†æ¯é¢‘ç‡é¡¹\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))  \n",
    "\n",
    "        # å¯¹å¶æ•°ç»´åº¦ä½¿ç”¨ sin ç¼–ç \n",
    "        pe[:, 0::2] = torch.sin(position * div_term)               \n",
    "         # å¯¹å¥‡æ•°ç»´åº¦ä½¿ç”¨ cos ç¼–ç \n",
    "        pe[:, 1::2] = torch.cos(position * div_term)                \n",
    "        # å¢åŠ  batch ç»´åº¦ï¼Œå½¢çŠ¶å˜ä¸º (1, max_len, d_model)\n",
    "        pe = pe.unsqueeze(0)                      \n",
    "        # æ³¨å†Œä¸º bufferï¼Œæ¨¡å‹ä¿å­˜æ—¶åŒ…å«ä½†ä¸æ›´æ–°\n",
    "        self.register_buffer('pe', pe)                               \n",
    "\n",
    "    def forward(self, x):\n",
    "        # æˆªå–å¯¹åº”é•¿åº¦ä½ç½®ç¼–ç ï¼ŒåŠ åˆ°è¾“å…¥ä¸Š\n",
    "        return x + self.pe[:, :x.size(1)]                            \n",
    "\n",
    "# ç®€åŒ–ç‰ˆ Transformer Decoder å±‚ï¼ˆæœ¬ä¾‹æœªä½¿ç”¨ï¼‰\n",
    "class SimpleDecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, n_head, dim_feedforward, dropout):\n",
    "        # åˆå§‹åŒ–çˆ¶ç±»\n",
    "        super().__init__()   \n",
    "        # è‡ªæ³¨æ„åŠ›å±‚\n",
    "        self.self_atten = nn.MultiheadAttention(d_model, n_head, dropout=dropout, batch_first=True)  \n",
    "         # ç¬¬ä¸€ä¸ª LayerNorm\n",
    "        self.norm1 = nn.LayerNorm(d_model)   \n",
    "        # å‰é¦ˆç¥ç»ç½‘ç»œ\n",
    "        self.ffn = nn.Sequential(                                    \n",
    "            nn.Linear(d_model, dim_feedforward),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(dim_feedforward, d_model)\n",
    "        )\n",
    "        # ç¬¬äºŒä¸ª LayerNorm\n",
    "        self.norm2 = nn.LayerNorm(d_model)    \n",
    "        # Dropout é˜²æ­¢è¿‡æ‹Ÿåˆ\n",
    "        self.dropout = nn.Dropout(dropout)                           \n",
    "\n",
    "    def forward(self, tgt, tgt_mask=None):\n",
    "        # æ‰§è¡Œè‡ªæ³¨æ„åŠ›\n",
    "        attn_output, _ = self.self_atten(tgt, tgt, tgt, attn_mask=tgt_mask)  \n",
    "        # æ®‹å·®è¿æ¥ååŠ å…¥ Dropout\n",
    "        tgt = tgt + self.dropout(attn_output)           \n",
    "        # ç¬¬ä¸€æ¬¡å½’ä¸€åŒ–\n",
    "        tgt = self.norm1(tgt)     \n",
    "        # å‰é¦ˆè¾“å‡º\n",
    "        ffn_output = self.ffn(tgt)            \n",
    "         # å†æ¬¡æ®‹å·®è¿æ¥\n",
    "        tgt = tgt + self.dropout(tgt)    \n",
    "        # ç¬¬äºŒæ¬¡å½’ä¸€åŒ–\n",
    "        tgt = self.norm2(tgt)                                       \n",
    "        return tgt\n",
    "\n",
    "# å®šä¹‰ä¸»æ¨¡å‹ï¼šå­—ç¬¦çº§è¯­è¨€æ¨¡å‹\n",
    "class SimleTransformerLM(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, n_head, num_layers, dim_feedforward, dropout, max_len):\n",
    "        # åˆå§‹åŒ–çˆ¶ç±»\n",
    "        super().__init__()               \n",
    "        # å­—ç¬¦ç´¢å¼•åµŒå…¥ä¸º d_model ç»´å‘é‡\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)      \n",
    "        # æ·»åŠ ä½ç½®ç¼–ç æ¨¡å—\n",
    "        self.pos_encoder = PositionalEncoding(d_model, max_len)     \n",
    "        # å•å±‚è§£ç å™¨\n",
    "        decoder_layer = nn.TransformerDecoderLayer(d_model, n_head, dim_feedforward, dropout, batch_first=True)  \n",
    "        # å †å å¤šä¸ªè§£ç å±‚\n",
    "        self.transformer_decoder = nn.TransformerDecoder(decoder_layer, num_layers) \n",
    "        # æœ€ç»ˆçº¿æ€§å±‚è¾“å‡ºè¯è¡¨æ¦‚ç‡\n",
    "        self.fc = nn.Linear(d_model, vocab_size)                    \n",
    "\n",
    "        # ä¿å­˜æ¨¡å‹ç»´åº¦\n",
    "        self.d_model = d_model       \n",
    "        # åˆå§‹åŒ–æ¨¡å‹å‚æ•°\n",
    "        self.init_weights()                                         \n",
    "\n",
    "    def init_weights(self):\n",
    "        # è®¾ç½®åˆå§‹åŒ–èŒƒå›´\n",
    "        initrange = 0.1                  \n",
    "        # åˆå§‹åŒ–åµŒå…¥å±‚æƒé‡\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange) \n",
    "        # å°†çº¿æ€§å±‚åç½®è®¾ä¸º 0\n",
    "        self.fc.bias.data.zero_()    \n",
    "        # åˆå§‹åŒ–çº¿æ€§å±‚æƒé‡\n",
    "        self.fc.weight.data.uniform_(-initrange, initrange)         \n",
    "\n",
    "    def forward(self, src, tgt_mask=None):\n",
    "        # å°†è¾“å…¥ç´¢å¼•åµŒå…¥å¹¶ç¼©æ”¾\n",
    "        src_emb = self.embedding(src) * np.sqrt(self.d_model)   \n",
    "        # åŠ å…¥ä½ç½®ç¼–ç \n",
    "        src_emb = self.pos_encoder(src_emb)             \n",
    "        # ä½¿ç”¨é›¶å‘é‡ä½œä¸º Encoder è¾“å‡ºï¼ˆDecoder-onlyï¼‰\n",
    "        memory = torch.zeros_like(src_emb)                   \n",
    "        # è§£ç å™¨å‰å‘ä¼ æ’­\n",
    "        output = self.transformer_decoder(tgt=src_emb, memory=memory, tgt_mask=tgt_mask)  \n",
    "        # æ˜ å°„ä¸ºè¯è¡¨å¤§å°è¾“å‡º\n",
    "        output = self.fc(output)                                    \n",
    "        return output\n",
    "\n",
    "    def generate_square_mask(self, size):\n",
    "        # ä¸Šä¸‰è§’æ©ç é˜²æ­¢çœ‹åˆ°æœªæ¥\n",
    "        mask = torch.triu(torch.ones(size, size) * float('-inf'), diagonal=1)  \n",
    "        return mask\n",
    "\n",
    "# æ–‡æœ¬æ•°æ®é›†å®šä¹‰ï¼šå°†æ–‡æœ¬è½¬æ¢ä¸ºåºåˆ—å¯¹ç”¨äºè®­ç»ƒ\n",
    "class TextDataset:\n",
    "    def __init__(self, text, tokenizer, seq_len):\n",
    "        # ä¿å­˜åˆ†è¯å™¨å¯¹è±¡\n",
    "        self.tokenizer = tokenizer      \n",
    "        # å°†æ–‡æœ¬è½¬ä¸ºå­—ç¬¦ç´¢å¼•åˆ—è¡¨\n",
    "        self.indexed_text = tokenizer.encode(text)     \n",
    "        # è®¾ç½®åºåˆ—é•¿åº¦\n",
    "        self.seq_len = seq_len                                      \n",
    "\n",
    "    def __len__(self):\n",
    "        # å¯æ„é€ çš„è®­ç»ƒæ ·æœ¬æ•°é‡\n",
    "        return len(self.indexed_text) - self.seq_len                \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # è¾“å…¥åºåˆ—\n",
    "        input_indices = self.indexed_text[idx:idx + self.seq_len]   \n",
    "        # ç›®æ ‡åºåˆ—ä¸ºè¾“å…¥å‘åç§»åŠ¨ä¸€ä½\n",
    "        target_indices = self.indexed_text[idx + 1:idx + self.seq_len + 1]  \n",
    "        # è½¬æ¢ä¸ºå¼ é‡\n",
    "        return torch.tensor(input_indices), torch.tensor(target_indices)    \n",
    "\n",
    "# å®šä¹‰è®­ç»ƒæ¨¡å‹çš„ä¸»å¾ªç¯å‡½æ•°\n",
    "def train_model(model, dataset, tokenizer, epochs, batch_size, seq_len, learning_rate, device):\n",
    "    # å°†æ¨¡å‹ç§»åŠ¨åˆ°è®¾å¤‡ï¼ˆCPU/GPUï¼‰\n",
    "    model.to(device)      \n",
    "    # è®¾ç½®ä¸ºè®­ç»ƒæ¨¡å¼\n",
    "    model.train()                     \n",
    "    # ä½¿ç”¨ AdamW ä¼˜åŒ–å™¨\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate)   \n",
    "    # ä½¿ç”¨äº¤å‰ç†µæŸå¤±\n",
    "    criterion = nn.CrossEntropyLoss()                               \n",
    "    # æ•°æ®åŠ è½½å™¨\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size, shuffle=True, drop_last=True)  \n",
    "\n",
    "    # éå†æ¯ä¸ª epoch\n",
    "    for epoch in range(epochs):                                     \n",
    "        total_loss = 0\n",
    "        # éå†æ¯ä¸ª batch\n",
    "        for batch_idx, (input_seq, target_seq) in enumerate(dataloader):  \n",
    "            # ç§»åŠ¨æ•°æ®åˆ°è®¾å¤‡\n",
    "            input_seq, target_seq = input_seq.to(device), target_seq.to(device)  \n",
    "            # ç”Ÿæˆå› æœæ©ç \n",
    "            src_mask = model.generate_square_mask(seq_len).to(device)           \n",
    "\n",
    "            # æ¸…é™¤æ¢¯åº¦\n",
    "            optimizer.zero_grad()          \n",
    "            # æ¨¡å‹å‰å‘ä¼ æ’­\n",
    "            output = model(input_seq, tgt_mask=src_mask)       \n",
    "            # è®¡ç®—æŸå¤±\n",
    "            loss = criterion(output.view(-1, tokenizer.vocab_size), target_seq.view(-1))  \n",
    "\n",
    "            # åå‘ä¼ æ’­\n",
    "            loss.backward()     \n",
    "            # ä¼˜åŒ–æ›´æ–°\n",
    "            optimizer.step()                                        \n",
    "\n",
    "            # ç´¯ç§¯æŸå¤±\n",
    "            total_loss += loss.item()      \n",
    "            # æ¯ 100 æ‰¹è¾“å‡ºä¸€æ¬¡å¹³å‡æŸå¤±\n",
    "            if batch_idx % 100 == 0:                                \n",
    "                avg_loss = total_loss / (batch_idx + 1)\n",
    "                print(f'Epoch: {epoch+1}/{epochs}, Batch: {batch_idx}, Avg Loss:{avg_loss:.4f}')\n",
    "\n",
    "        # å½“å‰ epoch å¹³å‡æŸå¤±\n",
    "        avg_epoch_loss = total_loss / len(dataloader)               \n",
    "        print(f'Epoch{epoch+1} finished, Average Loss:{avg_epoch_loss:.4f}')     \n",
    "\n",
    "# å®šä¹‰æ–‡æœ¬ç”Ÿæˆå‡½æ•°ï¼ˆç»™å®šèµ·å§‹å­—ç¬¦ç”Ÿæˆåºåˆ—ï¼‰\n",
    "def generate_text(model, tokenizer, start_text, max_len, device, temperature=1.0):\n",
    "    # ç§»åŠ¨æ¨¡å‹åˆ°è®¾å¤‡\n",
    "    model.to(device)          \n",
    "    # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼\n",
    "    model.eval()                    \n",
    "    # å°†èµ·å§‹æ–‡æœ¬ç¼–ç ä¸ºç´¢å¼•åˆ—è¡¨\n",
    "    input_indices = tokenizer.encode(start_text)                   \n",
    "    # æ·»åŠ  batch ç»´åº¦å¹¶è½¬ä¸ºå¼ é‡\n",
    "    input_tensor = torch.tensor(input_indices).unsqueeze(0).to(device)  \n",
    "\n",
    "    # åˆå§‹åŒ–ç”Ÿæˆç»“æœåˆ—è¡¨\n",
    "    generated_indices = input_indices.copy()                        \n",
    "\n",
    "    # ä¸è®°å½•æ¢¯åº¦ï¼ŒèŠ‚çœå†…å­˜\n",
    "    with torch.no_grad():      \n",
    "        # æœ€é•¿ç”Ÿæˆ max_len ä¸ªå­—ç¬¦\n",
    "        for _ in range(max_len):                        \n",
    "            # åŠ¨æ€ç”Ÿæˆæ©ç \n",
    "            src_mask = model.generate_square_mask(input_tensor.size(1)).to(device)  \n",
    "            # å‰å‘ä¼ æ’­è·å– logits\n",
    "            output = model(input_tensor, tgt_mask=src_mask)         \n",
    "\n",
    "            # è·å–æœ€åä¸€ä¸ªä½ç½®çš„è¾“å‡ºå‘é‡\n",
    "            last_output = output[:, -1, :]                          \n",
    "            # åº”ç”¨ softmax è·å–æ¦‚ç‡åˆ†å¸ƒ\n",
    "            output_probs = nn.functional.softmax(last_output / temperature, dim=-1)  \n",
    "            # ä»æ¦‚ç‡ä¸­é‡‡æ ·ä¸‹ä¸€ä¸ªå­—ç¬¦ç´¢å¼•\n",
    "            next_token_idx = torch.multinomial(output_probs, num_samples=1).item()  \n",
    "\n",
    "            # æ·»åŠ æ–°å­—ç¬¦\n",
    "            generated_indices.append(next_token_idx)           \n",
    "            # æ›´æ–°è¾“å…¥å¼ é‡\n",
    "            input_tensor = torch.tensor([generated_indices]).to(device)  \n",
    "\n",
    "    # è§£ç ç”Ÿæˆçš„ç´¢å¼•ä¸ºå­—ç¬¦ä¸²\n",
    "    generate_text = tokenizer.decode(generated_indices)             \n",
    "    return generate_text\n",
    "\n",
    "# ä¸»ç¨‹åºå…¥å£\n",
    "if __name__ == '__main__':\n",
    "    # è¾“å‡ºå½“å‰æ—¶é—´\n",
    "    print('åŠ è½½æ•°æ®', datetime.datetime.now())                      \n",
    "\n",
    "    # å®šä¹‰æ–‡æœ¬ç›®å½•\n",
    "    book_dir = Path(r'test')      \n",
    "    # åˆå§‹åŒ–æ–‡æœ¬å†…å®¹å˜é‡\n",
    "    text_data = ''             \n",
    "    # éå†æ‰€æœ‰ txt æ–‡ä»¶\n",
    "    for book in book_dir.glob('*.txt'):                         \n",
    "        # è¯»å–æ–‡æœ¬å¹¶è¿½åŠ åˆ° text_data\n",
    "        text_data += book.read_text(encoding='utf-8')               \n",
    "\n",
    "    # æ‰“å°æ–‡æœ¬æ€»é•¿åº¦\n",
    "    print('å†…å®¹é•¿åº¦', len(text_data))       \n",
    "    # è¾“å‡ºæ—¶é—´æˆ³\n",
    "    print('åˆ†è¯', datetime.datetime.now())       \n",
    "    # åˆå§‹åŒ–å­—ç¬¦åˆ†è¯å™¨\n",
    "    tokenizer = CharTokenizer(text_data)                            \n",
    "\n",
    "    # è®¾ç½®æ¨¡å‹è¶…å‚æ•°\n",
    "    vocab_size = tokenizer.vocab_size\n",
    "    d_model = 128\n",
    "    n_head = 8\n",
    "    num_layers = 8\n",
    "    dim_feedforward = 256\n",
    "    dropout = 0.1\n",
    "    seq_len = 32\n",
    "    max_len = 512\n",
    "\n",
    "    # è®¾ç½®è®­ç»ƒè¶…å‚æ•°\n",
    "    epochs = 10\n",
    "    batch_size = 32\n",
    "    learning_rate = 0.001\n",
    "    # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨ GPU\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \n",
    "\n",
    "    # åˆå§‹åŒ–æ¨¡å‹\n",
    "    model = SimleTransformerLM(vocab_size, d_model, n_head, num_layers, dim_feedforward, dropout, max_len)  \n",
    "    # åˆ›å»ºæ•°æ®é›†å¯¹è±¡\n",
    "    dataset = TextDataset(text_data, tokenizer, seq_len)         \n",
    "    # è¾“å‡ºå¼€å§‹è®­ç»ƒæ—¶é—´\n",
    "    print('è®­ç»ƒ', datetime.datetime.now())                          \n",
    "    # å¼€å§‹è®­ç»ƒ\n",
    "    train_model(model, dataset, tokenizer, epochs, batch_size, seq_len, learning_rate, device)  \n",
    "\n",
    "    # è¾“å‡ºæµ‹è¯•å¼€å§‹æ—¶é—´\n",
    "    print('æµ‹è¯•', datetime.datetime.now())          \n",
    "    # è®¾ç½®èµ·å§‹æ–‡æœ¬\n",
    "    start_text = 'å­™æ‚Ÿç©º'                                           \n",
    "    # æ–‡æœ¬ç”Ÿæˆ\n",
    "    generate_text = generate_text(model, tokenizer, start_text, max_len=100, device=device, temperature=1.0)  \n",
    "    # è¾“å‡ºæç¤ºä¿¡æ¯\n",
    "    print('\\nGenerated Text:')                                     \n",
    "    # æ‰“å°ç”Ÿæˆçš„æ–‡æœ¬\n",
    "    print(generate_text)                                           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n### ğŸŒ å®é™…åº”ç”¨åœºæ™¯\n\n1. **æ™ºèƒ½å®¢æœæœºå™¨äºº**\n   - åœºæ™¯: æ·˜å®ã€äº¬ä¸œçš„åœ¨çº¿å®¢æœ\n   - åº”ç”¨: ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹ç†è§£ç”¨æˆ·é—®é¢˜å¹¶å›ç­”\n   - æ•ˆæœ: 24å°æ—¶åœ¨çº¿,ç§’å›æ¶ˆæ¯,è§£å†³ç‡80%+\n   - æ¡ˆä¾‹: é˜¿é‡Œå°èœœæ¯å¤©æœåŠ¡è¶…è¿‡1000ä¸‡ç”¨æˆ·\n\n2. **è¯­éŸ³åŠ©æ‰‹**\n   - åœºæ™¯: Siriã€å°çˆ±åŒå­¦ã€å¤©çŒ«ç²¾çµ\n   - åº”ç”¨: è¯­éŸ³è¯†åˆ«æ¨¡å‹+è‡ªç„¶è¯­è¨€ç†è§£æ¨¡å‹\n   - æ•ˆæœ: å¬æ‡‚ä½ è¯´çš„è¯,æ‰§è¡Œå„ç§æŒ‡ä»¤\n   - æ¡ˆä¾‹: å…¨çƒæ™ºèƒ½éŸ³ç®±å‡ºè´§é‡è¶…2äº¿å°\n\n3. **ç…§ç‰‡ç¾åŒ–**\n   - åœºæ™¯: ç¾å›¾ç§€ç§€ã€æŠ–éŸ³æ»¤é•œ\n   - åº”ç”¨: ä½¿ç”¨æ¨¡å‹è‡ªåŠ¨ç£¨çš®ã€ç˜¦è„¸ã€ç¾ç™½\n   - æ•ˆæœ: ä¸€é”®ç¾é¢œ,æ•ˆæœè‡ªç„¶\n   - æ¡ˆä¾‹: ç¾å›¾ç§€ç§€æœˆæ´»ç”¨æˆ·è¶…3äº¿\n\n4. **æ¸¸æˆAI**\n   - åœºæ™¯: ç‹è€…è£è€€ã€å’Œå¹³ç²¾è‹±çš„AIå¯¹æ‰‹\n   - åº”ç”¨: è®­ç»ƒæ¨¡å‹è®©AIåƒäººä¸€æ ·ç©æ¸¸æˆ\n   - æ•ˆæœ: AIèƒ½åšå‡ºåˆç†çš„æˆ˜æœ¯å†³ç­–\n   - æ¡ˆä¾‹: OpenAIçš„Dota2 AIå‡»è´¥ä¸–ç•Œå† å†›\n\n5. **æ™ºèƒ½æ¨è**\n   - åœºæ™¯: ç½‘æ˜“äº‘éŸ³ä¹ã€Bç«™çš„æ¨èç³»ç»Ÿ\n   - åº”ç”¨: æ¨¡å‹åˆ†æä½ çš„å–œå¥½,æ¨èå†…å®¹\n   - æ•ˆæœ: è¶Šç”¨è¶Šæ‡‚ä½ ,æ¨èè¶Šæ¥è¶Šå‡†\n   - æ¡ˆä¾‹: æŠ–éŸ³æ¨èç®—æ³•è®©ç”¨æˆ·å¹³å‡åœç•™æ—¶é•¿è¶…100åˆ†é’Ÿ/å¤©\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n### ğŸŒ å®é™…åº”ç”¨åœºæ™¯\n\n1. **æ™ºèƒ½å®¢æœæœºå™¨äºº**\n   - åœºæ™¯: æ·˜å®ã€äº¬ä¸œçš„åœ¨çº¿å®¢æœ\n   - åº”ç”¨: ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹ç†è§£ç”¨æˆ·é—®é¢˜å¹¶å›ç­”\n   - æ•ˆæœ: 24å°æ—¶åœ¨çº¿,ç§’å›æ¶ˆæ¯,è§£å†³ç‡80%+\n   - æ¡ˆä¾‹: é˜¿é‡Œå°èœœæ¯å¤©æœåŠ¡è¶…è¿‡1000ä¸‡ç”¨æˆ·\n\n2. **è¯­éŸ³åŠ©æ‰‹**\n   - åœºæ™¯: Siriã€å°çˆ±åŒå­¦ã€å¤©çŒ«ç²¾çµ\n   - åº”ç”¨: è¯­éŸ³è¯†åˆ«æ¨¡å‹+è‡ªç„¶è¯­è¨€ç†è§£æ¨¡å‹\n   - æ•ˆæœ: å¬æ‡‚ä½ è¯´çš„è¯,æ‰§è¡Œå„ç§æŒ‡ä»¤\n   - æ¡ˆä¾‹: å…¨çƒæ™ºèƒ½éŸ³ç®±å‡ºè´§é‡è¶…2äº¿å°\n\n3. **ç…§ç‰‡ç¾åŒ–**\n   - åœºæ™¯: ç¾å›¾ç§€ç§€ã€æŠ–éŸ³æ»¤é•œ\n   - åº”ç”¨: ä½¿ç”¨æ¨¡å‹è‡ªåŠ¨ç£¨çš®ã€ç˜¦è„¸ã€ç¾ç™½\n   - æ•ˆæœ: ä¸€é”®ç¾é¢œ,æ•ˆæœè‡ªç„¶\n   - æ¡ˆä¾‹: ç¾å›¾ç§€ç§€æœˆæ´»ç”¨æˆ·è¶…3äº¿\n\n4. **æ¸¸æˆAI**\n   - åœºæ™¯: ç‹è€…è£è€€ã€å’Œå¹³ç²¾è‹±çš„AIå¯¹æ‰‹\n   - åº”ç”¨: è®­ç»ƒæ¨¡å‹è®©AIåƒäººä¸€æ ·ç©æ¸¸æˆ\n   - æ•ˆæœ: AIèƒ½åšå‡ºåˆç†çš„æˆ˜æœ¯å†³ç­–\n   - æ¡ˆä¾‹: OpenAIçš„Dota2 AIå‡»è´¥ä¸–ç•Œå† å†›\n\n5. **æ™ºèƒ½æ¨è**\n   - åœºæ™¯: ç½‘æ˜“äº‘éŸ³ä¹ã€Bç«™çš„æ¨èç³»ç»Ÿ\n   - åº”ç”¨: æ¨¡å‹åˆ†æä½ çš„å–œå¥½,æ¨èå†…å®¹\n   - æ•ˆæœ: è¶Šç”¨è¶Šæ‡‚ä½ ,æ¨èè¶Šæ¥è¶Šå‡†\n   - æ¡ˆä¾‹: æŠ–éŸ³æ¨èç®—æ³•è®©ç”¨æˆ·å¹³å‡åœç•™æ—¶é•¿è¶…100åˆ†é’Ÿ/å¤©\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“š æœ¬èŠ‚å°ç»“\n",
    "\n",
    "æ­å–œä½ å®Œæˆäº†æœ¬èŠ‚å­¦ä¹ !è®©æˆ‘ä»¬å›é¡¾ä¸€ä¸‹:\n",
    "\n",
    "### âœ… ä½ å­¦åˆ°äº†ä»€ä¹ˆ?\n",
    "- è¯·åœ¨è¿™é‡Œå†™ä¸‹ä½ çš„æ”¶è·...\n",
    "\n",
    "### ğŸ¤” è¿˜æœ‰ç–‘é—®?\n",
    "- è¯·è®°å½•ä¸‹ä½ ä¸ç†è§£çš„åœ°æ–¹...\n",
    "\n",
    "### ğŸš€ ä¸‹ä¸€æ­¥\n",
    "- ç»§ç»­å­¦ä¹ ç›¸å…³ä¸»é¢˜\n",
    "- å°è¯•åšä¸€äº›ç»ƒä¹ é¢˜\n",
    "- åº”ç”¨åˆ°å®é™…é¡¹ç›®ä¸­\n",
    "\n",
    "---\n",
    "\n",
    "**è®°ä½:** å­¦ä¹ æ˜¯ä¸€ä¸ªå¾ªåºæ¸è¿›çš„è¿‡ç¨‹,ä¸è¦ç€æ€¥,æ…¢æ…¢æ¥! ğŸ’ª\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG",
   "language": "python",
   "name": "rag"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "277.969px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}