{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 课程2_第2周_优化算法\n",
    "\n",
    "**分类:** 吴恩达深度学习课程\n",
    "\n",
    "**🏔️ 寻找最低谷**\n",
    "\n",
    "---\n",
    "\n",
    "### 🧪 想象这样一个场景\n",
    "\n",
    "你被困在了一座漆黑的高山上（高Loss），你的目标是下到最低的山谷里（低Loss）。\n",
    "\n",
    "你看不见路，只能用脚试探。\n",
    "- **SGD (随机梯度下降)**: 像个醉汉，跌跌撞撞，但这步往左，下步往右，虽然慢但也能下山。\n",
    "- **Momentum (动量)**: 像个滑雪者，利用惯性，冲过小坑，加速下山。\n",
    "- **Adam**: 像个专业的登山向导，不仅利用惯性，还懂得根据地形调整步子大小（自适应学习率）。\n",
    "\n",
    "### 🎯 为什么需要这个技术?\n",
    "\n",
    "**问题:** 如何快速、稳定地找到损失函数的最小值？\n",
    "\n",
    "**解决:** 使用改进的优化算法（如Adam），结合动量和自适应学习率，加速收敛。\n",
    "\n",
    "### 📚 循序渐进学习\n",
    "\n",
    "**第一步: 理解问题** (你现在在这里)\n",
    "- 为什么需要这个技术?\n",
    "- 它解决什么问题?\n",
    "\n",
    "**第二步: 学习原理** (接下来)\n",
    "- 这个技术如何工作?\n",
    "- 核心思想是什么?\n",
    "\n",
    "**第三步: 实际应用** (最后)\n",
    "- 如何应用到实际项目?\n",
    "- 如何解决实际问题?\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "",
    "## 🔰 新手必看",
    "",
    "**第一次学？这些提示能帮到你！**",
    "",
    "### 💡 学习建议",
    "",
    "1. **不要急** - 慢慢看，不懂的多看几遍",
    "2. **动手做** - 每个代码都运行一遍",
    "3. **改参数** - 试着改改数字，看看会怎样",
    "4. **记笔记** - 把重点记下来",
    "",
    "### ⚠️ 常见问题",
    "",
    "**Q: 代码报错怎么办？**",
    "- 先看错误提示（红色的那行）",
    "- 检查是否有拼写错误",
    "- 确认缩进是否正确（Python对空格很敏感）",
    "- 复制错误信息搜索一下",
    "",
    "**Q: 看不懂怎么办？**",
    "- 跳过难的部分，先学简单的",
    "- 看看前面的课程有没有遗漏",
    "- 多看几遍，理解需要时间",
    "",
    "**Q: 需要什么基础？**",
    "- 会用电脑就行",
    "- Python基础最好有，没有也能学",
    "- 数学不好也没关系，我们用例子讲",
    "",
    "### 📌 学习技巧",
    "",
    "- 🎯 **目标明确**: 知道这节课要学什么",
    "- 📝 **做笔记**: 重点内容记下来",
    "- 💻 **多练习**: 代码要自己敲一遍",
    "- 🤔 **多思考**: 想想为什么这样做",
    "- 🔄 **多复习**: 学完了回头再看看",
    "",
    "---",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 课程2_第2周_优化算法\n",
    "\n",
    "**分类:** 其他\n",
    "\n",
    "**🎯 让我们从实际问题出发**\n",
    "\n",
    "---\n",
    "\n",
    "\n## 💭 开始之前:想想这个问题\n\n学习 **课程2_第2周_优化算法** 能帮我们解决什么实际问题?\n\n在日常生活中,你可能已经在不知不觉中使用了这个技术:\n- 📱 手机App\n- 🎮 游戏\n- 🛒 网购\n- 📺 视频推荐\n\n让我们一起探索这个技术背后的原理!\n\n### 🎯 为什么需要这个技术?\n\n**问题:** 传统方法有什么局限?\n- 效率低?\n- 准确率低?\n- 不能处理复杂情况?\n\n**解决:** 这个技术如何改进?\n- 提高效率?\n- 提高准确率?\n- 处理复杂情况?\n\n### 📚 循序渐进学习\n\n**第一步: 理解问题** (你现在在这里)\n- 为什么需要这个技术?\n- 它解决什么问题?\n\n**第二步: 学习原理** (接下来)\n- 这个技术如何工作?\n- 核心思想是什么?\n\n**第三步: 实际应用** (最后)\n- 如何应用到实际项目?\n- 如何解决实际问题?\n",
    "\n",
    "---\n",
    "\n",
    "## 🎯 本节课你将学会\n",
    "\n",
    "- ✅ 理解核心概念和原理\n",
    "- ✅ 掌握实际代码实现\n",
    "- ✅ 知道如何应用到实际项目\n",
    "- ✅ 理解这个技术解决什么问题\n",
    "\n",
    "## 💡 学习建议\n",
    "\n",
    "1. **先理解\"为什么\"** - 这个技术解决什么实际问题?\n",
    "2. **再学习\"是什么\"** - 这个技术的原理是什么?\n",
    "3. **最后掌握\"怎么做\"** - 如何用代码实现?\n",
    "4. **动手实践** - 运行代码,修改参数,观察结果\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 课程2_第2周_优化算法\n",
    "\n",
    "**分类:** 其他\n",
    "\n",
    "**🎯 如何找到最佳答案?就像爬山找最高点**\n",
    "\n",
    "---\n",
    "\n",
    "\n## 🏔️ 爬山找最高点\n\n想象你在一座大山上,被蒙上眼睛,要找到山顶:\n\n**方法1: 随机乱走** ❌\n- 可能永远找不到山顶\n- 效率太低\n\n**方法2: 感受脚下的坡度** ✅\n- 如果脚下是上坡,继续往前走\n- 如果脚下是下坡,换个方向\n- 每次都往\"最陡的上坡\"方向走\n- 最终能到达山顶\n\n**这就是优化算法的思想!**\n\n## 🎮 打游戏练级\n\n玩RPG游戏时:\n- **目标:** 让角色变得最强\n- **方法:** \n  - 打怪升级(调整参数)\n  - 装备升级(优化策略)\n  - 技能加点(选择方向)\n\n每次战斗后:\n- 如果赢了,说明方向对了,继续这样练\n- 如果输了,说明需要调整策略\n\n**AI训练就是这样\"练级\"的!**\n\n## 🎯 什么是优化算法?\n\n**用一句话说:** 不断尝试,找到让结果最好的那组参数。\n\n就像调音量:\n- 音量太小 → 往上调\n- 音量太大 → 往下调\n- 直到找到最舒服的音量\n\n在AI中:\n- 预测不准 → 调整参数\n- 越来越准 → 继续这个方向\n- 直到找到最佳参数\n",
    "\n",
    "---\n",
    "\n",
    "## 🎯 本节课你将学会\n",
    "\n",
    "- ✅ 理解核心概念和原理\n",
    "- ✅ 掌握实际代码实现\n",
    "- ✅ 知道如何应用到实际项目\n",
    "- ✅ 理解这个技术解决什么问题\n",
    "\n",
    "## 💡 学习建议\n",
    "\n",
    "1. **先理解\"为什么\"** - 这个技术解决什么实际问题?\n",
    "2. **再学习\"是什么\"** - 这个技术的原理是什么?\n",
    "3. **最后掌握\"怎么做\"** - 如何用代码实现?\n",
    "4. **动手实践** - 运行代码,修改参数,观察结果\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***优化算法***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Mini-batch梯度下降"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "① 之前我们介绍的神经网络训练过程是对所有m个样本，称为batch，通过向量化计算方式，同时进行的。\n",
    "\n",
    "② 如果m很大，例如达到百万数量级，训练速度往往会很慢，因为每次迭代都要对所有样本进行求和运算和矩阵运算。我们将这种梯度下降算法称为Batch Gradient Descent。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "① 为了解决这一问题，我们可以把m个训练样本分成若干个子集，称为mini-batches，这样每个子集包含的数据量就小了，例如只有1000，然后每次在单一子集上进行神经网络训练，速度就会大大提高。这种梯度下降算法叫做Mini-batch Gradient Descent。"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n### 🌍 实际应用场景\n\n1. **手机拍照优化**\n   - 场景: iPhone、华为等手机的AI拍照\n   - 应用: 自动识别场景(人像/风景/美食),优化参数\n   - 效果: 随手一拍就是大片\n   - 案例: 华为P系列手机的AI摄影获得多项大奖\n\n2. **智能家居**\n   - 场景: 小米、华为的智能家居系统\n   - 应用: 学习你的生活习惯,自动调节空调、灯光\n   - 效果: 回家前自动开空调,睡觉时自动关灯\n   - 案例: 小米IoT平台连接设备超5亿台\n\n3. **在线教育**\n   - 场景: 作业帮、猿辅导的拍照搜题\n   - 应用: 拍下题目,AI自动识别并给出解答\n   - 效果: 秒出答案和详细解析\n   - 案例: 作业帮月活用户超1.7亿\n\n4. **健康监测**\n   - 场景: Apple Watch、小米手环的健康监测\n   - 应用: 分析心率、睡眠、运动数据\n   - 效果: 及时发现健康异常,提醒就医\n   - 案例: Apple Watch曾多次救人性命\n\n5. **智能翻译**\n   - 场景: 有道翻译、Google翻译\n   - 应用: 实时翻译语音和文字\n   - 效果: 出国旅游不再担心语言不通\n   - 案例: 有道翻译支持100+种语言互译\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "② 这里顺便总结一下我们遇到的神经网络中几类字母的上标含义："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "③ Mini-batches Gradient Descent的实现过程是先将总的训练样本分成T个子集（mini-batches），然后对每个mini-batch进行神经网络训练，包括Forward Propagation，Compute Cost Function，Backward Propagation，循环至T个mini-batch都训练完毕。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for  t=1,⋯,T {\n",
    "    Forward Propagation\n",
    "    ComputeCostFunction\n",
    "    BackwardPropagation\n",
    "    W:=W−α⋅dW\n",
    "    b:=b−α⋅db\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "① 经过T次循环之后，所有m个训练样本都进行了梯度下降计算。这个过程，我们称之为经历了一个epoch。\n",
    "\n",
    "② 对于Batch Gradient Descent而言，一个epoch只进行一次梯度下降算法；而Mini-Batches Gradient Descent，一个epoch会进行T次梯度下降算法。\n",
    "\n",
    "③ 值得一提的是，对于Mini-Batches Gradient Descent，可以进行多次epoch训练。而且，每次epoch，最好是将总体训练数据重新打乱、重新分成T组mini-batches，这样有利于训练出最佳的神经网络模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "① Batch gradient descent和Mini-batch gradient descent的cost曲线如下图所示："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "② 对于一般的神经网络模型，使用Batch gradient descent，随着迭代次数增加，cost是不断减小的。然而，使用Mini-batch gradient descent，随着在不同的mini-batch上迭代训练，其cost不是单调下降，而是受类似noise的影响，出现振荡。但整体的趋势是下降的，最终也能得到较低的cost值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "① 我们来比较一下Batch gradient descent和Stachastic gradient descent的梯度下降曲线。\n",
    "\n",
    "② 如下图所示，蓝色的线代表Batch gradient descent，紫色的线代表Stachastic gradient descent。\n",
    "\n",
    "③ Batch gradient descent会比较平稳地接近全局最小值，但是因为使用了所有m个样本，每次前进的速度有些慢。\n",
    "\n",
    "④ Stachastic gradient descent每次前进速度很快，但是路线曲折，有较大的振荡，最终会在最小值附近来回波动，难以真正达到最小值处。而且在数值处理上就不能使用向量化的方法来提高运算速度。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "① 实际使用中，mini-batch size不能设置得太大（Batch gradient descent），也不能设置得太小（Stachastic gradient descent）。\n",
    "\n",
    "② 这样，相当于结合了Batch gradient descent和Stachastic gradient descent各自的优点，既能使用向量化优化算法，又能较快速地找到最小值。\n",
    "\n",
    "③ mini-batch gradient descent的梯度下降曲线如下图绿色所示，每次前进速度较快，且振荡较小，基本能接近全局最小值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "① 一般来说，如果总体样本数量m不太大时，例如m≤2000m≤2000，建议直接使用Batch gradient descent。\n",
    "\n",
    "② 如果总体样本数量m很大时，建议将样本分成许多mini-batches。推荐常用的mini-batch size为64,128,256,512。这些都是2的幂。\n",
    "\n",
    "③ 之所以这样设置的原因是计算机存储数据一般是2的幂，这样设置可以提高运算速度。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 加权平均"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "① 该部分我们将介绍指数加权平均（Exponentially weighted averages）的概念。\n",
    "\n",
    "② 举个例子，记录半年内伦敦市的气温变化，并在二维平面上绘制出来，如下图所示："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "③ 看上去，温度数据似乎有noise，而且抖动较大。\n",
    "\n",
    "④ 如果我们希望看到半年内气温的整体变化趋势，可以通过移动平均（moving average）的方法来对每天气温进行平滑处理。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "① 例如我们可以设V0=0，当成第0天的气温值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "② 第一天的气温与第0天的气温有关："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "③ 第二天的气温与第一天的气温有关："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "④ 第三天的气温与第二天的气温有关："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "⑤ 即第t天与第t-1天的气温迭代关系为："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "⑥ 经过移动平均处理得到的气温如下图红色曲线所示："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "① 这种滑动平均算法称为指数加权平均（exponentially weighted average）。根据之前的推导公式，其一般形式为："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "② 上面的例子中，β=0.9。β值决定了指数加权平均的天数，近似表示为："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "① 这里简单解释一下公式1/(1−β)是怎么来的。准确来说，指数加权平均算法跟之前所有天的数值都有关系，根据之前的推导公式就能看出。\n",
    "\n",
    "② 但是指数是衰减的，一般认为衰减到1/e就可以忽略不计了。因此，根据之前的推导公式，我们只要证明下式就好了："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "③ 显然，当N>>0时，上述等式是近似成立的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "④ 至此，简单解释了为什么指数加权平均的天数的计算公式为1/(1−β)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "① 我们将指数加权平均公式的一般形式写下来："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "② 我们已经知道了指数加权平均的递推公式。实际应用中，为了减少内存的使用，我们可以使用这样的语句来实现指数加权平均算法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vθ=0\n",
    "Repeat {\n",
    "    Get next θt\n",
    "    Vθ:=βVθ+(1−β)θt\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "① 上文中提到当β=0.98时，指数加权平均结果如下图绿色曲线所示。但是实际上，真实曲线如紫色曲线所示。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "② 我们注意到，紫色曲线与绿色曲线的区别是，紫色曲线开始的时候相对较低一些。这是因为开始时我们设置V0=0，所以初始值会相对小一些，直到后面受前面的影响渐渐变小，趋于正常。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "③ 修正这种问题的方法是进行偏移校正（bias correction），即在每次计算完Vt后，对Vt进行下式处理："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "④ 值得一提的是，机器学习中，偏移校正并不是必须的。因为，在迭代一次次数后（t较大），Vt受初始值影响微乎其微，紫色曲线与绿色曲线基本重合。所以，一般可以忽略初始迭代过程，等到一定迭代之后再取值，这样就不需要进行偏移校正了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 动量梯度下降算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "① 该部分将介绍动量梯度下降算法，其速度要比传统的梯度下降算法快很多。做法是在每次训练时，对梯度进行指数加权平均处理，然后用得到的梯度值更新权重W和常数项b。下面介绍具体的实现过程。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "② 原始的梯度下降算法如上图蓝色折线所示。在梯度下降过程中，梯度下降的振荡较大，尤其对于W、b之间数值范围差别较大的情况。\n",
    "\n",
    "③ 此时每一点处的梯度只与当前方向有关，产生类似折线的效果，前进缓慢。而如果对梯度进行指数加权平均，这样使当前梯度不仅与当前方向有关，还与之前的方向有关，这样处理让梯度前进方向更加平滑，减少振荡，能够更快地到达最小值处。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "④ 权重W和常数项b的指数加权平均表达式如下："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "⑤ 从动量的角度来看，以权重W为例，Vdw可以成速度V，dW可以看成是加速度a。指数加权平均实际上是计算当前的速度，当前速度由之前的速度和现在的加速度共同影响。\n",
    "\n",
    "⑥ 而β<1，又能限制速度Vdw过大。也就是说，当前的速度是渐变的，而不是瞬变的，是动量的过程。这保证了梯度下降的平稳性和准确性，减少振荡，较快地达到最小值处。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "① 动量梯度下降算法的过程如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "On iteration t:\n",
    "    Compute dW, db on the current mini−batch\n",
    "    VdW=βVdw+(1−β)dW\n",
    "    Vdb=βVdb+(1−β)db\n",
    "    W=W−αVdw, b=b−αVdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "② 初始时，令Vdw=0,Vdb=0。一般设置β=0.9，即指数加权平均前10天的数据，实际应用效果较好。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "③ 另外，关于偏移校正，可以不使用。因为经过10次迭代后，随着滑动平均的过程，偏移情况会逐渐消失。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "④ 补充一下，在其它文献资料中，动量梯度下降还有另外一种写法："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "⑤ 即消去了dW和db前的系数(1−β)。这样简化了表达式，但是学习因子α相当于变成了α/(1−β)，表示α也受β的影响。从效果上来说，这种写法也是可以的，但是不够直观，且调参涉及到α，不够方便。所以，实际应用中，推荐第一种动量梯度下降的表达式。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. RMSprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "① RMSprop是另外一种优化梯度下降速度的算法。每次迭代训练过程中，其权重W和常数项b的更新表达式为："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "② 下面简单解释一下RMSprop算法的原理，仍然以下图为例，为了便于分析，令水平方向为W的方向，垂直方向为b的方向。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "③ 还有一点需要注意的是为了避免RMSprop算法中分母为零，通常可以在分母增加一个极小的常数ε："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "④ 其中，ε=10^−8，或者其它较小值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Adam优化算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "① Adam（Adaptive Moment Estimation）算法结合了动量梯度下降算法和RMSprop算法。其算法流程为："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "② 实际应用中，Adam算法结合了动量梯度下降和RMSprop各自的优点，使得神经网络训练速度大大提高。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. 学习率衰减"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "① 减小学习因子α也能有效提高神经网络训练速度，这种方法被称为learning rate decay。\n",
    "\n",
    "② Learning rate decay就是随着迭代次数增加，学习因子α逐渐减小。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "① 下面用图示的方式来解释这样做的好处。下图中，蓝色折线表示使用恒定的学习因子α，由于每次训练α相同，步进长度不变，在接近最优值处的振荡也大，在最优值附近较大范围内振荡，与最优值距离就比较远。\n",
    "\n",
    "② 绿色折线表示使用不断减小的α，随着训练次数增加，α逐渐减小，步进长度减小，使得能够在最优值处较小范围内微弱振荡，不断逼近最优值。相比较恒定的α来说，learning rate decay更接近最优值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "① Learning rate decay中对α可由下列公式得到："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "② 其中，deacy_rate是参数（可调），epoch是训练完所有样本的次数。随着epoch增加，α会不断变小。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "③ 除了上面计算α的公式之外，还有其它可供选择的计算公式："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "④ 其中，k为可调参数，t为mini-bach number。\n",
    "\n",
    "⑤ 除此之外，还可以设置α为关于t的离散值，随着t增加，α呈阶梯式减小。当然，也可以根据训练情况灵活调整当前的α值，但会比较耗时间。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. 局部最优问题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "① 在使用梯度下降算法不断减小cost function时，可能会得到局部最优解（local optima）而不是全局最优解（global optima）。\n",
    "\n",
    "② 之前我们对局部最优解的理解是形如碗状的凹槽，如下图左边所示。但是在神经网络中，local optima的概念发生了变化。\n",
    "\n",
    "③ 准确地来说，大部分梯度为零的“最优点”并不是这些凹槽处，而是形如右边所示的马鞍状，称为saddle point。\n",
    "\n",
    "④ 也就是说，梯度为零并不能保证都是convex（极小值），也有可能是concave（极大值）。\n",
    "\n",
    "⑤ 特别是在神经网络中参数很多的情况下，所有参数梯度为零的点很可能都是右边所示的马鞍状的saddle point，而不是左边那样的local optimum。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "① 类似马鞍状的plateaus会降低神经网络学习速度。Plateaus是梯度接近于零的平缓区域，如下图所示。在plateaus上梯度很小，前进缓慢，到达saddle point需要很长时间。\n",
    "\n",
    "② 到达saddle point后，由于随机扰动，梯度一般能够沿着图中绿色箭头，离开saddle point，继续前进，只是在plateaus上花费了太多时间。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "① 总的来说，关于local optima，有两点总结：\n",
    "\n",
    " - 只要选择合理的强大的神经网络，一般不太可能陷入local optima\n",
    " - Plateaus可能会使梯度下降变慢，降低学习速度\n",
    "\n",
    "② 值得一提的是，上文介绍的动量梯度下降，RMSprop，Adam算法都能有效解决plateaus下降过慢的问题，大大提高神经网络的学习速度。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.3",
   "language": "python",
   "name": "python3.6.3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "357.344px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}