#!/usr/bin/env python3
"""
深度优化所有Jupyter笔记本 - V2版本
针对每个知识点添加生活化的引入和实际应用场景
"""
import json
import os
import re
from pathlib import Path

# 知识点到生活场景的映射
CONCEPT_SCENARIOS = {
    # 数据处理相关
    "transforms": {
        "intro": "🎨 想象你在用美图秀秀修图",
        "scenario": """
## 📱 生活中的例子:修图App

你有没有用过美图秀秀、Instagram滤镜?

当你给照片加滤镜时,其实就是在做"Transform"(变换):
- 📐 **调整大小** - 把照片裁剪成正方形发朋友圈
- 🎨 **调整颜色** - 增加饱和度让照片更鲜艳
- 🔄 **旋转翻转** - 把横屏照片转成竖屏
- ✂️ **裁剪** - 去掉不想要的部分

**Transforms就是AI的"美图秀秀"!**

在深度学习中,我们需要把各种各样的图片(不同大小、不同格式)变成统一的格式,
就像你发朋友圈前要把照片处理成统一的尺寸一样。
""",
        "real_use": """
### 🌍 实际应用场景

1. **人脸识别(手机解锁)**
   - 你的脸可能在不同角度、不同光线下
   - Transform把所有照片调整到统一大小和亮度
   - 然后AI才能准确识别

2. **自动驾驶**
   - 摄像头拍到的图片需要统一处理
   - 白天、晚上、雨天的图片都要标准化
   - 才能让AI准确识别路标和行人

3. **医学影像**
   - CT、X光片需要统一格式
   - 才能让AI帮医生诊断疾病
"""
    },
    
    "totensor": {
        "intro": "🔢 把图片变成数字,让电脑能\"看懂\"",
        "scenario": """
## 🖼️ 为什么要把图片变成数字?

**问题:** 电脑看不懂图片,只认识数字!

想象一下:
- 你看到一张猫的照片,你知道这是猫
- 但电脑看到的只是一堆像素点
- 我们需要把这些像素点变成数字,电脑才能处理

### 📸 图片是怎么存储的?

一张彩色图片其实是由三层颜色组成的:
```
红色层(R) + 绿色层(G) + 蓝色层(B) = 彩色图片
```

每个像素的颜色用0-255的数字表示:
- 0 = 最暗(黑色)
- 255 = 最亮(白色)
- 128 = 中等亮度

### 🎯 ToTensor做什么?

把图片变成一个"数字魔方":
1. **读取图片** - 获取每个像素的RGB值(0-255)
2. **归一化** - 把0-255变成0-1之间的小数(除以255)
3. **重新排列** - 变成 [通道, 高度, 宽度] 的格式

**为什么要变成0-1?**
- 就像考试成绩统一用百分制,方便比较
- 0-1之间的数字更适合神经网络计算
- 避免数字太大导致计算出错
""",
        "real_use": """
### 🌍 实际应用

**手机相册的人脸识别:**
1. 你拍了100张照片
2. ToTensor把每张照片变成数字
3. AI分析这些数字,找出哪些照片里有人脸
4. 自动给照片分类

**淘宝拍照搜同款:**
1. 你拍一张衣服的照片
2. ToTensor把照片变成数字
3. AI在数据库里搜索相似的数字模式
4. 找到同款或相似的商品
"""
    },
    
    "线性回归": {
        "intro": "📈 预测未来,就像天气预报一样",
        "scenario": """
## 🌤️ 生活中的预测问题

### 场景1: 房价预测

你想买房,看到这些数据:
- 50平米的房子,卖100万
- 80平米的房子,卖160万
- 100平米的房子,卖200万

**问题:** 120平米的房子应该卖多少钱?

你会怎么想?
- "好像每平米2万元"
- "那120平米应该是240万"

**恭喜!你刚才做的就是线性回归!**

### 场景2: 学习时间与成绩

观察发现:
- 小明每天学习2小时,考了70分
- 小红每天学习4小时,考了80分
- 小刚每天学习6小时,考了90分

**问题:** 如果每天学习8小时,能考多少分?

你的大脑会自动找规律:
- 每多学2小时,多考10分
- 那8小时应该能考100分

**这就是线性回归的思维方式!**

## 🎯 什么是线性回归?

**用一句话说:** 找一条直线,让它尽可能穿过所有的点。

就像你用尺子在散点图上画一条"最合适"的直线:
```
成绩 = 起始分数 + 学习时间 × 每小时提升的分数
  y  =    b     +     x    ×        w
```

- **w (权重)** - 直线的斜率,表示x每变化1,y变化多少
- **b (偏置)** - 直线的起点,表示x=0时y的值
""",
        "real_use": """
### 🌍 实际应用场景

1. **外卖配送时间预测**
   - 输入:距离、天气、时段
   - 输出:预计送达时间
   - "您的外卖预计30分钟送达"

2. **股票价格预测**
   - 输入:历史价格、成交量
   - 输出:明天的价格趋势
   - 帮助投资决策

3. **电商销量预测**
   - 输入:价格、促销力度、季节
   - 输出:预计销量
   - 帮助商家备货

4. **身高体重预测**
   - 输入:身高
   - 输出:标准体重
   - 医疗健康建议

5. **能源消耗预测**
   - 输入:温度、时间、天气
   - 输出:用电量
   - 电网调度优化
"""
    },
    
    "优化算法": {
        "intro": "🎯 如何找到最佳答案?就像爬山找最高点",
        "scenario": """
## 🏔️ 爬山找最高点

想象你在一座大山上,被蒙上眼睛,要找到山顶:

**方法1: 随机乱走** ❌
- 可能永远找不到山顶
- 效率太低

**方法2: 感受脚下的坡度** ✅
- 如果脚下是上坡,继续往前走
- 如果脚下是下坡,换个方向
- 每次都往"最陡的上坡"方向走
- 最终能到达山顶

**这就是优化算法的思想!**

## 🎮 打游戏练级

玩RPG游戏时:
- **目标:** 让角色变得最强
- **方法:** 
  - 打怪升级(调整参数)
  - 装备升级(优化策略)
  - 技能加点(选择方向)

每次战斗后:
- 如果赢了,说明方向对了,继续这样练
- 如果输了,说明需要调整策略

**AI训练就是这样"练级"的!**

## 🎯 什么是优化算法?

**用一句话说:** 不断尝试,找到让结果最好的那组参数。

就像调音量:
- 音量太小 → 往上调
- 音量太大 → 往下调
- 直到找到最舒服的音量

在AI中:
- 预测不准 → 调整参数
- 越来越准 → 继续这个方向
- 直到找到最佳参数
""",
        "real_use": """
### 🌍 实际应用场景

1. **导航软件找最短路径**
   - 输入:起点、终点、实时路况
   - 优化目标:时间最短或距离最短
   - 输出:最佳路线

2. **外卖平台配送优化**
   - 输入:多个订单、骑手位置
   - 优化目标:总配送时间最短
   - 输出:每个骑手的配送顺序

3. **广告投放优化**
   - 输入:用户特征、广告内容
   - 优化目标:点击率最高
   - 输出:给谁看什么广告

4. **游戏AI**
   - 输入:当前游戏状态
   - 优化目标:获胜概率最大
   - 输出:下一步操作

5. **推荐系统**
   - 输入:用户历史行为
   - 优化目标:用户满意度最高
   - 输出:推荐内容列表
"""
    },
    
    "损失函数": {
        "intro": "📊 如何知道AI学得好不好?就像考试打分",
        "scenario": """
## 📝 考试打分系统

想象你是老师,批改学生的试卷:

**学生的答案 vs 标准答案:**
- 完全正确 → 0分扣分(满分)
- 稍有偏差 → 扣5分
- 差距很大 → 扣20分
- 完全错误 → 扣50分

**扣分越少,说明学得越好!**

这就是损失函数的作用:
- 预测值 = 学生答案
- 真实值 = 标准答案
- 损失 = 扣分

## 🎯 射箭比赛

射箭时:
- 射中靶心(10环) → 损失 = 0(完美!)
- 射中9环 → 损失 = 1(很接近)
- 射中5环 → 损失 = 5(还行)
- 脱靶 → 损失 = 10(太差了)

**AI训练就是不断练习,让"损失"越来越小!**

## 🍕 外卖送达时间预测

外卖平台预测送达时间:
- 预测30分钟,实际30分钟 → 损失 = 0(完美)
- 预测30分钟,实际35分钟 → 损失 = 5(还行)
- 预测30分钟,实际60分钟 → 损失 = 30(太差,用户要投诉!)

**损失越小,用户越满意!**
""",
        "real_use": """
### 🌍 实际应用场景

1. **人脸识别**
   - 损失函数:识别错误的次数
   - 目标:让错误率降到0.1%以下
   - 应用:手机解锁、门禁系统

2. **语音识别**
   - 损失函数:识别错误的字数
   - 目标:让准确率达到95%以上
   - 应用:语音助手、字幕生成

3. **自动驾驶**
   - 损失函数:偏离车道的距离
   - 目标:让车始终在车道中央
   - 应用:特斯拉自动驾驶

4. **推荐系统**
   - 损失函数:用户不喜欢的推荐数量
   - 目标:让用户点击率最高
   - 应用:抖音、淘宝推荐

5. **图像生成**
   - 损失函数:生成图片与真实图片的差异
   - 目标:让生成的图片以假乱真
   - 应用:AI绘画、照片修复
"""
    },
    
    "卷积": {
        "intro": "🔍 用放大镜扫描图片,找特征",
        "scenario": """
## 🔍 用放大镜看报纸

想象你在看一份报纸,想找"优惠券":

**方法1: 一个字一个字看** ❌
- 太慢了!

**方法2: 用放大镜快速扫描** ✅
- 放大镜只看一小块区域
- 从左到右、从上到下扫描
- 看到"优惠"两个字就停下来
- 找到所有优惠券的位置

**这就是卷积的工作方式!**

## 🎮 找茬游戏

玩"找不同"游戏时:
- 你不会看整张图
- 而是用眼睛扫描每个小区域
- 对比两张图的对应位置
- 找出不同的地方

**AI用卷积"看"图片,也是这样扫描的!**

## 📱 手机扫描二维码

扫二维码时:
- 摄像头不是看整个画面
- 而是在画面中找"正方形的黑白格子"
- 找到后才开始解码

**卷积就是AI的"模式识别器"!**
""",
        "real_use": """
### 🌍 实际应用场景

1. **人脸识别**
   - 第1层卷积:找边缘(轮廓)
   - 第2层卷积:找五官(眼睛、鼻子、嘴巴)
   - 第3层卷积:识别整张脸
   - 应用:手机解锁、刷脸支付

2. **自动驾驶**
   - 卷积找车道线
   - 卷积找车辆
   - 卷积找行人
   - 卷积找交通标志
   - 应用:特斯拉、百度Apollo

3. **医学影像**
   - 卷积找肿瘤
   - 卷积找骨折
   - 卷积找病变区域
   - 应用:辅助医生诊断

4. **照片美化**
   - 卷积找人脸
   - 卷积磨皮美白
   - 卷积瘦脸大眼
   - 应用:美图秀秀、抖音滤镜

5. **文字识别(OCR)**
   - 卷积找文字区域
   - 卷积识别每个字
   - 应用:扫描全能王、拍照翻译
"""
    },
    
    "池化": {
        "intro": "📉 压缩图片但保留重要信息",
        "scenario": """
## 📱 微信发照片

你拍了一张4K高清照片(4000×3000像素):
- 原图太大,发送很慢
- 微信自动压缩成1000×750
- 但你还是能看清照片内容

**这就是池化的作用!**

## 🗺️ 地图缩放

打开地图App:
- 放大看:能看到每条街道、每个门牌号
- 缩小看:只看到主要道路和地标

**缩小地图时,细节消失了,但重要信息还在!**

池化就是这样:
- 把图片变小
- 保留最重要的特征
- 减少计算量

## 👀 人眼的"池化"

你看一张照片:
- 不会记住每个像素
- 只记住重要的内容:"一个人在海边"
- 大脑自动"池化"了不重要的细节

**AI也要学会抓重点!**
""",
        "real_use": """
### 🌍 实际应用场景

1. **监控摄像头实时分析**
   - 场景: 商场、地铁站的安防监控
   - 应用: 每秒30帧的4K视频,池化后快速分析
   - 效果: 实时检测可疑人员、异常行为
   - 案例: 深圳地铁使用AI监控,识别率99%,响应时间<1秒

2. **手机相册智能管理**
   - 场景: iPhone、华为手机的相册
   - 应用: 池化压缩照片生成缩略图
   - 效果: 快速浏览上千张照片不卡顿
   - 案例: iPhone相册可以流畅浏览10万+张照片

3. **自动驾驶实时决策**
   - 场景: 特斯拉Autopilot系统
   - 应用: 8个摄像头拍摄高清视频,池化提取关键信息
   - 效果: 毫秒级识别障碍物并做出反应
   - 案例: 特斯拉FSD每秒处理2300帧图像

4. **刷脸支付快速识别**
   - 场景: 支付宝、微信刷脸支付
   - 应用: 池化人脸图像,只保留关键特征
   - 效果: 0.3秒完成识别和支付
   - 案例: 全国已有超过100万台刷脸支付设备

5. **淘宝拍照搜同款**
   - 场景: 淘宝、京东的图片搜索
   - 应用: 池化生成商品"指纹",在亿级数据库中快速匹配
   - 效果: 1秒内找到相似商品
   - 案例: 淘宝每天处理1亿+次拍照搜索,准确率90%+
"""
    },
    
    "激活函数": {
        "intro": "⚡ 给神经网络加上\"开关\",让它能学习复杂模式",
        "scenario": """
## 🎮 游戏角色的技能触发

玩游戏时,角色的技能不是随时都能用:
- 血量>50% → 可以使用普通技能
- 血量<30% → 触发\"绝地反击\"
- 能量满了 → 可以放大招

**这些条件判断就像激活函数!**

## 🚦 红绿灯系统

红绿灯的逻辑:
- 车流量很小 → 绿灯(通行)
- 车流量很大 → 红灯(等待)
- 车流量适中 → 根据情况调整

**激活函数就是神经网络的"红绿灯"!**

## 🎚️ 音量调节

调节音量时:
- 音量<0 → 静音(输出0)
- 音量0-100 → 正常输出
- 音量>100 → 最大音量(限制在100)

**激活函数控制神经元的输出范围!**
""",
        "real_use": """
### 🌍 实际应用场景

1. **图像识别(人脸解锁)**
   - 场景: 手机人脸解锁
   - 应用: ReLU激活函数让网络学习人脸特征
   - 效果: 准确识别是不是机主,防止照片解锁
   - 案例: Face ID错误率仅百万分之一

2. **语音助手(Siri、小爱)**
   - 场景: 智能音箱语音识别
   - 应用: Sigmoid激活函数判断是否是唤醒词
   - 效果: 准确识别"Hey Siri",过滤其他声音
   - 案例: 小爱同学日均唤醒超1亿次

3. **推荐系统(抖音、淘宝)**
   - 场景: 视频、商品推荐
   - 应用: Softmax激活函数计算每个内容的推荐概率
   - 效果: 推荐你最可能喜欢的内容
   - 案例: 抖音推荐准确率让用户平均停留100分钟/天

4. **自动驾驶(障碍物检测)**
   - 场景: 特斯拉自动驾驶
   - 应用: Leaky ReLU让网络学习复杂的道路场景
   - 效果: 准确识别车辆、行人、交通标志
   - 案例: Waymo无人车已安全行驶超2000万英里

5. **医疗诊断(肺癌筛查)**
   - 场景: CT影像分析
   - 应用: ELU激活函数提高诊断准确率
   - 效果: 辅助医生发现早期肺癌
   - 案例: AI诊断准确率达94%,接近资深医生水平
"""
    },
    
    "反向传播": {
        "intro": "🔄 从错误中学习,就像考试后订正错题",
        "scenario": """
## 📝 考试后的错题订正

考完试后:
1. 老师批改试卷,标出错题
2. 你看到哪里错了
3. 分析为什么错
4. 下次遇到类似题就不会错了

**这就是反向传播的过程!**

## 🎯 射箭练习

练习射箭:
1. 射出一箭,偏离靶心
2. 教练告诉你:"偏左了10cm"
3. 你调整姿势,往右瞄一点
4. 再射一箭,越来越准

**反向传播就是AI的"教练"!**

## 🚗 学开车

学车时:
- 方向盘打多了 → 教练说"回一点"
- 油门踩重了 → 教练说"轻一点"
- 刹车踩晚了 → 教练说"提前刹车"

**通过不断纠错,你学会了开车!**
""",
        "real_use": """
### 🌍 实际应用场景

1. **AlphaGo学下围棋**
   - 场景: 谷歌AlphaGo对战世界冠军
   - 应用: 通过反向传播从3000万局棋谱中学习
   - 效果: 击败世界冠军李世石、柯洁
   - 案例: AlphaGo Zero从零开始,3天超越人类千年积累

2. **自动驾驶学习驾驶**
   - 场景: 特斯拉Autopilot训练
   - 应用: 从数十亿英里真实驾驶数据中学习
   - 效果: 每次事故后更新模型,越来越安全
   - 案例: 特斯拉事故率仅为人类驾驶的1/10

3. **语音识别学说话**
   - 场景: 训练Siri、小爱等语音助手
   - 应用: 从数百万小时语音数据中学习
   - 效果: 识别准确率从60%提升到95%+
   - 案例: 科大讯飞语音识别准确率达98%

4. **机器翻译学语言**
   - 场景: Google翻译、DeepL
   - 应用: 从数十亿句对照翻译中学习
   - 效果: 翻译质量接近专业译员
   - 案例: DeepL被评为最好的机器翻译工具

5. **AI画画学艺术**
   - 场景: Midjourney、Stable Diffusion
   - 应用: 从数十亿张图片中学习绘画
   - 效果: 生成以假乱真的艺术作品
   - 案例: Midjourney生成的画作获得艺术比赛一等奖
"""
    }
}

def get_concept_intro(filename, title):
    """根据文件名和标题获取生活化引入"""
    filename_lower = filename.lower()
    title_lower = title.lower()
    
    # 检查是否匹配已定义的概念
    for concept, content in CONCEPT_SCENARIOS.items():
        if concept.lower() in filename_lower or concept.lower() in title_lower:
            return content
    
    # 默认引入 - 根据标题生成更具体的应用场景
    default_apps = generate_default_applications(title)
    
    return {
        "intro": "🎯 让我们从实际问题出发",
        "scenario": f"""
## 💭 开始之前,想想这个问题

学习 **{title}** 能帮我们解决什么实际问题?

在日常生活中,你可能已经在不知不觉中使用了这个技术:
- 📱 手机App
- 🎮 游戏
- 🛒 网购
- 📺 视频推荐

让我们一起探索这个技术背后的原理!
""",
        "real_use": default_apps
    }

def generate_default_applications(title):
    """为没有预定义的概念生成通用但具体的应用场景"""
    title_lower = title.lower()
    
    # 根据关键词匹配生成应用
    if any(word in title_lower for word in ['数据', 'data', 'loader', '加载']):
        return """
### 🌍 实际应用场景

1. **图像识别系统**
   - 场景: 医院的CT扫描图像诊断系统
   - 应用: 每天需要加载和处理成千上万张医学影像
   - 效果: 帮助医生快速发现肺结节、骨折等病变
   - 案例: 某三甲医院使用AI辅助诊断,准确率达95%

2. **自动驾驶训练**
   - 场景: 特斯拉、百度Apollo等自动驾驶系统
   - 应用: 需要加载数百万张道路图片进行训练
   - 效果: 让AI学会识别车辆、行人、交通标志
   - 案例: Waymo已经在美国多个城市提供无人出租车服务

3. **人脸识别门禁**
   - 场景: 小区门禁、公司考勤系统
   - 应用: 实时加载和比对人脸数据
   - 效果: 刷脸开门,0.3秒识别,准确率99.9%
   - 案例: 全国已有超过10万个小区使用人脸识别门禁

4. **短视频推荐**
   - 场景: 抖音、快手等短视频平台
   - 应用: 每秒加载处理数百万个视频帧
   - 效果: 分析你的喜好,推荐你可能喜欢的视频
   - 案例: 抖音日活用户超6亿,每天推荐数十亿次

5. **电商商品识别**
   - 场景: 淘宝拍照搜同款功能
   - 应用: 快速加载和比对商品图片数据库
   - 效果: 拍张照片就能找到同款或相似商品
   - 案例: 淘宝每天处理超过1亿次拍照搜索
"""
    
    elif any(word in title_lower for word in ['模型', 'model', '网络', 'network']):
        return """
### 🌍 实际应用场景

1. **智能客服机器人**
   - 场景: 淘宝、京东的在线客服
   - 应用: 使用训练好的模型理解用户问题并回答
   - 效果: 24小时在线,秒回消息,解决率80%+
   - 案例: 阿里小蜜每天服务超过1000万用户

2. **语音助手**
   - 场景: Siri、小爱同学、天猫精灵
   - 应用: 语音识别模型+自然语言理解模型
   - 效果: 听懂你说的话,执行各种指令
   - 案例: 全球智能音箱出货量超2亿台

3. **照片美化**
   - 场景: 美图秀秀、抖音滤镜
   - 应用: 使用模型自动磨皮、瘦脸、美白
   - 效果: 一键美颜,效果自然
   - 案例: 美图秀秀月活用户超3亿

4. **游戏AI**
   - 场景: 王者荣耀、和平精英的AI对手
   - 应用: 训练模型让AI像人一样玩游戏
   - 效果: AI能做出合理的战术决策
   - 案例: OpenAI的Dota2 AI击败世界冠军

5. **智能推荐**
   - 场景: 网易云音乐、B站的推荐系统
   - 应用: 模型分析你的喜好,推荐内容
   - 效果: 越用越懂你,推荐越来越准
   - 案例: 抖音推荐算法让用户平均停留时长超100分钟/天
"""
    
    elif any(word in title_lower for word in ['训练', 'train', '验证', 'valid']):
        return """
### 🌍 实际应用场景

1. **垃圾分类识别**
   - 场景: 上海等城市的智能垃圾桶
   - 应用: 训练模型识别垃圾类型(可回收/有害/厨余/其他)
   - 效果: 自动分类,准确率95%+
   - 案例: 上海已部署超过1000个智能垃圾分类点

2. **农作物病虫害识别**
   - 场景: 农业种植基地
   - 应用: 训练模型识别农作物的病虫害
   - 效果: 农民拍照上传,AI秒速诊断并给出治疗方案
   - 案例: 拼多多"多多农研科技大赛"用AI种草莓

3. **工业质检**
   - 场景: 手机、汽车等生产线
   - 应用: 训练模型检测产品缺陷(划痕、裂纹等)
   - 效果: 比人眼更快更准,24小时不休息
   - 案例: 富士康使用AI质检,效率提升10倍

4. **金融风控**
   - 场景: 支付宝、微信的转账风控
   - 应用: 训练模型识别异常交易和诈骗行为
   - 效果: 实时拦截可疑交易,保护用户资金
   - 案例: 支付宝每年拦截数十亿次风险交易

5. **内容审核**
   - 场景: 抖音、B站的视频审核
   - 应用: 训练模型识别违规内容(暴力、色情等)
   - 效果: 自动过滤99%的违规内容
   - 案例: 抖音每天审核超过10亿条内容
"""
    
    else:
        # 通用应用场景
        return """
### 🌍 实际应用场景

1. **手机拍照优化**
   - 场景: iPhone、华为等手机的AI拍照
   - 应用: 自动识别场景(人像/风景/美食),优化参数
   - 效果: 随手一拍就是大片
   - 案例: 华为P系列手机的AI摄影获得多项大奖

2. **智能家居**
   - 场景: 小米、华为的智能家居系统
   - 应用: 学习你的生活习惯,自动调节空调、灯光
   - 效果: 回家前自动开空调,睡觉时自动关灯
   - 案例: 小米IoT平台连接设备超5亿台

3. **在线教育**
   - 场景: 作业帮、猿辅导的拍照搜题
   - 应用: 拍下题目,AI自动识别并给出解答
   - 效果: 秒出答案和详细解析
   - 案例: 作业帮月活用户超1.7亿

4. **健康监测**
   - 场景: Apple Watch、小米手环的健康监测
   - 应用: 分析心率、睡眠、运动数据
   - 效果: 及时发现健康异常,提醒就医
   - 案例: Apple Watch曾多次救人性命

5. **智能翻译**
   - 场景: 有道翻译、Google翻译
   - 应用: 实时翻译语音和文字
   - 效果: 出国旅游不再担心语言不通
   - 案例: 有道翻译支持100+种语言互译
"""

def create_enhanced_intro(filename, title, category):
    """创建增强版的课程引入"""
    concept_content = get_concept_intro(filename, title)
    
    intro_cell = {
        "cell_type": "markdown",
        "metadata": {},
        "source": [
            f"# {title}\n",
            "\n",
            f"**分类:** {category}\n",
            "\n",
            f"**{concept_content['intro']}**\n",
            "\n",
            "---\n",
            "\n",
            concept_content['scenario'],
            "\n",
            "---\n",
            "\n",
            "## 🎯 本节课你将学会\n",
            "\n",
            "- ✅ 理解核心概念和原理\n",
            "- ✅ 掌握实际代码实现\n",
            "- ✅ 知道如何应用到实际项目\n",
            "- ✅ 理解这个技术解决什么问题\n",
            "\n",
            "## 💡 学习建议\n",
            "\n",
            "1. **先理解\"为什么\"** - 这个技术解决什么实际问题?\n",
            "2. **再学习\"是什么\"** - 这个技术的原理是什么?\n",
            "3. **最后掌握\"怎么做\"** - 如何用代码实现?\n",
            "4. **动手实践** - 运行代码,修改参数,观察结果\n",
            "\n",
            "---\n",
            "\n"
        ]
    }
    
    return intro_cell

def create_real_world_section(filename, title):
    """创建实际应用章节"""
    concept_content = get_concept_intro(filename, title)
    
    real_world_cell = {
        "cell_type": "markdown",
        "metadata": {},
        "source": [
            "---\n",
            "\n",
            concept_content['real_use'],
            "\n",
            "---\n",
            "\n"
        ]
    }
    
    return real_world_cell

def enhance_notebook(notebook_path, category):
    """增强单个笔记本"""
    try:
        with open(notebook_path, 'r', encoding='utf-8') as f:
            notebook = json.load(f)
        
        if not notebook.get('cells'):
            return False
        
        filename = os.path.basename(notebook_path)
        title = extract_title_from_filename(filename)
        
        # 检查是否已经增强过
        first_cell = notebook['cells'][0]
        if first_cell['cell_type'] == 'markdown':
            content = ''.join(first_cell['source'])
            if '💭 开始之前,想想这个问题' in content or '生活中的例子' in content:
                print(f"  ✓ {filename} 已经增强过")
                return False
        
        # 创建增强版引入
        intro_cell = create_enhanced_intro(filename, title, category)
        
        # 创建实际应用章节
        real_world_cell = create_real_world_section(filename, title)
        
        # 插入引入(替换第一个cell或在开头插入)
        if notebook['cells'] and notebook['cells'][0]['cell_type'] == 'markdown':
            # 如果第一个是标题cell,替换它
            first_content = ''.join(notebook['cells'][0]['source'])
            if first_content.strip().startswith('#') and len(first_content.strip().split('\n')) <= 3:
                notebook['cells'][0] = intro_cell
            else:
                notebook['cells'].insert(0, intro_cell)
        else:
            notebook['cells'].insert(0, intro_cell)
        
        # 在最后添加实际应用章节(在总结之前)
        # 找到总结的位置
        summary_index = -1
        for i, cell in enumerate(notebook['cells']):
            if cell['cell_type'] == 'markdown':
                content = ''.join(cell['source'])
                if '总结' in content or '小结' in content:
                    summary_index = i
                    break
        
        if summary_index > 0:
            notebook['cells'].insert(summary_index, real_world_cell)
        else:
            # 在倒数第二个位置插入
            notebook['cells'].insert(-1, real_world_cell)
        
        # 保存
        with open(notebook_path, 'w', encoding='utf-8') as f:
            json.dump(notebook, f, ensure_ascii=False, indent=1)
        
        print(f"  ✓ {filename} 增强完成")
        return True
        
    except Exception as e:
        print(f"  ✗ {filename} 增强失败: {e}")
        return False

def extract_title_from_filename(filename):
    """从文件名提取标题"""
    name = filename.replace('.ipynb', '')
    name = re.sub(r'^\d+_', '', name)
    return name

def categorize_notebook(filename):
    """分类笔记本"""
    keywords_map = {
        "基础入门": ["配置", "安装", "Python", "Pytorch", "START"],
        "数据处理": ["数据", "Dataloader", "Transforms", "预处理", "增广"],
        "神经网络基础": ["感知机", "线性", "激活", "损失", "优化器", "反向传播", "回归"],
        "卷积神经网络": ["卷积", "池化", "LeNet", "AlexNet", "VGG", "ResNet", "GoogLeNet"],
        "循环神经网络": ["RNN", "LSTM", "GRU", "序列", "循环"],
        "注意力机制": ["注意力", "Transformer", "BERT", "seq2seq"],
        "计算机视觉": ["检测", "分割", "识别", "风格迁移", "目标检测"],
        "实战项目": ["Kaggle", "竞赛", "实战", "项目"],
        "高级主题": ["分布式", "GPU", "TPU", "微调", "RAG", "大模型"],
    }
    
    filename_lower = filename.lower()
    for category, keywords in keywords_map.items():
        for keyword in keywords:
            if keyword.lower() in filename_lower:
                return category
    return "其他"

def main():
    """主函数"""
    notebooks_dir = Path('/Users/h/practice/CV-main')
    
    print("🚀 开始深度优化笔记本(V2版本)...\n")
    print("📝 本次优化重点:")
    print("   - 添加生活化的引入")
    print("   - 解释\"这是什么,能干啥\"")
    print("   - 联系实际应用场景")
    print("   - 理论联系实际\n")
    
    # 获取所有笔记本文件
    notebook_files = [f for f in os.listdir(notebooks_dir) 
                     if f.endswith('.ipynb') and not f.endswith('_backup.ipynb')]
    
    print(f"找到 {len(notebook_files)} 个笔记本文件\n")
    
    # 增强每个笔记本
    success_count = 0
    for notebook_file in sorted(notebook_files):
        notebook_path = notebooks_dir / notebook_file
        category = categorize_notebook(notebook_file)
        if enhance_notebook(notebook_path, category):
            success_count += 1
    
    print(f"\n✅ 优化完成! 成功增强 {success_count} 个笔记本")
    print("\n🎉 现在所有课程都:")
    print("   ✓ 从实际问题出发")
    print("   ✓ 用生活化的例子解释")
    print("   ✓ 包含实际应用场景")
    print("   ✓ 理论联系实际")

if __name__ == "__main__":
    main()
