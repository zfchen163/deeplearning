#!/usr/bin/env python3
"""
æ‰¹é‡ä¼˜åŒ–æ‰€æœ‰Jupyterç¬”è®°æœ¬,ä½¿å…¶æ›´é€‚åˆé«˜ä¸­ç”Ÿå­¦ä¹ 
"""
import json
import os
import re
from pathlib import Path

# ç¬”è®°æœ¬åˆ†ç±»å’Œä¼˜åŒ–è§„åˆ™
NOTEBOOK_CATEGORIES = {
    "åŸºç¡€å…¥é—¨": {
        "keywords": ["é…ç½®", "å®‰è£…", "Python", "Pytorch", "START"],
        "intro": "ğŸš€ ä»é›¶å¼€å§‹,æ­å»ºä½ çš„æ·±åº¦å­¦ä¹ ç¯å¢ƒ"
    },
    "æ•°æ®å¤„ç†": {
        "keywords": ["æ•°æ®", "Dataloader", "Transforms", "é¢„å¤„ç†", "å¢å¹¿"],
        "intro": "ğŸ“Š æ•°æ®æ˜¯AIçš„ç‡ƒæ–™,å­¦ä¼šå¤„ç†æ•°æ®æ˜¯ç¬¬ä¸€æ­¥"
    },
    "ç¥ç»ç½‘ç»œåŸºç¡€": {
        "keywords": ["æ„ŸçŸ¥æœº", "çº¿æ€§", "æ¿€æ´»", "æŸå¤±", "ä¼˜åŒ–å™¨", "åå‘ä¼ æ’­"],
        "intro": "ğŸ§  ç†è§£ç¥ç»ç½‘ç»œçš„åŸºæœ¬ç»„ä»¶"
    },
    "å·ç§¯ç¥ç»ç½‘ç»œ": {
        "keywords": ["å·ç§¯", "æ± åŒ–", "LeNet", "AlexNet", "VGG", "ResNet", "GoogLeNet"],
        "intro": "ğŸ–¼ï¸ è®©è®¡ç®—æœº\"çœ‹æ‡‚\"å›¾ç‰‡çš„ç§˜å¯†æ­¦å™¨"
    },
    "å¾ªç¯ç¥ç»ç½‘ç»œ": {
        "keywords": ["RNN", "LSTM", "GRU", "åºåˆ—", "å¾ªç¯"],
        "intro": "ğŸ”„ å¤„ç†æ—¶é—´åºåˆ—å’Œæ–‡æœ¬çš„ç¥ç»ç½‘ç»œ"
    },
    "æ³¨æ„åŠ›æœºåˆ¶": {
        "keywords": ["æ³¨æ„åŠ›", "Transformer", "BERT", "seq2seq"],
        "intro": "ğŸ‘€ è®©AIå­¦ä¼š\"å…³æ³¨é‡ç‚¹\""
    },
    "è®¡ç®—æœºè§†è§‰": {
        "keywords": ["æ£€æµ‹", "åˆ†å‰²", "è¯†åˆ«", "é£æ ¼è¿ç§»", "ç›®æ ‡æ£€æµ‹"],
        "intro": "ğŸ‘ï¸ å›¾åƒè¯†åˆ«ã€ç‰©ä½“æ£€æµ‹ç­‰è§†è§‰ä»»åŠ¡"
    },
    "å®æˆ˜é¡¹ç›®": {
        "keywords": ["Kaggle", "ç«èµ›", "å®æˆ˜", "é¡¹ç›®"],
        "intro": "ğŸ’ª çœŸå®é¡¹ç›®å®æˆ˜,æ£€éªŒå­¦ä¹ æˆæœ"
    },
    "é«˜çº§ä¸»é¢˜": {
        "keywords": ["åˆ†å¸ƒå¼", "GPU", "TPU", "å¾®è°ƒ", "RAG", "å¤§æ¨¡å‹"],
        "intro": "ğŸš€ è¿›é˜¶æŠ€æœ¯å’Œå‰æ²¿åº”ç”¨"
    }
}

def categorize_notebook(filename):
    """æ ¹æ®æ–‡ä»¶ååˆ¤æ–­ç¬”è®°æœ¬ç±»åˆ«"""
    filename_lower = filename.lower()
    
    for category, info in NOTEBOOK_CATEGORIES.items():
        for keyword in info["keywords"]:
            if keyword.lower() in filename_lower:
                return category
    
    return "å…¶ä»–"

def extract_title_from_filename(filename):
    """ä»æ–‡ä»¶åæå–æ ‡é¢˜"""
    # ç§»é™¤.ipynbåç¼€
    name = filename.replace('.ipynb', '')
    # ç§»é™¤æ•°å­—å‰ç¼€(å¦‚ 109_)
    name = re.sub(r'^\d+_', '', name)
    return name

def add_friendly_intro(notebook_path):
    """ä¸ºç¬”è®°æœ¬æ·»åŠ å‹å¥½çš„å¼•è¨€"""
    try:
        with open(notebook_path, 'r', encoding='utf-8') as f:
            notebook = json.load(f)
        
        if not notebook.get('cells'):
            return False
        
        filename = os.path.basename(notebook_path)
        title = extract_title_from_filename(filename)
        category = categorize_notebook(filename)
        category_intro = NOTEBOOK_CATEGORIES.get(category, {}).get("intro", "")
        
        # æ£€æŸ¥ç¬¬ä¸€ä¸ªcellæ˜¯å¦å·²ç»æ˜¯å‹å¥½çš„å¼•è¨€
        first_cell = notebook['cells'][0]
        if first_cell['cell_type'] == 'markdown':
            content = ''.join(first_cell['source'])
            if 'ğŸ¯' in content or 'å¼€å§‹ä¹‹å‰' in content:
                print(f"  âœ“ {filename} å·²ç»ä¼˜åŒ–è¿‡")
                return False
        
        # åˆ›å»ºæ–°çš„å¼•è¨€cell
        intro_cell = {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                f"# {title}\n",
                "\n",
                f"**åˆ†ç±»:** {category}\n",
                "\n",
                f"**ç®€ä»‹:** {category_intro}\n",
                "\n",
                "---\n",
                "\n",
                "## ğŸ¯ å­¦ä¹ ç›®æ ‡\n",
                "\n",
                "é€šè¿‡æœ¬èŠ‚è¯¾,ä½ å°†å­¦ä¼š:\n",
                "- ç†è§£æ ¸å¿ƒæ¦‚å¿µå’ŒåŸç†\n",
                "- æŒæ¡å®é™…ä»£ç å®ç°\n",
                "- èƒ½å¤Ÿåº”ç”¨åˆ°å®é™…é¡¹ç›®ä¸­\n",
                "\n",
                "## ğŸ’¡ å­¦ä¹ å»ºè®®\n",
                "\n",
                "1. **å…ˆçœ‹æ‡‚åŸç†** - ä¸è¦æ€¥ç€è¿è¡Œä»£ç \n",
                "2. **åŠ¨æ‰‹å®è·µ** - æ¯ä¸ªä»£ç å—éƒ½è¿è¡Œä¸€é\n",
                "3. **ä¿®æ”¹å‚æ•°** - è¯•è¯•æ”¹å˜å‚æ•°ä¼šå‘ç”Ÿä»€ä¹ˆ\n",
                "4. **åšç¬”è®°** - è®°å½•ä½ çš„ç†è§£å’Œç–‘é—®\n",
                "\n",
                "---\n",
                "\n"
            ]
        }
        
        # åœ¨å¼€å¤´æ’å…¥å¼•è¨€
        notebook['cells'].insert(0, intro_cell)
        
        # åœ¨ç»“å°¾æ·»åŠ æ€»ç»“(å¦‚æœæ²¡æœ‰çš„è¯)
        last_cell = notebook['cells'][-1]
        last_content = ''.join(last_cell['source']) if last_cell.get('source') else ''
        
        if 'æ€»ç»“' not in last_content and 'å°ç»“' not in last_content:
            summary_cell = {
                "cell_type": "markdown",
                "metadata": {},
                "source": [
                    "---\n",
                    "\n",
                    "## ğŸ“š æœ¬èŠ‚å°ç»“\n",
                    "\n",
                    "æ­å–œä½ å®Œæˆäº†æœ¬èŠ‚å­¦ä¹ !è®©æˆ‘ä»¬å›é¡¾ä¸€ä¸‹:\n",
                    "\n",
                    "### âœ… ä½ å­¦åˆ°äº†ä»€ä¹ˆ?\n",
                    "- è¯·åœ¨è¿™é‡Œå†™ä¸‹ä½ çš„æ”¶è·...\n",
                    "\n",
                    "### ğŸ¤” è¿˜æœ‰ç–‘é—®?\n",
                    "- è¯·è®°å½•ä¸‹ä½ ä¸ç†è§£çš„åœ°æ–¹...\n",
                    "\n",
                    "### ğŸš€ ä¸‹ä¸€æ­¥\n",
                    "- ç»§ç»­å­¦ä¹ ç›¸å…³ä¸»é¢˜\n",
                    "- å°è¯•åšä¸€äº›ç»ƒä¹ é¢˜\n",
                    "- åº”ç”¨åˆ°å®é™…é¡¹ç›®ä¸­\n",
                    "\n",
                    "---\n",
                    "\n",
                    "**è®°ä½:** å­¦ä¹ æ˜¯ä¸€ä¸ªå¾ªåºæ¸è¿›çš„è¿‡ç¨‹,ä¸è¦ç€æ€¥,æ…¢æ…¢æ¥! ğŸ’ª\n"
                ]
            }
            notebook['cells'].append(summary_cell)
        
        # ä¿å­˜ä¿®æ”¹
        with open(notebook_path, 'w', encoding='utf-8') as f:
            json.dump(notebook, f, ensure_ascii=False, indent=1)
        
        print(f"  âœ“ {filename} ä¼˜åŒ–å®Œæˆ")
        return True
        
    except Exception as e:
        print(f"  âœ— {filename} ä¼˜åŒ–å¤±è´¥: {e}")
        return False

def generate_index(notebooks_dir):
    """ç”Ÿæˆè¯¾ç¨‹ç´¢å¼•"""
    notebooks = []
    
    for file in sorted(os.listdir(notebooks_dir)):
        if file.endswith('.ipynb') and not file.endswith('_backup.ipynb'):
            category = categorize_notebook(file)
            title = extract_title_from_filename(file)
            
            # æå–æ•°å­—å‰ç¼€ä½œä¸ºé¡ºåº
            match = re.match(r'^(\d+)_', file)
            order = int(match.group(1)) if match else 999
            
            notebooks.append({
                "filename": file,
                "title": title,
                "category": category,
                "order": order
            })
    
    # æŒ‰ç±»åˆ«å’Œé¡ºåºåˆ†ç»„
    categorized = {}
    for nb in notebooks:
        cat = nb['category']
        if cat not in categorized:
            categorized[cat] = []
        categorized[cat].append(nb)
    
    # ç”ŸæˆMarkdownç´¢å¼•
    index_md = "# æ·±åº¦å­¦ä¹ è¯¾ç¨‹ç´¢å¼•\n\n"
    index_md += "## ğŸ“– è¯¾ç¨‹å¤§çº²\n\n"
    
    for category in NOTEBOOK_CATEGORIES.keys():
        if category in categorized:
            index_md += f"\n### {category}\n\n"
            index_md += f"*{NOTEBOOK_CATEGORIES[category]['intro']}*\n\n"
            
            for nb in sorted(categorized[category], key=lambda x: x['order']):
                index_md += f"- [{nb['title']}]({nb['filename']})\n"
    
    # å…¶ä»–ç±»åˆ«
    if "å…¶ä»–" in categorized:
        index_md += f"\n### å…¶ä»–\n\n"
        for nb in sorted(categorized["å…¶ä»–"], key=lambda x: x['order']):
            index_md += f"- [{nb['title']}]({nb['filename']})\n"
    
    return index_md, categorized

def main():
    """ä¸»å‡½æ•°"""
    notebooks_dir = Path('/Users/h/practice/CV-main')
    
    print("ğŸš€ å¼€å§‹æ‰¹é‡ä¼˜åŒ–ç¬”è®°æœ¬...\n")
    
    # è·å–æ‰€æœ‰ç¬”è®°æœ¬æ–‡ä»¶
    notebook_files = [f for f in os.listdir(notebooks_dir) 
                     if f.endswith('.ipynb') and not f.endswith('_backup.ipynb')]
    
    print(f"æ‰¾åˆ° {len(notebook_files)} ä¸ªç¬”è®°æœ¬æ–‡ä»¶\n")
    
    # ä¼˜åŒ–æ¯ä¸ªç¬”è®°æœ¬
    success_count = 0
    for notebook_file in sorted(notebook_files):
        notebook_path = notebooks_dir / notebook_file
        if add_friendly_intro(notebook_path):
            success_count += 1
    
    print(f"\nâœ… ä¼˜åŒ–å®Œæˆ! æˆåŠŸä¼˜åŒ– {success_count} ä¸ªç¬”è®°æœ¬")
    
    # ç”Ÿæˆç´¢å¼•
    print("\nğŸ“š ç”Ÿæˆè¯¾ç¨‹ç´¢å¼•...")
    index_md, categorized = generate_index(notebooks_dir)
    
    index_path = notebooks_dir / "COURSE_INDEX.md"
    with open(index_path, 'w', encoding='utf-8') as f:
        f.write(index_md)
    
    print(f"âœ… ç´¢å¼•å·²ç”Ÿæˆ: {index_path}")
    
    # ç”ŸæˆJSONæ ¼å¼çš„ç´¢å¼•(ä¾›å‰ç«¯ä½¿ç”¨)
    index_json = {
        "categories": list(NOTEBOOK_CATEGORIES.keys()),
        "notebooks": categorized
    }
    
    json_path = notebooks_dir / "course_index.json"
    with open(json_path, 'w', encoding='utf-8') as f:
        json.dump(index_json, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… JSONç´¢å¼•å·²ç”Ÿæˆ: {json_path}")
    
    print("\nğŸ‰ æ‰€æœ‰ä»»åŠ¡å®Œæˆ!")

if __name__ == "__main__":
    main()
