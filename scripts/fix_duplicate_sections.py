#!/usr/bin/env python3
"""
ä¿®å¤ç¬”è®°æœ¬ä¸­é‡å¤çš„å­¦ä¹ ç›®æ ‡å’Œå­¦ä¹ å»ºè®®éƒ¨åˆ†
"""
import json
import os
from pathlib import Path

def remove_duplicate_sections(notebook_path):
    """ç§»é™¤ç¬”è®°æœ¬ä¸­é‡å¤çš„å­¦ä¹ ç›®æ ‡å’Œå»ºè®®"""
    try:
        with open(notebook_path, 'r', encoding='utf-8') as f:
            notebook = json.load(f)
        
        if not notebook.get('cells'):
            return False
        
        filename = os.path.basename(notebook_path)
        cells = notebook['cells']
        modified = False
        
        # æ‰¾åˆ°æ‰€æœ‰åŒ…å«å­¦ä¹ ç›®æ ‡çš„cell
        learning_goal_indices = []
        for i, cell in enumerate(cells):
            if cell['cell_type'] == 'markdown':
                content = ''.join(cell['source'])
                if 'ğŸ¯ æœ¬èŠ‚è¯¾ä½ å°†å­¦ä¼š' in content or 'ğŸ¯ å­¦ä¹ ç›®æ ‡' in content:
                    learning_goal_indices.append(i)
        
        # å¦‚æœæœ‰å¤šä¸ªå­¦ä¹ ç›®æ ‡éƒ¨åˆ†,åªä¿ç•™ç¬¬ä¸€ä¸ª
        if len(learning_goal_indices) > 1:
            # ä»åå¾€å‰åˆ é™¤,é¿å…ç´¢å¼•å˜åŒ–
            for idx in reversed(learning_goal_indices[1:]):
                del cells[idx]
                modified = True
            print(f"  âœ“ {filename} - åˆ é™¤äº† {len(learning_goal_indices)-1} ä¸ªé‡å¤çš„å­¦ä¹ ç›®æ ‡")
        
        # æ‰¾åˆ°æ‰€æœ‰åŒ…å«å­¦ä¹ å»ºè®®çš„cell
        learning_tips_indices = []
        for i, cell in enumerate(cells):
            if cell['cell_type'] == 'markdown':
                content = ''.join(cell['source'])
                if 'ğŸ’¡ å­¦ä¹ å»ºè®®' in content and 'å…ˆç†è§£"ä¸ºä»€ä¹ˆ"' in content:
                    learning_tips_indices.append(i)
        
        # å¦‚æœæœ‰å¤šä¸ªå­¦ä¹ å»ºè®®éƒ¨åˆ†,åªä¿ç•™ç¬¬ä¸€ä¸ª
        if len(learning_tips_indices) > 1:
            for idx in reversed(learning_tips_indices[1:]):
                del cells[idx]
                modified = True
            print(f"  âœ“ {filename} - åˆ é™¤äº† {len(learning_tips_indices)-1} ä¸ªé‡å¤çš„å­¦ä¹ å»ºè®®")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰è¿ç»­çš„é‡å¤å†…å®¹
        i = 0
        while i < len(cells) - 1:
            if cells[i]['cell_type'] == 'markdown' and cells[i+1]['cell_type'] == 'markdown':
                content1 = ''.join(cells[i]['source'])
                content2 = ''.join(cells[i+1]['source'])
                
                # å¦‚æœä¸¤ä¸ªcellå†…å®¹ç›¸ä¼¼åº¦å¾ˆé«˜(å¯èƒ½æ˜¯é‡å¤)
                if content1 == content2:
                    del cells[i+1]
                    modified = True
                    print(f"  âœ“ {filename} - åˆ é™¤äº†é‡å¤çš„cell")
                    continue
            i += 1
        
        if modified:
            # ä¿å­˜ä¿®æ”¹
            notebook['cells'] = cells
            with open(notebook_path, 'w', encoding='utf-8') as f:
                json.dump(notebook, f, ensure_ascii=False, indent=1)
            return True
        else:
            print(f"  - {filename} - æ²¡æœ‰å‘ç°é‡å¤å†…å®¹")
            return False
        
    except Exception as e:
        print(f"  âœ— {filename} - å¤„ç†å¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    notebooks_dir = Path('/Users/h/practice/CV-main')
    
    print("ğŸ”§ å¼€å§‹ä¿®å¤é‡å¤çš„å­¦ä¹ ç›®æ ‡å’Œå»ºè®®...\n")
    
    # è·å–æ‰€æœ‰ç¬”è®°æœ¬æ–‡ä»¶
    notebook_files = [f for f in os.listdir(notebooks_dir) 
                     if f.endswith('.ipynb') and not f.endswith('_backup.ipynb')]
    
    print(f"æ‰¾åˆ° {len(notebook_files)} ä¸ªç¬”è®°æœ¬æ–‡ä»¶\n")
    
    # ä¿®å¤æ¯ä¸ªç¬”è®°æœ¬
    fixed_count = 0
    for notebook_file in sorted(notebook_files):
        notebook_path = notebooks_dir / notebook_file
        if remove_duplicate_sections(notebook_path):
            fixed_count += 1
    
    print(f"\nâœ… ä¿®å¤å®Œæˆ! ä¿®æ”¹äº† {fixed_count} ä¸ªç¬”è®°æœ¬")
    print("\nğŸ‰ ç°åœ¨æ¯ä¸ªç¬”è®°æœ¬åªæœ‰ä¸€ä»½å­¦ä¹ ç›®æ ‡å’Œå»ºè®®äº†!")

if __name__ == "__main__":
    main()
