# ğŸ’¼ çœŸå®åœºæ™¯æ¡ˆä¾‹ - ä½ ä¼šé‡åˆ°çš„é—®é¢˜

**è¿™é‡Œè®²çš„éƒ½æ˜¯ä»é›¶å¼€å§‹çš„äººçœŸå®ä¼šé‡åˆ°çš„é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆã€‚**

---

## æ¡ˆä¾‹1ï¼šæˆ‘æœ‰ä¸€å †å›¾ç‰‡ï¼Œæƒ³åˆ†ç±»

**çœŸå®åœºæ™¯**ï¼šä½ æœ‰100ä¸ªçŒ«çš„å›¾ç‰‡ï¼Œ200ä¸ªç‹—çš„å›¾ç‰‡ï¼Œæƒ³è®­ç»ƒä¸ªæ¨¡å‹åŒºåˆ†ã€‚

### æ­¥éª¤1ï¼šæŠŠæ•°æ®æ•´ç†æˆè¿™æ ·
```
data/
â”œâ”€â”€ cat/
â”‚   â”œâ”€â”€ 001.jpg
â”‚   â”œâ”€â”€ 002.jpg
â”‚   â””â”€â”€ ...
â””â”€â”€ dog/
    â”œâ”€â”€ 001.jpg
    â”œâ”€â”€ 002.jpg
    â””â”€â”€ ...
```

### æ­¥éª¤2ï¼šå†™ä¸ªç®€å•çš„æ•°æ®åŠ è½½å™¨
```python
import os
import cv2
import numpy as np
from pathlib import Path

# åŠ è½½æ‰€æœ‰å›¾ç‰‡
def load_data():
    X, y = [], []
    labels = {'cat': 0, 'dog': 1}
    
    for label_name, label_id in labels.items():
        folder = f'data/{label_name}'
        for img_name in os.listdir(folder):
            img = cv2.imread(f'{folder}/{img_name}')
            if img is not None:
                img = cv2.resize(img, (224, 224))  # ç»Ÿä¸€å¤§å°
                X.append(img)
                y.append(label_id)
    
    return np.array(X), np.array(y)

X, y = load_data()
print(f"åŠ è½½äº† {len(X)} å¼ å›¾ç‰‡")
```

### æ­¥éª¤3ï¼šç”¨æˆ‘çš„ä»£ç è®­ç»ƒ
```python
from production_code_examples import CustomDataset, ResNet18Classifier, Trainer, AdvancedOptimizer
from torch.utils.data import DataLoader, random_split
import torch

# åˆ›å»ºæ•°æ®é›†
dataset = CustomDataset(X, y)

# åˆ†å‰²æˆè®­ç»ƒå’ŒéªŒè¯
train_size = int(0.8 * len(dataset))
val_size = len(dataset) - train_size
train_dataset, val_dataset = random_split(dataset, [train_size, val_size])

# åˆ›å»ºDataLoader
train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=16)

# åˆ›å»ºæ¨¡å‹
model = ResNet18Classifier(num_classes=2)

# åˆ›å»ºä¼˜åŒ–å™¨
optimizer = AdvancedOptimizer.get_optimizer(model, 'adamw', lr=1e-3)

# è®­ç»ƒ
trainer = Trainer(model, device='cuda')
trainer.train(train_loader, val_loader, num_epochs=50, optimizer=optimizer, 
              loss_fn=torch.nn.CrossEntropyLoss())
```

### æ­¥éª¤4ï¼šç”¨æ¨¡å‹é¢„æµ‹
```python
# æµ‹è¯•å›¾ç‰‡
test_img = cv2.imread('test_cat.jpg')
test_img = cv2.resize(test_img, (224, 224))
test_img = torch.FloatTensor(test_img).unsqueeze(0).to('cuda')

model.eval()
with torch.no_grad():
    output = model(test_img)
    pred = output.argmax(1)
    
print(f"é¢„æµ‹ç»“æœ: {'cat' if pred == 0 else 'dog'}")
```

**ä¸ºä»€ä¹ˆè¿™æ ·åš**ï¼š
- âœ… æ•°æ®æ¸…æ™°æœ‰åº
- âœ… ä»£ç ç®€å•æ˜“æ‡‚
- âœ… èƒ½å¿«é€Ÿè¯•éªŒ

**å¯èƒ½é‡åˆ°çš„é—®é¢˜**ï¼š
- å›¾ç‰‡å¤§å°ä¸ä¸€æ ·ï¼Ÿ â†’ ç”¨ `cv2.resize` ç»Ÿä¸€
- å†…å­˜ä¸å¤Ÿï¼Ÿ â†’ å‡å°batch_size
- ç²¾åº¦ä¸å¥½ï¼Ÿ â†’ å¢åŠ æ•°æ®æˆ–è®­ç»ƒæ›´ä¹…

---

## æ¡ˆä¾‹2ï¼šæˆ‘æƒ³ç”¨é¢„è®­ç»ƒæ¨¡å‹ï¼Œä½†ä¸çŸ¥é“æ€ä¹ˆç”¨

**çœŸå®åœºæ™¯**ï¼šä½ å¬è¯´ç”¨ImageNeté¢„è®­ç»ƒçš„æ¨¡å‹èƒ½æ›´å¿«æ”¶æ•›ï¼Œä½†ä¸çŸ¥é“æ€ä¹ˆç”¨ã€‚

### é”™çš„åšæ³• âŒ
```python
# ä¸è¦è¿™æ ·åšï¼Œè¿™æ ·æ˜¯é‡æ–°è®­ç»ƒ
model = ResNet18Classifier(pretrained=False)
```

### å¯¹çš„åšæ³• âœ…
```python
from production_code_examples import ResNet18Classifier

# ç”¨é¢„è®­ç»ƒçš„æƒé‡ï¼ˆå·²ç»å­¦è¿‡å¾ˆå¤šç‰¹å¾ï¼‰
model = ResNet18Classifier(num_classes=2, pretrained=True)

# ç„¶åç›´æ¥è®­ç»ƒ
# å› ä¸ºåº•å±‚å·²ç»æœ‰äº†å¥½çš„ç‰¹å¾ï¼Œåªéœ€è¦å¾®è°ƒé¡¶å±‚
```

**ä¸ºä»€ä¹ˆè¿™æ ·åš**ï¼š
- é¢„è®­ç»ƒæ¨¡å‹å·²ç»å­¦ä¼šäº†è¯†åˆ«è¾¹ç¼˜ã€çº¹ç†ç­‰åŸºæœ¬ç‰¹å¾
- ä½ åªéœ€è¦è®©å®ƒå­¦ä¼šåŒºåˆ†ä½ çš„æ•°æ®
- æ”¶æ•›å¿«10å€ï¼Œç²¾åº¦ä¹Ÿæ›´å¥½

**è¿›é˜¶ï¼šåªå¾®è°ƒéƒ¨åˆ†å±‚**
```python
# å†»ç»“åº•å±‚ï¼ˆä¸è®­ç»ƒï¼‰
for name, param in model.backbone.named_parameters():
    if 'layer3' not in name and 'layer4' not in name:
        param.requires_grad = False

# è¿™æ ·åªè®­ç»ƒåä¸¤å±‚ï¼Œæ›´å¿«
```

---

## æ¡ˆä¾‹3ï¼šæˆ‘çš„æ¨¡å‹è¿‡æ‹Ÿåˆäº†

**çœŸå®åœºæ™¯**ï¼šè®­ç»ƒç²¾åº¦99%ï¼Œæµ‹è¯•ç²¾åº¦50%ã€‚æ€ä¹ˆåŠï¼Ÿ

### ç¬¬1æ­¥ï¼šç¡®è®¤çœŸçš„è¿‡æ‹Ÿåˆäº†
```python
# çœ‹ä¸¤æ¡çº¿
# å¦‚æœè®­ç»ƒæ›²çº¿æŒç»­ä¸‹é™ï¼Œä½†éªŒè¯æ›²çº¿å¼€å§‹ä¸Šå‡ â†’ è¿‡æ‹Ÿåˆ

import matplotlib.pyplot as plt
plt.plot(train_losses, label='train')
plt.plot(val_losses, label='val')
plt.legend()
plt.show()
```

### ç¬¬2æ­¥ï¼šè§£å†³æ–¹æ¡ˆï¼ˆæŒ‰é¡ºåºè¯•ï¼‰

**æ–¹æ¡ˆ1ï¼šåŠ Dropout** âœ… æœ€ç®€å•
```yaml
# æ”¹config_example.yaml
regularization_config:
  use_dropout: true
  dropout_rate: 0.5  # å¢åŠ åˆ°0.7è¯•è¯•
```

**æ–¹æ¡ˆ2ï¼šåŠ L2æ­£åˆ™åŒ–**
```yaml
regularization_config:
  use_weight_decay: true
  weight_decay: 1e-4  # ä»1e-5æ”¹æˆ1e-4
```

**æ–¹æ¡ˆ3ï¼šæ—©åœ** âœ… æœ€å®ç”¨
```yaml
early_stopping_config:
  enabled: true
  patience: 5  # 5ä¸ªepochæ²¡è¿›æ­¥å°±åœ
```

**æ–¹æ¡ˆ4ï¼šåŠ æ•°æ®å¢å¼º** âœ… æ•ˆæœæœ€å¥½ï¼ˆä½†éœ€è¦ä»£ç æ”¹ï¼‰
```python
# åœ¨CustomDatasetä¸­åŠ ä¸Šæ•°æ®å¢å¼º
import torchvision.transforms as transforms

transform = transforms.Compose([
    transforms.RandomRotation(10),  # éšæœºæ—‹è½¬
    transforms.RandomHorizontalFlip(),  # éšæœºç¿»è½¬
    transforms.ColorJitter(brightness=0.2),  # éšæœºè°ƒæ•´äº®åº¦
])
```

**æ–¹æ¡ˆ5ï¼šæ›´å¤šæ•°æ®** âœ… ç»ˆæè§£å†³
- å¦‚æœæ•°æ®å¤ªå°‘ï¼ˆ<1000å¼ ï¼‰ï¼Œå¢åŠ æ•°æ®ä¼šæœ‰æ˜æ˜¾å¸®åŠ©
- å¯ä»¥åšæ•°æ®å¢å¼ºã€çˆ¬è™«ã€æˆ–æ ‡æ³¨

---

## æ¡ˆä¾‹4ï¼šæˆ‘è¦å‚åŠ Kaggleç«èµ›

**çœŸå®åœºæ™¯**ï¼šä½ æƒ³è¯•è¯•Kaggleçš„æ¯”èµ›ï¼Œä½†ä»æ¥æ²¡å‚åŠ è¿‡ã€‚

### æ­¥éª¤1ï¼šä¸‹è½½æ•°æ®
```bash
# Kaggleæä¾›äº†å‘½ä»¤è¡Œå·¥å…·
kaggle competitions download -c [ç«èµ›å]
```

### æ­¥éª¤2ï¼šå¿«é€Ÿæ£€æŸ¥æ•°æ®
```python
import pandas as pd
import numpy as np

# çœ‹çœ‹æ•°æ®é•¿å•¥æ ·
train_df = pd.read_csv('train.csv')
print(train_df.head())
print(train_df.shape)
print(train_df.info())

# çœ‹çœ‹æœ‰æ²¡æœ‰ç¼ºå¤±å€¼
print(train_df.isnull().sum())
```

### æ­¥éª¤3ï¼šç”¨æˆ‘çš„ä»£ç å¿«é€Ÿå»ºç«‹baseline
```python
from production_code_examples import *
import torch

# 1. è¯»å–æ•°æ®
X_train = np.load('train_images.npy')
y_train = np.load('train_labels.npy')

# 2. åˆ›å»ºæ•°æ®é›†å’ŒDataLoader
dataset = CustomDataset(X_train, y_train)
train_loader = DataLoader(dataset, batch_size=32)

# 3. è®­ç»ƒ
model = ResNet18Classifier(num_classes=10)  # æ”¹æˆå¯¹åº”çš„ç±»åˆ«æ•°
optimizer = AdvancedOptimizer.get_optimizer(model, 'adamw')
trainer = Trainer(model)
trainer.train(train_loader, val_loader, num_epochs=20, optimizer=optimizer)

# 4. é¢„æµ‹
X_test = np.load('test_images.npy')
test_dataset = CustomDataset(X_test, np.zeros(len(X_test)))
test_loader = DataLoader(test_dataset, batch_size=32)

predictions = []
model.eval()
with torch.no_grad():
    for images, _ in test_loader:
        outputs = model(images.to('cuda'))
        preds = outputs.argmax(1).cpu().numpy()
        predictions.extend(preds)

# 5. æäº¤
submission = pd.DataFrame({
    'id': range(len(predictions)),
    'target': predictions
})
submission.to_csv('submission.csv', index=False)
```

**KaggleæŠ€å·§**ï¼š
1. å…ˆå»ºç«‹baselineï¼ˆå¿«é€Ÿè·‘ä¸ªç‰ˆæœ¬ï¼‰
2. å†ä¼˜åŒ–ï¼ˆè°ƒå‚ã€åŠ ç‰¹å¾ã€é›†æˆç­‰ï¼‰
3. çœ‹æ’è¡Œæ¦œï¼Œå‚è€ƒåˆ«äººçš„æ€è·¯

---

## æ¡ˆä¾‹5ï¼šæˆ‘è®­ç»ƒäº†ä¸€ä¸ªæ¨¡å‹ï¼Œè¦ç”¨å®ƒåšç”Ÿäº§é¢„æµ‹

**çœŸå®åœºæ™¯**ï¼šä½ è¦æŠŠæ¨¡å‹éƒ¨ç½²åˆ°æœåŠ¡å™¨æˆ–æ‰‹æœºä¸Šã€‚

### æ­¥éª¤1ï¼šä¿å­˜æœ€å¥½çš„æ¨¡å‹
```python
# è®­ç»ƒè¿‡ç¨‹ä¸­è‡ªåŠ¨ä¿å­˜ï¼ˆç”¨æˆ‘çš„Trainerï¼‰
# æˆ–æ‰‹åŠ¨ä¿å­˜
torch.save(model.state_dict(), 'best_model.pt')
```

### æ­¥éª¤2ï¼šéƒ¨ç½²åˆ°FlaskæœåŠ¡å™¨
```python
from flask import Flask, request, jsonify
import torch
from production_code_examples import ResNet18Classifier
import numpy as np
import cv2

app = Flask(__name__)

# åŠ è½½æ¨¡å‹
model = ResNet18Classifier(num_classes=10)
model.load_state_dict(torch.load('best_model.pt'))
model.eval()

@app.route('/predict', methods=['POST'])
def predict():
    # è·å–ä¸Šä¼ çš„å›¾ç‰‡
    file = request.files['image']
    img = cv2.imdecode(np.fromfile(file), cv2.IMREAD_COLOR)
    img = cv2.resize(img, (224, 224))
    
    # é¢„å¤„ç†
    img = torch.FloatTensor(img).unsqueeze(0).to('cuda')
    
    # é¢„æµ‹
    with torch.no_grad():
        output = model(img)
        pred = output.argmax(1).item()
    
    return jsonify({'prediction': int(pred)})

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000)
```

### æ­¥éª¤3ï¼šç”¨Pythonè°ƒç”¨
```python
import requests
from PIL import Image

# ä¸Šä¼ å›¾ç‰‡å¹¶è·å¾—é¢„æµ‹
with open('test.jpg', 'rb') as f:
    response = requests.post('http://localhost:5000/predict', 
                            files={'image': f})
    print(response.json())
```

---

## æ¡ˆä¾‹6ï¼šæˆ‘çš„æ•°æ®æ˜¯CSVæ ¼å¼ï¼Œä¸æ˜¯å›¾ç‰‡

**çœŸå®åœºæ™¯**ï¼šä½ çš„æ•°æ®æ˜¯è¡¨æ ¼ï¼ˆCSVï¼‰ï¼Œæ¯”å¦‚è‚¡ç¥¨æ•°æ®ã€åŒ»ç–—æ•°æ®ç­‰ã€‚

### æ­¥éª¤1ï¼šè¯»å–æ•°æ®
```python
import pandas as pd
import numpy as np

df = pd.read_csv('data.csv')

# åˆ†ç¦»ç‰¹å¾å’Œæ ‡ç­¾
X = df.drop('target', axis=1).values
y = df['target'].values

print(f"ç‰¹å¾æ•°: {X.shape[1]}")
print(f"æ ·æœ¬æ•°: {X.shape[0]}")
```

### æ­¥éª¤2ï¼šæ”¹æ•°æ®åŠ è½½å™¨
```python
from production_code_examples import CustomDataset
from torch.utils.data import DataLoader
import torch

# å½’ä¸€åŒ–ï¼ˆå¾ˆé‡è¦ï¼ï¼‰
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X = scaler.fit_transform(X)

# åˆ›å»ºæ•°æ®é›†
dataset = CustomDataset(X.astype(np.float32), y)
train_loader = DataLoader(dataset, batch_size=32, shuffle=True)
```

### æ­¥éª¤3ï¼šæ”¹æ¨¡å‹
```python
import torch.nn as nn

class TabularModel(nn.Module):
    def __init__(self, input_size, num_classes):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(input_size, 128),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(64, num_classes)
        )
    
    def forward(self, x):
        return self.net(x)

model = TabularModel(input_size=X.shape[1], num_classes=2)
```

**ä¸ºä»€ä¹ˆè¦æ”¹**ï¼š
- è¡¨æ ¼æ•°æ®ä¸éœ€è¦CNNï¼Œç”¨å…¨è¿æ¥å±‚å°±è¡Œ
- è¦å¯¹æ•°æ®åšå½’ä¸€åŒ–
- ç½‘ç»œå¯ä»¥æ›´æµ…

---

## æ¡ˆä¾‹7ï¼šæˆ‘æƒ³ç”¨å¤šGPUè®­ç»ƒ

**çœŸå®åœºæ™¯**ï¼šä½ æœ‰å¤šå¼ æ˜¾å¡ï¼Œæƒ³åŠ é€Ÿè®­ç»ƒã€‚

### æ­¥éª¤1ï¼šæ”¹ä»£ç ï¼ˆä¸€è¡Œè§£å†³ï¼‰
```python
import torch.nn as nn
from torch.nn.parallel import DataParallel

model = ResNet18Classifier(num_classes=10)
model = DataParallel(model)  # å°±è¿™ä¸€è¡Œ

# ç„¶åæ­£å¸¸è®­ç»ƒ
trainer = Trainer(model, device='cuda')
```

### æ­¥éª¤2ï¼šçœ‹çœ‹å·¥ä½œæ²¡
```bash
# æŸ¥çœ‹GPUä½¿ç”¨æƒ…å†µ
nvidia-smi

# åº”è¯¥çœ‹åˆ°ä¸¤å¼ GPUéƒ½åœ¨å·¥ä½œ
```

**ä¸ºä»€ä¹ˆè¿™æ ·åš**ï¼š
- batchä¼šè‡ªåŠ¨åˆ†åˆ°å¤šå¼ GPU
- é€Ÿåº¦æ¥è¿‘çº¿æ€§å¢é•¿ï¼ˆ2å¼ GPUå¤§æ¦‚å¿«2å€ï¼‰
- ä»£ç æ”¹åŠ¨æœ€å°

---

## ğŸ’¡ è¿™äº›æ¡ˆä¾‹çš„è§„å¾‹

**è®°ä½è¿™ä¸ªæµç¨‹ï¼Œ99%çš„æ·±åº¦å­¦ä¹ é—®é¢˜éƒ½èƒ½è§£å†³**ï¼š

```
1. æ•°æ®å‡†å¤‡
   â†“
2. æ•°æ®åŠ è½½ï¼ˆå¯èƒ½éœ€è¦æ”¹CustomDatasetï¼‰
   â†“
3. é€‰æ¨¡å‹ï¼ˆResNet / CNN / å…¨è¿æ¥å±‚ ç­‰ï¼‰
   â†“
4. é€‰ä¼˜åŒ–å™¨ï¼ˆä¸€èˆ¬ç”¨Adamï¼‰
   â†“
5. è®­ç»ƒï¼ˆç”¨æˆ‘çš„Traineræˆ–è‡ªå·±å†™è®­ç»ƒå¾ªç¯ï¼‰
   â†“
6. è¯„ä¼°ï¼ˆçœ‹ç²¾åº¦ã€lossç­‰æŒ‡æ ‡ï¼‰
   â†“
7. å¦‚æœä¸å¥½ â†’ å›åˆ°ç¬¬1æˆ–4é‡æ–°è°ƒæ•´
   â†“
8. éƒ¨ç½²ï¼ˆä¿å­˜æ¨¡å‹ã€å¯èƒ½è¦æ”¹æˆONNXç­‰ï¼‰
```

---

**ç°åœ¨ä½ åº”è¯¥èƒ½å¤„ç†å¤§éƒ¨åˆ†å®é™…é—®é¢˜äº†ã€‚** ğŸ‰

*ç”Ÿæˆæ—¶é—´: 2026-01-27*  
*éƒ½æ˜¯ä»é›¶å¼€å§‹ä¼šé‡åˆ°çš„çœŸå®åœºæ™¯*
