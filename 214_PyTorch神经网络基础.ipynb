{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorchç¥ç»ç½‘ç»œåŸºç¡€\n",
    "\n",
    "**åˆ†ç±»:** åŸºç¡€å…¥é—¨\n",
    "\n",
    "**ğŸ§  è®­ç»ƒAIå°±åƒæ•™å°å­©,éœ€è¦è€å¿ƒå’Œæ–¹æ³•**\n",
    "\n",
    "---\n",
    "\n",
    "\n## ğŸ“ æ•™å°å­©å­¦ä¹ \n\næ•™å°å­©æ—¶:\n- **ç¬¬ä¸€æ­¥**: å‘Šè¯‰ä»–è¿™æ˜¯ä»€ä¹ˆ(è¾“å…¥)\n- **ç¬¬äºŒæ­¥**: å‘Šè¯‰ä»–åº”è¯¥æ€ä¹ˆåš(ç›®æ ‡)\n- **ç¬¬ä¸‰æ­¥**: ä»–åšé”™äº†,çº æ­£ä»–(æŸå¤±å‡½æ•°)\n- **ç¬¬å››æ­¥**: é‡å¤ç»ƒä¹ ,è¶Šæ¥è¶Šç†Ÿç»ƒ(è®­ç»ƒ)\n\n**è®­ç»ƒAIæ¨¡å‹å°±åƒæ•™å°å­©!**\n\n### ğŸ¯ ä¸ºä»€ä¹ˆéœ€è¦è®­ç»ƒ?\n\n**é—®é¢˜:** AIä¸€å¼€å§‹ä»€ä¹ˆéƒ½ä¸ä¼š\n- å°±åƒåˆšå‡ºç”Ÿçš„å©´å„¿\n- éœ€è¦å­¦ä¹ æ‰èƒ½å˜èªæ˜\n- è®­ç»ƒå°±æ˜¯\"æ•™\"AIå­¦ä¹ \n\n**æ–¹æ³•:** é€šè¿‡å¤§é‡æ•°æ®è®­ç»ƒ\n- ç»™AIçœ‹å¾ˆå¤šä¾‹å­\n- å‘Šè¯‰AIæ­£ç¡®ç­”æ¡ˆ\n- AIæ…¢æ…¢å­¦ä¼šè§„å¾‹\n\n### ğŸ“š å¾ªåºæ¸è¿›å­¦ä¹ \n\n**ç¬¬ä¸€æ­¥: ç†è§£é—®é¢˜** (ä½ ç°åœ¨åœ¨è¿™é‡Œ)\n- ä¸ºä»€ä¹ˆéœ€è¦è®­ç»ƒ?\n- å¦‚ä½•è®­ç»ƒ?\n\n**ç¬¬äºŒæ­¥: å­¦ä¹ è®­ç»ƒæ–¹æ³•** (æ¥ä¸‹æ¥)\n- å¦‚ä½•è®¾è®¡æŸå¤±å‡½æ•°?\n- å¦‚ä½•ä¼˜åŒ–å‚æ•°?\n\n**ç¬¬ä¸‰æ­¥: å®é™…åº”ç”¨** (æœ€å)\n- å¦‚ä½•è®­ç»ƒè‡ªå·±çš„æ¨¡å‹?\n- å¦‚ä½•è¯„ä¼°æ•ˆæœ?\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ æœ¬èŠ‚è¯¾ä½ å°†å­¦ä¼š\n",
    "\n",
    "- âœ… ç†è§£æ ¸å¿ƒæ¦‚å¿µå’ŒåŸç†\n",
    "- âœ… æŒæ¡å®é™…ä»£ç å®ç°\n",
    "- âœ… çŸ¥é“å¦‚ä½•åº”ç”¨åˆ°å®é™…é¡¹ç›®\n",
    "- âœ… ç†è§£è¿™ä¸ªæŠ€æœ¯è§£å†³ä»€ä¹ˆé—®é¢˜\n",
    "\n",
    "## ğŸ’¡ å­¦ä¹ å»ºè®®\n",
    "\n",
    "1. **å…ˆç†è§£\"ä¸ºä»€ä¹ˆ\"** - è¿™ä¸ªæŠ€æœ¯è§£å†³ä»€ä¹ˆå®é™…é—®é¢˜?\n",
    "2. **å†å­¦ä¹ \"æ˜¯ä»€ä¹ˆ\"** - è¿™ä¸ªæŠ€æœ¯çš„åŸç†æ˜¯ä»€ä¹ˆ?\n",
    "3. **æœ€åæŒæ¡\"æ€ä¹ˆåš\"** - å¦‚ä½•ç”¨ä»£ç å®ç°?\n",
    "4. **åŠ¨æ‰‹å®è·µ** - è¿è¡Œä»£ç ,ä¿®æ”¹å‚æ•°,è§‚å¯Ÿç»“æœ\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "",
    "## ğŸ”° æ–°æ‰‹å¿…çœ‹",
    "",
    "**ç¬¬ä¸€æ¬¡å­¦ï¼Ÿè¿™äº›æç¤ºèƒ½å¸®åˆ°ä½ ï¼**",
    "",
    "### ğŸ’¡ å­¦ä¹ å»ºè®®",
    "",
    "1. **ä¸è¦æ€¥** - æ…¢æ…¢çœ‹ï¼Œä¸æ‡‚çš„å¤šçœ‹å‡ é",
    "2. **åŠ¨æ‰‹åš** - æ¯ä¸ªä»£ç éƒ½è¿è¡Œä¸€é",
    "3. **æ”¹å‚æ•°** - è¯•ç€æ”¹æ”¹æ•°å­—ï¼Œçœ‹çœ‹ä¼šæ€æ ·",
    "4. **è®°ç¬”è®°** - æŠŠé‡ç‚¹è®°ä¸‹æ¥",
    "",
    "### âš ï¸ å¸¸è§é—®é¢˜",
    "",
    "**Q: ä»£ç æŠ¥é”™æ€ä¹ˆåŠï¼Ÿ**",
    "- å…ˆçœ‹é”™è¯¯æç¤ºï¼ˆçº¢è‰²çš„é‚£è¡Œï¼‰",
    "- æ£€æŸ¥æ˜¯å¦æœ‰æ‹¼å†™é”™è¯¯",
    "- ç¡®è®¤ç¼©è¿›æ˜¯å¦æ­£ç¡®ï¼ˆPythonå¯¹ç©ºæ ¼å¾ˆæ•æ„Ÿï¼‰",
    "- å¤åˆ¶é”™è¯¯ä¿¡æ¯æœç´¢ä¸€ä¸‹",
    "",
    "**Q: çœ‹ä¸æ‡‚æ€ä¹ˆåŠï¼Ÿ**",
    "- è·³è¿‡éš¾çš„éƒ¨åˆ†ï¼Œå…ˆå­¦ç®€å•çš„",
    "- çœ‹çœ‹å‰é¢çš„è¯¾ç¨‹æœ‰æ²¡æœ‰é—æ¼",
    "- å¤šçœ‹å‡ éï¼Œç†è§£éœ€è¦æ—¶é—´",
    "",
    "**Q: éœ€è¦ä»€ä¹ˆåŸºç¡€ï¼Ÿ**",
    "- ä¼šç”¨ç”µè„‘å°±è¡Œ",
    "- PythonåŸºç¡€æœ€å¥½æœ‰ï¼Œæ²¡æœ‰ä¹Ÿèƒ½å­¦",
    "- æ•°å­¦ä¸å¥½ä¹Ÿæ²¡å…³ç³»ï¼Œæˆ‘ä»¬ç”¨ä¾‹å­è®²",
    "",
    "### ğŸ“Œ å­¦ä¹ æŠ€å·§",
    "",
    "- ğŸ¯ **ç›®æ ‡æ˜ç¡®**: çŸ¥é“è¿™èŠ‚è¯¾è¦å­¦ä»€ä¹ˆ",
    "- ğŸ“ **åšç¬”è®°**: é‡ç‚¹å†…å®¹è®°ä¸‹æ¥",
    "- ğŸ’» **å¤šç»ƒä¹ **: ä»£ç è¦è‡ªå·±æ•²ä¸€é",
    "- ğŸ¤” **å¤šæ€è€ƒ**: æƒ³æƒ³ä¸ºä»€ä¹ˆè¿™æ ·åš",
    "- ğŸ”„ **å¤šå¤ä¹ **: å­¦å®Œäº†å›å¤´å†çœ‹çœ‹",
    "",
    "---",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorchç¥ç»ç½‘ç»œåŸºç¡€\n",
    "\n",
    "**åˆ†ç±»:** åŸºç¡€å…¥é—¨\n",
    "\n",
    "**ğŸ§  è®­ç»ƒAIå°±åƒæ•™å°å­©,éœ€è¦è€å¿ƒå’Œæ–¹æ³•**\n",
    "\n",
    "---\n",
    "\n",
    "\n## ğŸ“ æ•™å°å­©å­¦ä¹ \n\næ•™å°å­©æ—¶:\n- **ç¬¬ä¸€æ­¥**: å‘Šè¯‰ä»–è¿™æ˜¯ä»€ä¹ˆ(è¾“å…¥)\n- **ç¬¬äºŒæ­¥**: å‘Šè¯‰ä»–åº”è¯¥æ€ä¹ˆåš(ç›®æ ‡)\n- **ç¬¬ä¸‰æ­¥**: ä»–åšé”™äº†,çº æ­£ä»–(æŸå¤±å‡½æ•°)\n- **ç¬¬å››æ­¥**: é‡å¤ç»ƒä¹ ,è¶Šæ¥è¶Šç†Ÿç»ƒ(è®­ç»ƒ)\n\n**è®­ç»ƒAIæ¨¡å‹å°±åƒæ•™å°å­©!**\n\n### ğŸ¯ ä¸ºä»€ä¹ˆéœ€è¦è®­ç»ƒ?\n\n**é—®é¢˜:** AIä¸€å¼€å§‹ä»€ä¹ˆéƒ½ä¸ä¼š\n- å°±åƒåˆšå‡ºç”Ÿçš„å©´å„¿\n- éœ€è¦å­¦ä¹ æ‰èƒ½å˜èªæ˜\n- è®­ç»ƒå°±æ˜¯\"æ•™\"AIå­¦ä¹ \n\n**æ–¹æ³•:** é€šè¿‡å¤§é‡æ•°æ®è®­ç»ƒ\n- ç»™AIçœ‹å¾ˆå¤šä¾‹å­\n- å‘Šè¯‰AIæ­£ç¡®ç­”æ¡ˆ\n- AIæ…¢æ…¢å­¦ä¼šè§„å¾‹\n\n### ğŸ“š å¾ªåºæ¸è¿›å­¦ä¹ \n\n**ç¬¬ä¸€æ­¥: ç†è§£é—®é¢˜** (ä½ ç°åœ¨åœ¨è¿™é‡Œ)\n- ä¸ºä»€ä¹ˆéœ€è¦è®­ç»ƒ?\n- å¦‚ä½•è®­ç»ƒ?\n\n**ç¬¬äºŒæ­¥: å­¦ä¹ è®­ç»ƒæ–¹æ³•** (æ¥ä¸‹æ¥)\n- å¦‚ä½•è®¾è®¡æŸå¤±å‡½æ•°?\n- å¦‚ä½•ä¼˜åŒ–å‚æ•°?\n\n**ç¬¬ä¸‰æ­¥: å®é™…åº”ç”¨** (æœ€å)\n- å¦‚ä½•è®­ç»ƒè‡ªå·±çš„æ¨¡å‹?\n- å¦‚ä½•è¯„ä¼°æ•ˆæœ?\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ æœ¬èŠ‚è¯¾ä½ å°†å­¦ä¼š\n",
    "\n",
    "- âœ… ç†è§£æ ¸å¿ƒæ¦‚å¿µå’ŒåŸç†\n",
    "- âœ… æŒæ¡å®é™…ä»£ç å®ç°\n",
    "- âœ… çŸ¥é“å¦‚ä½•åº”ç”¨åˆ°å®é™…é¡¹ç›®\n",
    "- âœ… ç†è§£è¿™ä¸ªæŠ€æœ¯è§£å†³ä»€ä¹ˆé—®é¢˜\n",
    "\n",
    "## ğŸ’¡ å­¦ä¹ å»ºè®®\n",
    "\n",
    "1. **å…ˆç†è§£\"ä¸ºä»€ä¹ˆ\"** - è¿™ä¸ªæŠ€æœ¯è§£å†³ä»€ä¹ˆå®é™…é—®é¢˜?\n",
    "2. **å†å­¦ä¹ \"æ˜¯ä»€ä¹ˆ\"** - è¿™ä¸ªæŠ€æœ¯çš„åŸç†æ˜¯ä»€ä¹ˆ?\n",
    "3. **æœ€åæŒæ¡\"æ€ä¹ˆåš\"** - å¦‚ä½•ç”¨ä»£ç å®ç°?\n",
    "4. **åŠ¨æ‰‹å®è·µ** - è¿è¡Œä»£ç ,ä¿®æ”¹å‚æ•°,è§‚å¯Ÿç»“æœ\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorchç¥ç»ç½‘ç»œåŸºç¡€\n",
    "\n",
    "**åˆ†ç±»:** åŸºç¡€å…¥é—¨\n",
    "\n",
    "**ğŸ¯ è®©æˆ‘ä»¬ä»å®é™…é—®é¢˜å‡ºå‘**\n",
    "\n",
    "---\n",
    "\n",
    "\n## ğŸ’­ å¼€å§‹ä¹‹å‰,æƒ³æƒ³è¿™ä¸ªé—®é¢˜\n\nå­¦ä¹  **PyTorchç¥ç»ç½‘ç»œåŸºç¡€** èƒ½å¸®æˆ‘ä»¬è§£å†³ä»€ä¹ˆå®é™…é—®é¢˜?\n\nåœ¨æ—¥å¸¸ç”Ÿæ´»ä¸­,ä½ å¯èƒ½å·²ç»åœ¨ä¸çŸ¥ä¸è§‰ä¸­ä½¿ç”¨äº†è¿™ä¸ªæŠ€æœ¯:\n- ğŸ“± æ‰‹æœºApp\n- ğŸ® æ¸¸æˆ\n- ğŸ›’ ç½‘è´­\n- ğŸ“º è§†é¢‘æ¨è\n\nè®©æˆ‘ä»¬ä¸€èµ·æ¢ç´¢è¿™ä¸ªæŠ€æœ¯èƒŒåçš„åŸç†!\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ æœ¬èŠ‚è¯¾ä½ å°†å­¦ä¼š\n",
    "\n",
    "- âœ… ç†è§£æ ¸å¿ƒæ¦‚å¿µå’ŒåŸç†\n",
    "- âœ… æŒæ¡å®é™…ä»£ç å®ç°\n",
    "- âœ… çŸ¥é“å¦‚ä½•åº”ç”¨åˆ°å®é™…é¡¹ç›®\n",
    "- âœ… ç†è§£è¿™ä¸ªæŠ€æœ¯è§£å†³ä»€ä¹ˆé—®é¢˜\n",
    "\n",
    "## ğŸ’¡ å­¦ä¹ å»ºè®®\n",
    "\n",
    "1. **å…ˆç†è§£\"ä¸ºä»€ä¹ˆ\"** - è¿™ä¸ªæŠ€æœ¯è§£å†³ä»€ä¹ˆå®é™…é—®é¢˜?\n",
    "2. **å†å­¦ä¹ \"æ˜¯ä»€ä¹ˆ\"** - è¿™ä¸ªæŠ€æœ¯çš„åŸç†æ˜¯ä»€ä¹ˆ?\n",
    "3. **æœ€åæŒæ¡\"æ€ä¹ˆåš\"** - å¦‚ä½•ç”¨ä»£ç å®ç°?\n",
    "4. **åŠ¨æ‰‹å®è·µ** - è¿è¡Œä»£ç ,ä¿®æ”¹å‚æ•°,è§‚å¯Ÿç»“æœ\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. å±‚å’Œå—"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â‘  nn.Sequential å®šä¹‰äº†ä¸€ç§ç‰¹æ®Šçš„Moduleã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0214, -0.1789, -0.0700, -0.0238, -0.2697,  0.0381,  0.3078, -0.2082,\n",
       "         -0.1502,  0.0433],\n",
       "        [ 0.0200, -0.1466, -0.0633,  0.0031, -0.2042,  0.0993,  0.3137, -0.1206,\n",
       "         -0.1057,  0.0434]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# å›é¡¾ä¸€ä¸‹å¤šå±‚æ„ŸçŸ¥æœº\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "net = nn.Sequential(nn.Linear(20,256),nn.ReLU(),nn.Linear(256,10))\n",
    "X = torch.rand(2,20)\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. è‡ªå®šä¹‰å—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1600,  0.0363,  0.0851,  0.0364,  0.0189,  0.1590,  0.1519,  0.1299,\n",
       "         -0.1382, -0.2075],\n",
       "        [-0.1956,  0.0779, -0.0385, -0.0741,  0.0229,  0.0116,  0.1271,  0.0273,\n",
       "         -0.0867, -0.0511]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()  # è°ƒç”¨çˆ¶ç±»çš„__init__å‡½æ•°\n",
    "        self.hidden = nn.Linear(20,256)\n",
    "        self.out = nn.Linear(256,10)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        return self.out(F.relu(self.hidden(X)))\n",
    "    \n",
    "# å®ä¾‹åŒ–å¤šå±‚æ„ŸçŸ¥æœºçš„å±‚ï¼Œç„¶ååœ¨æ¯æ¬¡è°ƒç”¨æ­£å‘ä¼ æ’­å‡½æ•°è°ƒç”¨è¿™äº›å±‚\n",
    "net = MLP()\n",
    "X = torch.rand(2,20)\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. é¡ºåºå—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=20, out_features=256, bias=True)\n",
      "ReLU()\n",
      "Linear(in_features=256, out_features=10, bias=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0651,  0.0377, -0.0348, -0.0377,  0.1602,  0.0022, -0.0904,  0.1742,\n",
       "         -0.0520,  0.0189],\n",
       "        [-0.0192,  0.1056, -0.0497,  0.0301,  0.2464,  0.0126, -0.1700,  0.4147,\n",
       "          0.0703, -0.0013]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MySequential(nn.Module):\n",
    "    def __init__(self, *args):\n",
    "        super().__init__()\n",
    "        for block in args:\n",
    "            self._modules[block] = block # block æœ¬èº«ä½œä¸ºå®ƒçš„keyï¼Œå­˜åœ¨_modulesé‡Œé¢çš„ä¸ºå±‚ï¼Œä»¥å­—å…¸çš„å½¢å¼\n",
    "            \n",
    "    def forward(self, X):\n",
    "        for block in self._modules.values():\n",
    "            print(block)\n",
    "            X = block(X)\n",
    "        return X\n",
    "    \n",
    "net = MySequential(nn.Linear(20,256),nn.ReLU(),nn.Linear(256,10))\n",
    "X = torch.rand(2,20)\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. æ­£å‘ä¼ æ’­"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3770, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# åœ¨æ­£å‘ä¼ æ’­å‡½æ•°ä¸­æ‰§è¡Œä»£ç \n",
    "class FixedHiddenMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.rand_weight = torch.rand((20,20),requires_grad=False)\n",
    "        self.linear = nn.Linear(20,20)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        X = self.linear(X)\n",
    "        X = F.relu(torch.mm(X, self.rand_weight + 1))\n",
    "        X = self.linear(X)\n",
    "        while X.abs().sum() > 1:\n",
    "            X /= 2\n",
    "        return X.sum()\n",
    "    \n",
    "net = FixedHiddenMLP()\n",
    "X = torch.rand(2,20)\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. æ··åˆç»„åˆå—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.1488, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# æ··åˆä»£åŸ¹å„ç§ç»„åˆå—çš„æ–¹æ³•\n",
    "class NestMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(nn.Linear(20,64),nn.ReLU(),\n",
    "                                nn.Linear(64,32),nn.ReLU())\n",
    "        self.linear = nn.Linear(32,16)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        return self.linear(self.net(X))\n",
    "    \n",
    "chimear = nn.Sequential(NestMLP(),nn.Linear(16,20),FixedHiddenMLP())\n",
    "X = torch.rand(2,20)\n",
    "chimear(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. å‚æ•°ç®¡ç†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3941],\n",
      "        [0.4224]], grad_fn=<AddmmBackward0>)\n",
      "OrderedDict([('weight', tensor([[ 4.7564e-02, -5.3226e-02,  1.4919e-04, -2.8679e-01,  1.7408e-01,\n",
      "          3.0859e-01, -1.2281e-01,  5.6171e-02]])), ('bias', tensor([0.3129]))])\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "Parameter containing:\n",
      "tensor([0.3129], requires_grad=True)\n",
      "tensor([0.3129])\n",
      "True\n",
      "('weight', torch.Size([8, 4])) ('bias', torch.Size([8]))\n",
      "('0.weight', torch.Size([8, 4])) ('0.bias', torch.Size([8])) ('2.weight', torch.Size([1, 8])) ('2.bias', torch.Size([1]))\n",
      "tensor([0.3129])\n"
     ]
    }
   ],
   "source": [
    "# é¦–å…ˆå…³æ³¨å…·æœ‰å•éšè—å±‚çš„å¤šå±‚æ„ŸçŸ¥æœº\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "net = nn.Sequential(nn.Linear(4,8),nn.ReLU(),nn.Linear(8,1))\n",
    "X = torch.rand(size=(2,4))\n",
    "print(net(X))\n",
    "print(net[2].state_dict()) # è®¿é—®å‚æ•°ï¼Œnet[2]å°±æ˜¯æœ€åä¸€ä¸ªè¾“å‡ºå±‚\n",
    "print(type(net[2].bias)) # ç›®æ ‡å‚æ•°\n",
    "print(net[2].bias)\n",
    "print(net[2].bias.data)\n",
    "print(net[2].weight.grad == None) # è¿˜æ²¡è¿›è¡Œåå‘è®¡ç®—ï¼Œæ‰€ä»¥gradä¸ºNone\n",
    "print(*[(name, param.shape) for name, param in net[0].named_parameters()])  # ä¸€æ¬¡æ€§è®¿é—®æ‰€æœ‰å‚æ•°         \n",
    "print(*[(name, param.shape) for name, param in net.named_parameters()])  # 0æ˜¯ç¬¬ä¸€å±‚åå­—ï¼Œ1æ˜¯ReLUï¼Œå®ƒæ²¡æœ‰å‚æ•°\n",
    "print(net.state_dict()['2.bias'].data) # é€šè¿‡åå­—è·å–å‚æ•°"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. åµŒå¥—å—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1750],\n",
      "        [-0.1750]], grad_fn=<AddmmBackward0>)\n",
      "Sequential(\n",
      "  (0): Sequential(\n",
      "    (block0): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (block1): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (block2): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (block3): Sequential(\n",
      "      (0): Linear(in_features=4, out_features=8, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (1): Linear(in_features=4, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# ä»åµŒå¥—å—æ”¶é›†å‚æ•°\n",
    "def block1():\n",
    "    return nn.Sequential(nn.Linear(4,8),nn.ReLU(),nn.Linear(8,4),nn.ReLU())\n",
    "\n",
    "def block2():\n",
    "    net = nn.Sequential()\n",
    "    for i in range(4):\n",
    "        net.add_module(f'block{i}',block1()) # f'block{i}' å¯ä»¥ä¼ ä¸€ä¸ªå­—ç¬¦ä¸²åå­—è¿‡æ¥ï¼Œblock2å¯ä»¥åµŒå¥—å››ä¸ªblock1                                      \n",
    "    return net\n",
    "\n",
    "rgnet = nn.Sequential(block2(), nn.Linear(4,1))\n",
    "print(rgnet(X))\n",
    "print(rgnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8 å†…ç½®åˆå§‹åŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0012, -0.0112, -0.0153,  0.0218])\n",
      "tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "net = nn.Sequential(nn.Linear(4,8),nn.ReLU(),nn.Linear(8,1))\n",
    "\n",
    "def init_normal(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.normal_(m.weight, mean=0, std=0.01) # ä¸‹åˆ’çº¿è¡¨ç¤ºæŠŠm.weightçš„å€¼æ›¿æ¢æ‰   \n",
    "        nn.init.zeros_(m.bias)\n",
    "        \n",
    "net.apply(init_normal) # ä¼šé€’å½’è°ƒç”¨ ç›´åˆ°æ‰€æœ‰å±‚éƒ½åˆå§‹åŒ–\n",
    "print(net[0].weight.data[0])\n",
    "print(net[0].bias.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1.])\n",
      "tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "net = nn.Sequential(nn.Linear(4,8),nn.ReLU(),nn.Linear(8,1))\n",
    "\n",
    "def init_constant(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.constant_(m.weight,1)\n",
    "        nn.init.zeros_(m.bias)\n",
    "        \n",
    "net.apply(init_constant)\n",
    "print(net[0].weight.data[0]) \n",
    "print(net[0].bias.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0479, -0.1771,  0.5267, -0.0020])\n",
      "tensor([[42., 42., 42., 42., 42., 42., 42., 42.]])\n"
     ]
    }
   ],
   "source": [
    "# å¯¹æŸäº›å—åº”ç”¨ä¸åŒçš„åˆå§‹åŒ–\n",
    "def xavier(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "        \n",
    "def init_42(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.constant_(m.weight, 42)\n",
    "        \n",
    "net[0].apply(xavier)\n",
    "net[2].apply(init_42)\n",
    "print(net[0].weight.data[0])\n",
    "print(net[2].weight.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. å‚æ•°æ›¿æ¢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init weight torch.Size([8, 4])\n",
      "Init weight torch.Size([1, 8])\n",
      "tensor([[ 0.0000,  7.1240,  0.0000,  5.1135],\n",
      "        [-8.6745, -7.3974,  0.0000, -0.0000]], grad_fn=<SliceBackward0>)\n",
      "tensor([42.0000,  8.1240,  1.0000,  6.1135])\n"
     ]
    }
   ],
   "source": [
    "# è‡ªå®šä¹‰åˆå§‹åŒ–\n",
    "def my_init(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        print(\"Init\",*[(name, param.shape) for name, param in m.named_parameters()][0])  # æ‰“å°åå­—æ˜¯å•¥ï¼Œå½¢çŠ¶æ˜¯å•¥       \n",
    "        nn.init.uniform_(m.weight, -10, 10)\n",
    "        m.weight.data *= m.weight.data.abs() >=  5 # è¿™é‡Œ*=çš„ä»£ç ç›¸å½“äºå…ˆè®¡ç®—ä¸€ä¸ªå¸ƒå°”çŸ©é˜µ(å…ˆåˆ¤æ–­>=)ï¼Œç„¶åå†ç”¨å¸ƒå°”çŸ©é˜µçš„å¯¹åº”å…ƒç´ å»ä¹˜ä»¥åŸå§‹çŸ©é˜µçš„æ¯ä¸ªå…ƒç´ ã€‚ä¿ç•™ç»å¯¹å€¼å¤§äº5çš„æƒé‡ï¼Œä¸æ˜¯çš„è¯å°±è®¾ä¸º0\n",
    "\n",
    "net.apply(my_init)\n",
    "print(net[0].weight[:2])\n",
    "net[0].weight.data[:] += 1 # å‚æ•°æ›¿æ¢\n",
    "net[0].weight.data[0,0] = 42\n",
    "print(net[0].weight.data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. å‚æ•°ç»‘å®š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([True, True, True, True, True, True, True, True])\n",
      "tensor([True, True, True, True, True, True, True, True])\n"
     ]
    }
   ],
   "source": [
    "# å‚æ•°ç»‘å®š\n",
    "shared = nn.Linear(8,8)\n",
    "net = nn.Sequential(nn.Linear(4,8),nn.ReLU(),shared,nn.ReLU(),shared,nn.ReLU(),nn.Linear(8,1))  # ç¬¬2ä¸ªéšè—å±‚å’Œç¬¬3ä¸ªéšè—å±‚æ˜¯shareæƒé‡çš„ï¼Œç¬¬ä¸€ä¸ªå’Œç¬¬å››ä¸ªæ˜¯è‡ªå·±çš„  \n",
    "net(X)\n",
    "print(net[2].weight.data[0] == net[4].weight.data[0])\n",
    "net[2].weight.data[0,0] = 100\n",
    "print(net[2].weight.data[0] == net[4].weight.data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. è‡ªå®šä¹‰å±‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-2., -1.,  0.,  1.,  2.])\n",
      "tensor(-6.2864e-09, grad_fn=<MeanBackward0>)\n",
      "Parameter containing:\n",
      "tensor([[-2.8449,  0.1887,  0.7945],\n",
      "        [ 0.4226,  1.6180, -0.5880],\n",
      "        [-0.4794, -0.0817, -0.3648],\n",
      "        [-0.1979,  0.8702, -0.3515],\n",
      "        [-1.4943,  0.3618,  0.2969]], requires_grad=True)\n",
      "tensor([[0.0000, 0.0000, 1.3957],\n",
      "        [0.8225, 0.0000, 0.9089]])\n",
      "tensor([[0.],\n",
      "        [0.]])\n"
     ]
    }
   ],
   "source": [
    "# æ„é€ ä¸€ä¸ªæ²¡æœ‰ä»»ä½•å‚æ•°çš„è‡ªå®šä¹‰å±‚\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "class CenteredLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, X):\n",
    "        return X - X.mean()\n",
    "    \n",
    "layer = CenteredLayer()\n",
    "print(layer(torch.FloatTensor([1,2,3,4,5])))\n",
    "\n",
    "# å°†å±‚ä½œä¸ºç»„ä»¶åˆå¹¶åˆ°æ„å»ºæ›´å¤æ‚çš„æ¨¡å‹ä¸­\n",
    "net = nn.Sequential(nn.Linear(8,128),CenteredLayer())\n",
    "Y = net(torch.rand(4,8))\n",
    "print(Y.mean())\n",
    "\n",
    "# å¸¦å‚æ•°çš„å›¾å±‚\n",
    "class MyLinear(nn.Module):\n",
    "    def __init__(self, in_units, units):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.randn(in_units,units)) # nn.Parameterä½¿å¾—è¿™äº›å‚æ•°åŠ ä¸Šäº†æ¢¯åº¦    \n",
    "        self.bias = nn.Parameter(torch.randn(units,))\n",
    "\n",
    "    def forward(self, X):\n",
    "        linear = torch.matmul(X, self.weight.data) + self.bias.data\n",
    "        return F.relu(linear)\n",
    "    \n",
    "dense = MyLinear(5,3)\n",
    "print(dense.weight)\n",
    "\n",
    "# ä½¿ç”¨è‡ªå®šä¹‰å±‚ç›´æ¥æ‰§è¡Œæ­£å‘ä¼ æ’­è®¡ç®—\n",
    "print(dense(torch.rand(2,5)))\n",
    "# ä½¿ç”¨è‡ªå®šä¹‰å±‚æ„å»ºæ¨¡å‹\n",
    "net = nn.Sequential(MyLinear(64,8),MyLinear(8,1))\n",
    "print(net(torch.rand(2,64)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12. è¯»å†™æ–‡ä»¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3])\n",
      "tensor([0, 1, 2, 3])\n",
      "tensor([0., 0., 0., 0.])\n",
      "{'x': tensor([0, 1, 2, 3]), 'y': tensor([0., 0., 0., 0.])}\n"
     ]
    }
   ],
   "source": [
    "# åŠ è½½å’Œä¿å­˜å¼ é‡\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "x = torch.arange(4)\n",
    "torch.save(x, 'x-file')\n",
    "x2 = torch.load(\"x-file\")\n",
    "print(x2)\n",
    "\n",
    "#å­˜å‚¨ä¸€ä¸ªå¼ é‡åˆ—è¡¨ï¼Œç„¶åæŠŠå®ƒä»¬è¯»å›å†…å­˜\n",
    "y = torch.zeros(4)\n",
    "torch.save([x,y],'x-files')\n",
    "x2, y2 = torch.load('x-files')\n",
    "print(x2)\n",
    "print(y2)\n",
    "\n",
    "# å†™å…¥æˆ–è¯»å–ä»å­—ç¬¦ä¸²æ˜ å°„åˆ°å¼ é‡çš„å­—å…¸\n",
    "mydict = {'x':x,'y':y}\n",
    "torch.save(mydict,'mydict')\n",
    "mydict2 = torch.load('mydict')\n",
    "print(mydict2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (hidden): Linear(in_features=20, out_features=256, bias=True)\n",
      "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n",
      "tensor([[True, True, True, True, True, True, True, True, True, True],\n",
      "        [True, True, True, True, True, True, True, True, True, True]])\n"
     ]
    }
   ],
   "source": [
    "# åŠ è½½å’Œä¿å­˜æ¨¡å‹å‚æ•°\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(20,256)\n",
    "        self.output = nn.Linear(256,10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.output(F.relu(self.hidden(x)))\n",
    "    \n",
    "net = MLP()\n",
    "X = torch.randn(size=(2,20))\n",
    "Y = net(X)\n",
    "\n",
    "# å°†æ¨¡å‹çš„å‚æ•°å­˜å‚¨ä¸ºä¸€ä¸ªå«åš\"mlp.params\"çš„æ–‡ä»¶\n",
    "torch.save(net.state_dict(),'mlp.params')\n",
    "\n",
    "# å®ä¾‹åŒ–äº†åŸå§‹å¤šå±‚æ„ŸçŸ¥æœºæ¨¡å‹çš„ä¸€ä¸ªå¤‡ä»½ã€‚ç›´æ¥è¯»å–æ–‡ä»¶ä¸­å­˜å‚¨çš„å‚æ•°\n",
    "clone = MLP() # å¿…é¡»è¦å…ˆå£°æ˜ä¸€ä¸‹ï¼Œæ‰èƒ½å¯¼å…¥å‚æ•°\n",
    "clone.load_state_dict(torch.load(\"mlp.params\"))\n",
    "print(clone.eval()) # eval()æ˜¯è¿›å…¥æµ‹è¯•æ¨¡å¼\n",
    "\n",
    "Y_clone = clone(X)\n",
    "print(Y_clone == Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n### ğŸŒ å®é™…åº”ç”¨åœºæ™¯\n\n1. **æ™ºèƒ½å®¢æœæœºå™¨äºº**\n   - åœºæ™¯: æ·˜å®ã€äº¬ä¸œçš„åœ¨çº¿å®¢æœ\n   - åº”ç”¨: ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹ç†è§£ç”¨æˆ·é—®é¢˜å¹¶å›ç­”\n   - æ•ˆæœ: 24å°æ—¶åœ¨çº¿,ç§’å›æ¶ˆæ¯,è§£å†³ç‡80%+\n   - æ¡ˆä¾‹: é˜¿é‡Œå°èœœæ¯å¤©æœåŠ¡è¶…è¿‡1000ä¸‡ç”¨æˆ·\n\n2. **è¯­éŸ³åŠ©æ‰‹**\n   - åœºæ™¯: Siriã€å°çˆ±åŒå­¦ã€å¤©çŒ«ç²¾çµ\n   - åº”ç”¨: è¯­éŸ³è¯†åˆ«æ¨¡å‹+è‡ªç„¶è¯­è¨€ç†è§£æ¨¡å‹\n   - æ•ˆæœ: å¬æ‡‚ä½ è¯´çš„è¯,æ‰§è¡Œå„ç§æŒ‡ä»¤\n   - æ¡ˆä¾‹: å…¨çƒæ™ºèƒ½éŸ³ç®±å‡ºè´§é‡è¶…2äº¿å°\n\n3. **ç…§ç‰‡ç¾åŒ–**\n   - åœºæ™¯: ç¾å›¾ç§€ç§€ã€æŠ–éŸ³æ»¤é•œ\n   - åº”ç”¨: ä½¿ç”¨æ¨¡å‹è‡ªåŠ¨ç£¨çš®ã€ç˜¦è„¸ã€ç¾ç™½\n   - æ•ˆæœ: ä¸€é”®ç¾é¢œ,æ•ˆæœè‡ªç„¶\n   - æ¡ˆä¾‹: ç¾å›¾ç§€ç§€æœˆæ´»ç”¨æˆ·è¶…3äº¿\n\n4. **æ¸¸æˆAI**\n   - åœºæ™¯: ç‹è€…è£è€€ã€å’Œå¹³ç²¾è‹±çš„AIå¯¹æ‰‹\n   - åº”ç”¨: è®­ç»ƒæ¨¡å‹è®©AIåƒäººä¸€æ ·ç©æ¸¸æˆ\n   - æ•ˆæœ: AIèƒ½åšå‡ºåˆç†çš„æˆ˜æœ¯å†³ç­–\n   - æ¡ˆä¾‹: OpenAIçš„Dota2 AIå‡»è´¥ä¸–ç•Œå† å†›\n\n5. **æ™ºèƒ½æ¨è**\n   - åœºæ™¯: ç½‘æ˜“äº‘éŸ³ä¹ã€Bç«™çš„æ¨èç³»ç»Ÿ\n   - åº”ç”¨: æ¨¡å‹åˆ†æä½ çš„å–œå¥½,æ¨èå†…å®¹\n   - æ•ˆæœ: è¶Šç”¨è¶Šæ‡‚ä½ ,æ¨èè¶Šæ¥è¶Šå‡†\n   - æ¡ˆä¾‹: æŠ–éŸ³æ¨èç®—æ³•è®©ç”¨æˆ·å¹³å‡åœç•™æ—¶é•¿è¶…100åˆ†é’Ÿ/å¤©\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n### ğŸŒ å®é™…åº”ç”¨åœºæ™¯\n\n1. **æ™ºèƒ½å®¢æœæœºå™¨äºº**\n   - åœºæ™¯: æ·˜å®ã€äº¬ä¸œçš„åœ¨çº¿å®¢æœ\n   - åº”ç”¨: ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹ç†è§£ç”¨æˆ·é—®é¢˜å¹¶å›ç­”\n   - æ•ˆæœ: 24å°æ—¶åœ¨çº¿,ç§’å›æ¶ˆæ¯,è§£å†³ç‡80%+\n   - æ¡ˆä¾‹: é˜¿é‡Œå°èœœæ¯å¤©æœåŠ¡è¶…è¿‡1000ä¸‡ç”¨æˆ·\n\n2. **è¯­éŸ³åŠ©æ‰‹**\n   - åœºæ™¯: Siriã€å°çˆ±åŒå­¦ã€å¤©çŒ«ç²¾çµ\n   - åº”ç”¨: è¯­éŸ³è¯†åˆ«æ¨¡å‹+è‡ªç„¶è¯­è¨€ç†è§£æ¨¡å‹\n   - æ•ˆæœ: å¬æ‡‚ä½ è¯´çš„è¯,æ‰§è¡Œå„ç§æŒ‡ä»¤\n   - æ¡ˆä¾‹: å…¨çƒæ™ºèƒ½éŸ³ç®±å‡ºè´§é‡è¶…2äº¿å°\n\n3. **ç…§ç‰‡ç¾åŒ–**\n   - åœºæ™¯: ç¾å›¾ç§€ç§€ã€æŠ–éŸ³æ»¤é•œ\n   - åº”ç”¨: ä½¿ç”¨æ¨¡å‹è‡ªåŠ¨ç£¨çš®ã€ç˜¦è„¸ã€ç¾ç™½\n   - æ•ˆæœ: ä¸€é”®ç¾é¢œ,æ•ˆæœè‡ªç„¶\n   - æ¡ˆä¾‹: ç¾å›¾ç§€ç§€æœˆæ´»ç”¨æˆ·è¶…3äº¿\n\n4. **æ¸¸æˆAI**\n   - åœºæ™¯: ç‹è€…è£è€€ã€å’Œå¹³ç²¾è‹±çš„AIå¯¹æ‰‹\n   - åº”ç”¨: è®­ç»ƒæ¨¡å‹è®©AIåƒäººä¸€æ ·ç©æ¸¸æˆ\n   - æ•ˆæœ: AIèƒ½åšå‡ºåˆç†çš„æˆ˜æœ¯å†³ç­–\n   - æ¡ˆä¾‹: OpenAIçš„Dota2 AIå‡»è´¥ä¸–ç•Œå† å†›\n\n5. **æ™ºèƒ½æ¨è**\n   - åœºæ™¯: ç½‘æ˜“äº‘éŸ³ä¹ã€Bç«™çš„æ¨èç³»ç»Ÿ\n   - åº”ç”¨: æ¨¡å‹åˆ†æä½ çš„å–œå¥½,æ¨èå†…å®¹\n   - æ•ˆæœ: è¶Šç”¨è¶Šæ‡‚ä½ ,æ¨èè¶Šæ¥è¶Šå‡†\n   - æ¡ˆä¾‹: æŠ–éŸ³æ¨èç®—æ³•è®©ç”¨æˆ·å¹³å‡åœç•™æ—¶é•¿è¶…100åˆ†é’Ÿ/å¤©\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“š æœ¬èŠ‚å°ç»“\n",
    "\n",
    "æ­å–œä½ å®Œæˆäº†æœ¬èŠ‚å­¦ä¹ !è®©æˆ‘ä»¬å›é¡¾ä¸€ä¸‹:\n",
    "\n",
    "### âœ… ä½ å­¦åˆ°äº†ä»€ä¹ˆ?\n",
    "- è¯·åœ¨è¿™é‡Œå†™ä¸‹ä½ çš„æ”¶è·...\n",
    "\n",
    "### ğŸ¤” è¿˜æœ‰ç–‘é—®?\n",
    "- è¯·è®°å½•ä¸‹ä½ ä¸ç†è§£çš„åœ°æ–¹...\n",
    "\n",
    "### ğŸš€ ä¸‹ä¸€æ­¥\n",
    "- ç»§ç»­å­¦ä¹ ç›¸å…³ä¸»é¢˜\n",
    "- å°è¯•åšä¸€äº›ç»ƒä¹ é¢˜\n",
    "- åº”ç”¨åˆ°å®é™…é¡¹ç›®ä¸­\n",
    "\n",
    "---\n",
    "\n",
    "**è®°ä½:** å­¦ä¹ æ˜¯ä¸€ä¸ªå¾ªåºæ¸è¿›çš„è¿‡ç¨‹,ä¸è¦ç€æ€¥,æ…¢æ…¢æ¥! ğŸ’ª\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.3",
   "language": "python",
   "name": "python3.6.3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "2041.23px",
    "left": "45.9792px",
    "top": "56px",
    "width": "301.875px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}